{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition\n",
    "#### By Siddhart Goel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Angry emotion = 3995\n"
     ]
    }
   ],
   "source": [
    "human_angry = glob.glob(\"../Data/Humans/Angry/*\")\n",
    "print(\"Number of images in Angry emotion = \"+str(len(human_angry)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3995, 3995, 3995, 3995)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_angry_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_angry]\n",
    "human_angry_folderName = [(human_angry[i].replace(\"\\\\\"+str(human_angry_imageName[i]),\"/\")) for i in range(len(human_angry))]\n",
    "human_angry_emotion = [[\"Angry\"]*len(human_angry)][0]\n",
    "human_angry_label = [1]*len(human_angry)\n",
    "len(human_angry_folderName), len(human_angry_imageName), len(human_angry_emotion), len(human_angry_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_10118481.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_10120469.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_10131352.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_10161559.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_1021836.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              folderName              imageName Emotion  Labels\n",
       "0  ../Data/Humans/Angry/  Training_10118481.jpg   Angry       1\n",
       "1  ../Data/Humans/Angry/  Training_10120469.jpg   Angry       1\n",
       "2  ../Data/Humans/Angry/  Training_10131352.jpg   Angry       1\n",
       "3  ../Data/Humans/Angry/  Training_10161559.jpg   Angry       1\n",
       "4  ../Data/Humans/Angry/   Training_1021836.jpg   Angry       1"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_angry = pd.DataFrame()\n",
    "df_angry[\"folderName\"] = human_angry_folderName\n",
    "df_angry[\"imageName\"] = human_angry_imageName\n",
    "df_angry[\"Emotion\"] = human_angry_emotion\n",
    "df_angry[\"Labels\"] = human_angry_label\n",
    "df_angry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Disgust emotion = 436\n"
     ]
    }
   ],
   "source": [
    "human_disgust = glob.glob(\"../Data/Humans/Disgust/*\")\n",
    "print(\"Number of images in Disgust emotion = \"+str(len(human_disgust)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 436, 436, 436)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_disgust_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_disgust]\n",
    "human_disgust_folderName = [(human_disgust[i].replace(\"\\\\\"+str(human_disgust_imageName[i]),\"/\")) for i in range(len(human_disgust))]\n",
    "human_disgust_emotion = [[\"Disgust\"]*len(human_disgust)][0]\n",
    "human_disgust_label = [2]*len(human_disgust)\n",
    "\n",
    "len(human_disgust_folderName), len(human_disgust_imageName), len(human_disgust_emotion), len(human_disgust_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_10371709.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_10598340.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_1070239.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_11050021.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_11550217.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                folderName              imageName  Emotion  Labels\n",
       "0  ../Data/Humans/Disgust/  Training_10371709.jpg  Disgust       2\n",
       "1  ../Data/Humans/Disgust/  Training_10598340.jpg  Disgust       2\n",
       "2  ../Data/Humans/Disgust/   Training_1070239.jpg  Disgust       2\n",
       "3  ../Data/Humans/Disgust/  Training_11050021.jpg  Disgust       2\n",
       "4  ../Data/Humans/Disgust/  Training_11550217.jpg  Disgust       2"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disgust = pd.DataFrame()\n",
    "df_disgust[\"folderName\"] = human_disgust_folderName\n",
    "df_disgust[\"imageName\"] = human_disgust_imageName\n",
    "df_disgust[\"Emotion\"] = human_disgust_emotion\n",
    "df_disgust[\"Labels\"] = human_disgust_label\n",
    "df_disgust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Fear emotion = 4097\n"
     ]
    }
   ],
   "source": [
    "human_fear = glob.glob(\"../Data/Humans/Fear/*\")\n",
    "print(\"Number of images in Fear emotion = \"+str(len(human_fear)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4097, 4097, 4097, 4097)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_fear_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_fear]\n",
    "human_fear_folderName = [(human_fear[i].replace(\"\\\\\"+str(human_fear_imageName[i]),\"/\")) for i in range(len(human_fear))]\n",
    "human_fear_emotion = [[\"Fear\"]*len(human_fear)][0]\n",
    "human_fear_label = [3]*len(human_fear)\n",
    "\n",
    "len(human_fear_folderName), len(human_fear_imageName), len(human_fear_emotion), len(human_fear_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_10018621.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_10031494.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_10110501.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_10117992.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_10126156.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             folderName              imageName Emotion  Labels\n",
       "0  ../Data/Humans/Fear/  Training_10018621.jpg    Fear       3\n",
       "1  ../Data/Humans/Fear/  Training_10031494.jpg    Fear       3\n",
       "2  ../Data/Humans/Fear/  Training_10110501.jpg    Fear       3\n",
       "3  ../Data/Humans/Fear/  Training_10117992.jpg    Fear       3\n",
       "4  ../Data/Humans/Fear/  Training_10126156.jpg    Fear       3"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fear = pd.DataFrame()\n",
    "df_fear[\"folderName\"] = human_fear_folderName\n",
    "df_fear[\"imageName\"] = human_fear_imageName\n",
    "df_fear[\"Emotion\"] = human_fear_emotion\n",
    "df_fear[\"Labels\"] = human_fear_label\n",
    "df_fear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Happy emotion = 3819\n"
     ]
    }
   ],
   "source": [
    "human_happy = glob.glob(\"../Data/Humans/Happy/*\")\n",
    "print(\"Number of images in Happy emotion = \"+str(len(human_happy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3819, 3819, 3819, 3819)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_happy_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_happy]\n",
    "human_happy_folderName = [(human_happy[i].replace(\"\\\\\"+str(human_happy_imageName[i]),\"/\")) for i in range(len(human_happy))]\n",
    "human_happy_emotion = [[\"Happy\"]*len(human_happy)][0]\n",
    "human_happy_label = [4]*len(human_happy)\n",
    "\n",
    "len(human_happy_folderName), len(human_happy_imageName), len(human_happy_emotion), len(human_happy_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_47009669.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_47017843.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_47023842.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_47060033.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_47060911.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              folderName              imageName Emotion  Labels\n",
       "0  ../Data/Humans/Happy/  Training_47009669.jpg   Happy       4\n",
       "1  ../Data/Humans/Happy/  Training_47017843.jpg   Happy       4\n",
       "2  ../Data/Humans/Happy/  Training_47023842.jpg   Happy       4\n",
       "3  ../Data/Humans/Happy/  Training_47060033.jpg   Happy       4\n",
       "4  ../Data/Humans/Happy/  Training_47060911.jpg   Happy       4"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_happy = pd.DataFrame()\n",
    "df_happy[\"folderName\"] = human_happy_folderName\n",
    "df_happy[\"imageName\"] = human_happy_imageName\n",
    "df_happy[\"Emotion\"] = human_happy_emotion\n",
    "df_happy[\"Labels\"] = human_happy_label\n",
    "df_happy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Neutral emotion = 4965\n"
     ]
    }
   ],
   "source": [
    "human_neutral = glob.glob(\"../Data/Humans/Neutral/*\")\n",
    "print(\"Number of images in Neutral emotion = \"+str(len(human_neutral)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4965, 4965, 4965, 4965)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_neutral_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_neutral]\n",
    "human_neutral_folderName = [(human_neutral[i].replace(\"\\\\\"+str(human_neutral_imageName[i]),\"/\")) for i in range(len(human_neutral))]\n",
    "human_neutral_emotion = [[\"Neutral\"]*len(human_neutral)][0]\n",
    "human_neutral_label = [5]*len(human_neutral)\n",
    "\n",
    "len(human_neutral_folderName), len(human_neutral_imageName), len(human_neutral_emotion), len(human_neutral_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_10002154.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_10031781.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_10055498.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_10059941.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_10078021.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                folderName              imageName  Emotion  Labels\n",
       "0  ../Data/Humans/Neutral/  Training_10002154.jpg  Neutral       5\n",
       "1  ../Data/Humans/Neutral/  Training_10031781.jpg  Neutral       5\n",
       "2  ../Data/Humans/Neutral/  Training_10055498.jpg  Neutral       5\n",
       "3  ../Data/Humans/Neutral/  Training_10059941.jpg  Neutral       5\n",
       "4  ../Data/Humans/Neutral/  Training_10078021.jpg  Neutral       5"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neutral = pd.DataFrame()\n",
    "df_neutral[\"folderName\"] = human_neutral_folderName\n",
    "df_neutral[\"imageName\"] = human_neutral_imageName\n",
    "df_neutral[\"Emotion\"] = human_neutral_emotion\n",
    "df_neutral[\"Labels\"] = human_neutral_label\n",
    "df_neutral.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Sad emotion = 4830\n"
     ]
    }
   ],
   "source": [
    "human_sad = glob.glob(\"../Data/Humans/Sad/*\")\n",
    "print(\"Number of images in Sad emotion = \"+str(len(human_sad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4830, 4830, 4830, 4830)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_sad_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_sad]\n",
    "human_sad_folderName = [(human_sad[i].replace(\"\\\\\"+str(human_sad_imageName[i]),\"/\")) for i in range(len(human_sad))]\n",
    "human_sad_emotion = [[\"Sad\"]*len(human_sad)][0]\n",
    "human_sad_label = [6]*len(human_sad)\n",
    "\n",
    "len(human_sad_folderName), len(human_sad_imageName), len(human_sad_emotion), len(human_sad_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_10022789.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_10031481.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_10048646.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_10057152.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_10091569.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            folderName              imageName Emotion  Labels\n",
       "0  ../Data/Humans/Sad/  Training_10022789.jpg     Sad       6\n",
       "1  ../Data/Humans/Sad/  Training_10031481.jpg     Sad       6\n",
       "2  ../Data/Humans/Sad/  Training_10048646.jpg     Sad       6\n",
       "3  ../Data/Humans/Sad/  Training_10057152.jpg     Sad       6\n",
       "4  ../Data/Humans/Sad/  Training_10091569.jpg     Sad       6"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sad = pd.DataFrame()\n",
    "df_sad[\"folderName\"] = human_sad_folderName\n",
    "df_sad[\"imageName\"] = human_sad_imageName\n",
    "df_sad[\"Emotion\"] = human_sad_emotion\n",
    "df_sad[\"Labels\"] = human_sad_label\n",
    "df_sad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Surprise emotion = 3171\n"
     ]
    }
   ],
   "source": [
    "human_surprise = glob.glob(\"../Data/Humans/Surprise/*\")\n",
    "print(\"Number of images in Surprise emotion = \"+str(len(human_surprise)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3171, 3171, 3171, 3171)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_surprise_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_surprise]\n",
    "human_surprise_folderName = [(human_surprise[i].replace(\"\\\\\"+str(human_surprise_imageName[i]),\"/\")) for i in range(len(human_surprise))]\n",
    "human_surprise_emotion = [[\"Surprise\"]*len(human_surprise)][0]\n",
    "human_surprise_label = [7]*len(human_surprise)\n",
    "\n",
    "len(human_surprise_folderName), len(human_surprise_imageName), len(human_surprise_emotion), len(human_surprise_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_10013223.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_1002457.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_10028230.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_10060820.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_10073433.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 folderName              imageName   Emotion  Labels\n",
       "0  ../Data/Humans/Surprise/  Training_10013223.jpg  Surprise       7\n",
       "1  ../Data/Humans/Surprise/   Training_1002457.jpg  Surprise       7\n",
       "2  ../Data/Humans/Surprise/  Training_10028230.jpg  Surprise       7\n",
       "3  ../Data/Humans/Surprise/  Training_10060820.jpg  Surprise       7\n",
       "4  ../Data/Humans/Surprise/  Training_10073433.jpg  Surprise       7"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_surprise = pd.DataFrame()\n",
    "df_surprise[\"folderName\"] = human_surprise_folderName\n",
    "df_surprise[\"imageName\"] = human_surprise_imageName\n",
    "df_surprise[\"Emotion\"] = human_surprise_emotion\n",
    "df_surprise[\"Labels\"] = human_surprise_label\n",
    "df_surprise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Pain emotion = 552\n"
     ]
    }
   ],
   "source": [
    "human_pain = glob.glob(\"../Data/Humans/Pain/*\")\n",
    "print(\"Number of images in Pain emotion = \"+str(len(human_pain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 552, 552, 552)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_pain_imageName = [str(i.split(\"\\\\\")[-1]) for i in human_pain]\n",
    "human_pain_folderName = [(human_pain[i].replace(\"\\\\\"+str(human_pain_imageName[i]),\"/\")) for i in range(len(human_pain))]\n",
    "human_pain_emotion = [[\"Pain\"]*len(human_pain)][0]\n",
    "human_pain_label = [8]*len(human_pain)\n",
    "\n",
    "len(human_pain_folderName), len(human_pain_imageName), len(human_pain_emotion), len(human_pain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Pain/</td>\n",
       "      <td>f1-45.jpg</td>\n",
       "      <td>Pain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Pain/</td>\n",
       "      <td>f10a1.jpg</td>\n",
       "      <td>Pain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Pain/</td>\n",
       "      <td>f10a2.jpg</td>\n",
       "      <td>Pain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Pain/</td>\n",
       "      <td>f10d1.jpg</td>\n",
       "      <td>Pain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Pain/</td>\n",
       "      <td>f10d2.jpg</td>\n",
       "      <td>Pain</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             folderName  imageName Emotion  Labels\n",
       "0  ../Data/Humans/Pain/  f1-45.jpg    Pain       8\n",
       "1  ../Data/Humans/Pain/  f10a1.jpg    Pain       8\n",
       "2  ../Data/Humans/Pain/  f10a2.jpg    Pain       8\n",
       "3  ../Data/Humans/Pain/  f10d1.jpg    Pain       8\n",
       "4  ../Data/Humans/Pain/  f10d2.jpg    Pain       8"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pain = pd.DataFrame()\n",
    "df_pain[\"folderName\"] = human_pain_folderName\n",
    "df_pain[\"imageName\"] = human_pain_imageName\n",
    "df_pain[\"Emotion\"] = human_pain_emotion\n",
    "df_pain[\"Labels\"] = human_pain_label\n",
    "df_pain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in all the emotions = 25865\n"
     ]
    }
   ],
   "source": [
    "length = df_angry.shape[0] + df_disgust.shape[0] + df_fear.shape[0] + df_happy.shape[0] + df_neutral.shape[0] + df_sad.shape[0] + df_surprise.shape[0] + df_pain.shape[0]\n",
    "print(\"Total number of images in all the emotions = \"+str(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25865, 4)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_angry, df_disgust, df_fear, df_happy, df_neutral, df_sad, df_surprise, df_pain]\n",
    "Final_human = pd.concat(frames)\n",
    "Final_human.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20137</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_71939703.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11064</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_47193693.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19539</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_73708771.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2693</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_85546096.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9329</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_58158149.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    folderName              imageName  Emotion  Labels\n",
       "20137    ../Data/Humans/Angry/  Training_71939703.jpg    Angry       1\n",
       "11064  ../Data/Humans/Neutral/  Training_47193693.jpg  Neutral       5\n",
       "19539    ../Data/Humans/Happy/  Training_73708771.jpg    Happy       4\n",
       "2693     ../Data/Humans/Happy/  Training_85546096.jpg    Happy       4\n",
       "9329       ../Data/Humans/Sad/  Training_58158149.jpg      Sad       6"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_human.reset_index(inplace = True, drop = True)\n",
    "Final_human = Final_human.sample(frac = 1.0)   #shuffling the dataframe\n",
    "Final_human.reset_index(inplace = True, drop = True)\n",
    "Final_human.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17289, 4), (3458, 4), (5118, 4))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_train_data, df_human_test = train_test_split(Final_human, stratify=Final_human[\"Labels\"], test_size = 0.197860)\n",
    "df_human_train, df_human_cv = train_test_split(df_human_train_data, stratify=df_human_train_data[\"Labels\"], test_size = 0.166666)\n",
    "df_human_train.shape, df_human_cv.shape, df_human_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_train.reset_index(inplace = True, drop = True)\n",
    "df_human_train.to_pickle(\"../Data/Dataframes/df_human_train.pkl\")\n",
    "\n",
    "df_human_cv.reset_index(inplace = True, drop = True)\n",
    "df_human_cv.to_pickle(\"../Data/Dataframes/df_human_cv.pkl\")\n",
    "\n",
    "df_human_test.reset_index(inplace = True, drop = True)\n",
    "df_human_test.to_pickle(\"../Data/Dataframes/df_human_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_45817788.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_49148848.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_57334138.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_3250157.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_91825354.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                folderName              imageName  Emotion  Labels\n",
       "0     ../Data/Humans/Fear/  Training_45817788.jpg     Fear       3\n",
       "1      ../Data/Humans/Sad/  Training_49148848.jpg      Sad       6\n",
       "2  ../Data/Humans/Neutral/  Training_57334138.jpg  Neutral       5\n",
       "3      ../Data/Humans/Sad/   Training_3250157.jpg      Sad       6\n",
       "4     ../Data/Humans/Fear/  Training_91825354.jpg     Fear       3"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_train = pd.read_pickle(\"..\\Data\\Dataframes\\df_human_train.pkl\")\n",
    "df_human_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17289, 4)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_11569849.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_38444438.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Disgust/</td>\n",
       "      <td>Training_24592307.jpg</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Fear/</td>\n",
       "      <td>Training_93925872.jpg</td>\n",
       "      <td>Fear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_26083913.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                folderName              imageName  Emotion  Labels\n",
       "0      ../Data/Humans/Sad/  Training_11569849.jpg      Sad       6\n",
       "1      ../Data/Humans/Sad/  Training_38444438.jpg      Sad       6\n",
       "2  ../Data/Humans/Disgust/  Training_24592307.jpg  Disgust       2\n",
       "3     ../Data/Humans/Fear/  Training_93925872.jpg     Fear       3\n",
       "4    ../Data/Humans/Angry/  Training_26083913.jpg    Angry       1"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_cv = pd.read_pickle(\"../Data/Dataframes/df_human_cv.pkl\")\n",
    "df_human_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3458, 4)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../Data/Humans/Surprise/</td>\n",
       "      <td>Training_90190497.jpg</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../Data/Humans/Happy/</td>\n",
       "      <td>Training_66036835.jpg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../Data/Humans/Sad/</td>\n",
       "      <td>Training_95029336.jpg</td>\n",
       "      <td>Sad</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../Data/Humans/Neutral/</td>\n",
       "      <td>Training_92082348.jpg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../Data/Humans/Angry/</td>\n",
       "      <td>Training_8601269.jpg</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 folderName              imageName   Emotion  Labels\n",
       "0  ../Data/Humans/Surprise/  Training_90190497.jpg  Surprise       7\n",
       "1     ../Data/Humans/Happy/  Training_66036835.jpg     Happy       4\n",
       "2       ../Data/Humans/Sad/  Training_95029336.jpg       Sad       6\n",
       "3   ../Data/Humans/Neutral/  Training_92082348.jpg   Neutral       5\n",
       "4     ../Data/Humans/Angry/   Training_8601269.jpg     Angry       1"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_test = pd.read_pickle(\"../Data/Dataframes/df_human_test.pkl\")\n",
    "df_human_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5118, 4)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 4)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pain_df = df_human_train[ (df_human_train[\"Labels\"]==8)]\n",
    "pain_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysing Data of Human Images\n",
    "### Distribution of class labels in Train, CV and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_train = df_human_train.sort_values(by = \"Labels\", inplace = False)\n",
    "df_temp_cv = df_human_cv.sort_values(by = \"Labels\", inplace = False)\n",
    "df_temp_test = df_human_test.sort_values(by = \"Labels\", inplace = False)\n",
    "\n",
    "TrainData_distribution = df_human_train[\"Emotion\"].value_counts().sort_index()\n",
    "CVData_distribution = df_human_cv[\"Emotion\"].value_counts().sort_index()\n",
    "TestData_distribution = df_human_test[\"Emotion\"].value_counts().sort_index()\n",
    "\n",
    "TrainData_distribution_sorted = sorted(TrainData_distribution.items(), key = lambda d: d[1], reverse = True)\n",
    "CVData_distribution_sorted = sorted(CVData_distribution.items(), key = lambda d: d[1], reverse = True)\n",
    "TestData_distribution_sorted = sorted(TestData_distribution.items(), key = lambda d: d[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points in class Neutral = 3319(19.1972%)\n",
      "Number of training data points in class Sad = 3228(18.6708%)\n",
      "Number of training data points in class Fear = 2738(15.8367%)\n",
      "Number of training data points in class Angry = 2670(15.4433%)\n",
      "Number of training data points in class Happy = 2553(14.7666%)\n",
      "Number of training data points in class Surprise = 2120(12.2621%)\n",
      "Number of training data points in class Pain = 369(2.1343%)\n",
      "Number of training data points in class Disgust = 292(1.6889%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points in class Neutral = 664(19.2019%)\n",
      "Number of training data points in class Sad = 646(18.6813%)\n",
      "Number of training data points in class Fear = 548(15.8473%)\n",
      "Number of training data points in class Angry = 534(15.4425%)\n",
      "Number of training data points in class Happy = 510(14.7484%)\n",
      "Number of training data points in class Surprise = 424(12.2614%)\n",
      "Number of training data points in class Pain = 74(2.14%)\n",
      "Number of training data points in class Disgust = 58(1.6773%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points in class Neutral = 982(19.1872%)\n",
      "Number of training data points in class Sad = 956(18.6792%)\n",
      "Number of training data points in class Fear = 811(15.846%)\n",
      "Number of training data points in class Angry = 791(15.4553%)\n",
      "Number of training data points in class Happy = 756(14.7714%)\n",
      "Number of training data points in class Surprise = 627(12.2509%)\n",
      "Number of training data points in class Pain = 109(2.1297%)\n",
      "Number of training data points in class Disgust = 86(1.6803%)\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Count of each Emotion in Train Data\", fontsize = 20)\n",
    "sns.countplot(x = \"Emotion\", data = df_temp_train)\n",
    "plt.grid()\n",
    "for i in ax.patches:\n",
    "    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()\n",
    "\n",
    "for i in TrainData_distribution_sorted:\n",
    "    print(\"Number of training data points in class \"+str(i[0])+\" = \"+str(i[1])+ \"(\"+str(np.round(((i[1]/df_temp_train.shape[0])*100), 4))+\"%)\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Count of each Emotion in Validation Data\", fontsize = 20)\n",
    "sns.countplot(x = \"Emotion\", data = df_temp_cv)\n",
    "plt.grid()\n",
    "for i in ax.patches:\n",
    "    ax.text(x = i.get_x() + 0.27, y = i.get_height()+0.2, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()\n",
    "\n",
    "for i in CVData_distribution_sorted:\n",
    "    print(\"Number of training data points in class \"+str(i[0])+\" = \"+str(i[1])+ \"(\"+str(np.round(((i[1]/df_temp_cv.shape[0])*100), 4))+\"%)\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Count of each Emotion in Test Data\", fontsize = 20)\n",
    "sns.countplot(x = \"Emotion\", data = df_temp_test)\n",
    "plt.grid()\n",
    "for i in ax.patches:\n",
    "    ax.text(x = i.get_x() + 0.27, y = i.get_height()+0.2, s = str(i.get_height()), fontsize = 20, color = \"grey\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\", fontsize = 15)\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()\n",
    "\n",
    "for i in TestData_distribution_sorted:\n",
    "    print(\"Number of training data points in class \"+str(i[0])+\" = \"+str(i[1])+ \"(\"+str(np.round(((i[1]/df_temp_test.shape[0])*100), 4))+\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-Processing Human Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Converting all the images to grayscale and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convt_to_gray(df):\n",
    "    count = 0\n",
    "    for i in range(len(df)):\n",
    "        path1 = df[\"folderName\"][i]\n",
    "        path2 = df[\"imageName\"][i]\n",
    "        img = cv2.imread(os.path.join(path1, path2))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(os.path.join(path1, path2), gray)\n",
    "        count += 1\n",
    "    print(\"Total number of images converted and saved = \"+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images converted and saved = 17289\n"
     ]
    }
   ],
   "source": [
    "convt_to_gray(df_human_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images converted and saved = 3458\n"
     ]
    }
   ],
   "source": [
    "convt_to_gray(df_human_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images converted and saved = 5118\n"
     ]
    }
   ],
   "source": [
    "convt_to_gray(df_human_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Detecting face in image using HAAR then crop it then resize then save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the face in image using HAAR cascade then crop it then resize it and finally save it. \n",
    "#download this xml file from link: https://github.com/opencv/opencv/tree/master/data/haarcascades.\n",
    "def face_det_crop_resize(path):\n",
    "    #detect face in image, crop it then resize it then save it\n",
    "    face_cascade = cv2.CascadeClassifier(r'C:\\Users\\SIDDHARTH GOEL\\OneDrive\\Desktop\\FCR\\final code\\haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "    cv2.imwrite(path, img)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_clip = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(path, face_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in df_human_train.iterrows():\n",
    "    img_path = os.path.join(d[\"folderName\"], d[\"imageName\"])\n",
    "    face_det_crop_resize(img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in df_human_cv.iterrows():\n",
    "    img_path = os.path.join(d[\"folderName\"], d[\"imageName\"])\n",
    "    face_det_crop_resize(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in df_human_test.iterrows():\n",
    "    img_path = os.path.join(d[\"folderName\"], d[\"imageName\"])\n",
    "    face_det_crop_resize(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Creating bottleneck features from VGG-16 model. Here, we are using Transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17289, 4), (3458, 4), (5118, 4))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Combined = pd.read_pickle(\"..\\Data\\Dataframes\\df_human_train.pkl\")\n",
    "CV_Humans = pd.read_pickle(\"..\\Data\\Dataframes\\df_human_cv.pkl\")\n",
    "Test_Humans = pd.read_pickle(\"..\\Data\\Dataframes\\df_human_test.pkl\")\n",
    "\n",
    "Train_Combined.shape, CV_Humans.shape, Test_Humans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainCombined_batch_pointer = 0\n",
    "CVHumans_batch_pointer = 0\n",
    "TestHumans_batch_pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Bottleneck features for Final Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH GOEL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17289, 8)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainCombined_Labels = pd.get_dummies(Train_Combined[\"Labels\"]).as_matrix()\n",
    "TrainCombined_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainCombined_batch_pointer = 0\n",
    "def loadCombinedTrainBatch(batch_size):\n",
    "    global TrainCombined_batch_pointer\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        path1 = Train_Combined.iloc[TrainCombined_batch_pointer + i][\"folderName\"]\n",
    "        path2 = Train_Combined.iloc[TrainCombined_batch_pointer + i][\"imageName\"]\n",
    "        read_image = cv2.imread(os.path.join(path1, path2))\n",
    "        read_image_final = read_image.resize((48, 48 ,3))\n",
    "        read_image_final = read_image/255.0  #here, we are normalizing the images\n",
    "        batch_images.append(read_image_final)\n",
    "        \n",
    "        batch_labels.append(TrainCombined_Labels[TrainCombined_batch_pointer + i]) #appending corresponding labels\n",
    "        \n",
    "    TrainCombined_batch_pointer += batch_size\n",
    "        \n",
    "    return np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Creating bottleneck features for batch 1\n",
      "Bottleneck features for batch 1 created and saved\n",
      "\n",
      "Batch 2 loaded\n",
      "Creating bottleneck features for batch 2\n",
      "Bottleneck features for batch 2 created and saved\n",
      "\n",
      "Batch 3 loaded\n",
      "Creating bottleneck features for batch 3\n",
      "Bottleneck features for batch 3 created and saved\n",
      "\n",
      "Batch 4 loaded\n",
      "Creating bottleneck features for batch 4\n",
      "Bottleneck features for batch 4 created and saved\n",
      "\n",
      "Batch 5 loaded\n",
      "Creating bottleneck features for batch 5\n",
      "Bottleneck features for batch 5 created and saved\n",
      "\n",
      "Batch 6 loaded\n",
      "Creating bottleneck features for batch 6\n",
      "Bottleneck features for batch 6 created and saved\n",
      "\n",
      "Batch 7 loaded\n",
      "Creating bottleneck features for batch 7\n",
      "Bottleneck features for batch 7 created and saved\n",
      "\n",
      "Batch 8 loaded\n",
      "Creating bottleneck features for batch 8\n",
      "Bottleneck features for batch 8 created and saved\n",
      "\n",
      "Batch 9 loaded\n",
      "Creating bottleneck features for batch 9\n",
      "Bottleneck features for batch 9 created and saved\n",
      "\n",
      "Batch 10 loaded\n",
      "Creating bottleneck features for batch 10\n",
      "Bottleneck features for batch 10 created and saved\n",
      "\n",
      "Batch 11 loaded\n",
      "Creating bottleneck features for batch 11\n",
      "Bottleneck features for batch 11 created and saved\n",
      "\n",
      "Batch 12 loaded\n",
      "Creating bottleneck features for batch 12\n",
      "Bottleneck features for batch 12 created and saved\n",
      "\n",
      "Batch 13 loaded\n",
      "Creating bottleneck features for batch 13\n",
      "Bottleneck features for batch 13 created and saved\n",
      "\n",
      "Batch 14 loaded\n",
      "Creating bottleneck features for batch 14\n",
      "Bottleneck features for batch 14 created and saved\n",
      "\n",
      "Batch 15 loaded\n",
      "Creating bottleneck features for batch 15\n",
      "Bottleneck features for batch 15 created and saved\n",
      "\n",
      "Batch 16 loaded\n",
      "Creating bottleneck features for batch 16\n",
      "Bottleneck features for batch 16 created and saved\n",
      "\n",
      "Batch 17 loaded\n",
      "Creating bottleneck features for batch 17\n",
      "Bottleneck features for batch 17 created and saved\n",
      "\n",
      "Batch 18 loaded\n",
      "Creating bottleneck features for batch 18\n",
      "Bottleneck features for batch 18 created and saved\n",
      "\n",
      "Batch 19 loaded\n",
      "Creating bottleneck features for batch 19\n",
      "Bottleneck features for batch 19 created and saved\n",
      "\n",
      "Batch 20 loaded\n",
      "Creating bottleneck features for batch 20\n",
      "Bottleneck features for batch 20 created and saved\n",
      "\n",
      "Batch 21 loaded\n",
      "Creating bottleneck features for batch 21\n",
      "Bottleneck features for batch 21 created and saved\n",
      "\n",
      "Batch 22 loaded\n",
      "Creating bottleneck features for batch 22\n",
      "Bottleneck features for batch 22 created and saved\n",
      "\n",
      "Batch 23 loaded\n",
      "Creating bottleneck features for batch 23\n",
      "Bottleneck features for batch 23 created and saved\n",
      "\n",
      "Batch 24 loaded\n",
      "Creating bottleneck features for batch 24\n",
      "Bottleneck features for batch 24 created and saved\n",
      "\n",
      "Batch 25 loaded\n",
      "Creating bottleneck features for batch 25\n",
      "Bottleneck features for batch 25 created and saved\n",
      "\n",
      "Batch 26 loaded\n",
      "Creating bottleneck features for batch 26\n",
      "Bottleneck features for batch 26 created and saved\n",
      "\n",
      "Batch 27 loaded\n",
      "Creating bottleneck features for batch 27\n",
      "Bottleneck features for batch 27 created and saved\n",
      "\n",
      "Batch 28 loaded\n",
      "Creating bottleneck features for batch 28\n",
      "Bottleneck features for batch 28 created and saved\n",
      "\n",
      "Batch 29 loaded\n",
      "Creating bottleneck features for batch 29\n",
      "Bottleneck features for batch 29 created and saved\n",
      "\n",
      "Batch 30 loaded\n",
      "Creating bottleneck features for batch 30\n",
      "Bottleneck features for batch 30 created and saved\n",
      "\n",
      "Batch 31 loaded\n",
      "Creating bottleneck features for batch 31\n",
      "Bottleneck features for batch 31 created and saved\n",
      "\n",
      "Batch 32 loaded\n",
      "Creating bottleneck features for batch 32\n",
      "Bottleneck features for batch 32 created and saved\n",
      "\n",
      "Batch 33 loaded\n",
      "Creating bottleneck features for batch 33\n",
      "Bottleneck features for batch 33 created and saved\n",
      "\n",
      "Batch 34 loaded\n",
      "Creating bottleneck features for batch 34\n",
      "Bottleneck features for batch 34 created and saved\n",
      "\n",
      "Batch 35 loaded\n",
      "Creating bottleneck features for batch 35\n",
      "Bottleneck features for batch 35 created and saved\n",
      "\n",
      "Batch 36 loaded\n",
      "Creating bottleneck features for batch 36\n",
      "Bottleneck features for batch 36 created and saved\n",
      "\n",
      "Batch 37 loaded\n",
      "Creating bottleneck features for batch 37\n",
      "Bottleneck features for batch 37 created and saved\n",
      "\n",
      "Batch 38 loaded\n",
      "Creating bottleneck features for batch 38\n",
      "Bottleneck features for batch 38 created and saved\n",
      "\n",
      "Batch 39 loaded\n",
      "Creating bottleneck features for batch 39\n",
      "Bottleneck features for batch 39 created and saved\n",
      "\n",
      "Batch 40 loaded\n",
      "Creating bottleneck features for batch 40\n",
      "Bottleneck features for batch 40 created and saved\n",
      "\n",
      "Batch 41 loaded\n",
      "Creating bottleneck features for batch 41\n",
      "Bottleneck features for batch 41 created and saved\n",
      "\n",
      "Batch 42 loaded\n",
      "Creating bottleneck features for batch 42\n",
      "Bottleneck features for batch 42 created and saved\n",
      "\n",
      "Batch 43 loaded\n",
      "Creating bottleneck features for batch 43\n",
      "Bottleneck features for batch 43 created and saved\n",
      "\n",
      "Batch 44 loaded\n",
      "Creating bottleneck features for batch 44\n",
      "Bottleneck features for batch 44 created and saved\n",
      "\n",
      "Batch 45 loaded\n",
      "Creating bottleneck features for batch 45\n",
      "Bottleneck features for batch 45 created and saved\n",
      "\n",
      "Batch 46 loaded\n",
      "Creating bottleneck features for batch 46\n",
      "Bottleneck features for batch 46 created and saved\n",
      "\n",
      "Batch 47 loaded\n",
      "Creating bottleneck features for batch 47\n",
      "Bottleneck features for batch 47 created and saved\n",
      "\n",
      "Batch 48 loaded\n",
      "Creating bottleneck features for batch 48\n",
      "Bottleneck features for batch 48 created and saved\n",
      "\n",
      "Batch 49 loaded\n",
      "Creating bottleneck features for batch 49\n",
      "Bottleneck features for batch 49 created and saved\n",
      "\n",
      "Batch 50 loaded\n",
      "Creating bottleneck features for batch 50\n",
      "Bottleneck features for batch 50 created and saved\n",
      "\n",
      "Batch 51 loaded\n",
      "Creating bottleneck features for batch 51\n",
      "Bottleneck features for batch 51 created and saved\n",
      "\n",
      "Batch 52 loaded\n",
      "Creating bottleneck features for batch 52\n",
      "Bottleneck features for batch 52 created and saved\n",
      "\n",
      "Batch 53 loaded\n",
      "Creating bottleneck features for batch 53\n",
      "Bottleneck features for batch 53 created and saved\n",
      "\n",
      "Batch 54 loaded\n",
      "Creating bottleneck features for batch 54\n",
      "Bottleneck features for batch 54 created and saved\n",
      "\n",
      "Batch 55 loaded\n",
      "Creating bottleneck features for batch 55\n",
      "Bottleneck features for batch 55 created and saved\n",
      "\n",
      "Batch 56 loaded\n",
      "Creating bottleneck features for batch 56\n",
      "Bottleneck features for batch 56 created and saved\n",
      "\n",
      "Batch 57 loaded\n",
      "Creating bottleneck features for batch 57\n",
      "Bottleneck features for batch 57 created and saved\n",
      "\n",
      "Batch 58 loaded\n",
      "Creating bottleneck features for batch 58\n",
      "Bottleneck features for batch 58 created and saved\n",
      "\n",
      "Batch 59 loaded\n",
      "Creating bottleneck features for batch 59\n",
      "Bottleneck features for batch 59 created and saved\n",
      "\n",
      "Batch 60 loaded\n",
      "Creating bottleneck features for batch 60\n",
      "Bottleneck features for batch 60 created and saved\n",
      "\n",
      "Batch 61 loaded\n",
      "Creating bottleneck features for batch 61\n",
      "Bottleneck features for batch 61 created and saved\n",
      "\n",
      "Batch 62 loaded\n",
      "Creating bottleneck features for batch 62\n",
      "Bottleneck features for batch 62 created and saved\n",
      "\n",
      "Batch 63 loaded\n",
      "Creating bottleneck features for batch 63\n",
      "Bottleneck features for batch 63 created and saved\n",
      "\n",
      "Batch 64 loaded\n",
      "Creating bottleneck features for batch 64\n",
      "Bottleneck features for batch 64 created and saved\n",
      "\n",
      "Batch 65 loaded\n",
      "Creating bottleneck features for batch 65\n",
      "Bottleneck features for batch 65 created and saved\n",
      "\n",
      "Batch 66 loaded\n",
      "Creating bottleneck features for batch 66\n",
      "Bottleneck features for batch 66 created and saved\n",
      "\n",
      "Batch 67 loaded\n",
      "Creating bottleneck features for batch 67\n",
      "Bottleneck features for batch 67 created and saved\n",
      "\n",
      "Batch 68 loaded\n",
      "Creating bottleneck features for batch 68\n",
      "Bottleneck features for batch 68 created and saved\n",
      "\n",
      "Batch 69 loaded\n",
      "Creating bottleneck features for batch 69\n",
      "Bottleneck features for batch 69 created and saved\n",
      "\n",
      "Batch 70 loaded\n",
      "Creating bottleneck features for batch 70\n",
      "Bottleneck features for batch 70 created and saved\n",
      "\n",
      "Batch 71 loaded\n",
      "Creating bottleneck features for batch 71\n",
      "Bottleneck features for batch 71 created and saved\n",
      "\n",
      "Batch 72 loaded\n",
      "Creating bottleneck features for batch 72\n",
      "Bottleneck features for batch 72 created and saved\n",
      "\n",
      "Batch 73 loaded\n",
      "Creating bottleneck features for batch 73\n",
      "Bottleneck features for batch 73 created and saved\n",
      "\n",
      "Batch 74 loaded\n",
      "Creating bottleneck features for batch 74\n",
      "Bottleneck features for batch 74 created and saved\n",
      "\n",
      "Batch 75 loaded\n",
      "Creating bottleneck features for batch 75\n",
      "Bottleneck features for batch 75 created and saved\n",
      "\n",
      "Batch 76 loaded\n",
      "Creating bottleneck features for batch 76\n",
      "Bottleneck features for batch 76 created and saved\n",
      "\n",
      "Batch 77 loaded\n",
      "Creating bottleneck features for batch 77\n",
      "Bottleneck features for batch 77 created and saved\n",
      "\n",
      "Batch 78 loaded\n",
      "Creating bottleneck features for batch 78\n",
      "Bottleneck features for batch 78 created and saved\n",
      "\n",
      "Batch 79 loaded\n",
      "Creating bottleneck features for batch 79\n",
      "Bottleneck features for batch 79 created and saved\n",
      "\n",
      "Batch 80 loaded\n",
      "Creating bottleneck features for batch 80\n",
      "Bottleneck features for batch 80 created and saved\n",
      "\n",
      "Batch 81 loaded\n",
      "Creating bottleneck features for batch 81\n",
      "Bottleneck features for batch 81 created and saved\n",
      "\n",
      "Batch 82 loaded\n",
      "Creating bottleneck features for batch 82\n",
      "Bottleneck features for batch 82 created and saved\n",
      "\n",
      "Batch 83 loaded\n",
      "Creating bottleneck features for batch 83\n",
      "Bottleneck features for batch 83 created and saved\n",
      "\n",
      "Batch 84 loaded\n",
      "Creating bottleneck features for batch 84\n",
      "Bottleneck features for batch 84 created and saved\n",
      "\n",
      "Batch 85 loaded\n",
      "Creating bottleneck features for batch 85\n",
      "Bottleneck features for batch 85 created and saved\n",
      "\n",
      "Batch 86 loaded\n",
      "Creating bottleneck features for batch 86\n",
      "Bottleneck features for batch 86 created and saved\n",
      "\n",
      "Batch 87 loaded\n",
      "Creating bottleneck features for batch 87\n",
      "Bottleneck features for batch 87 created and saved\n",
      "\n",
      "Batch 88 loaded\n",
      "Creating bottleneck features for batch 88\n",
      "Bottleneck features for batch 88 created and saved\n",
      "\n",
      "Batch 89 loaded\n",
      "Creating bottleneck features for batch 89\n",
      "Bottleneck features for batch 89 created and saved\n",
      "\n",
      "Batch 90 loaded\n",
      "Creating bottleneck features for batch 90\n",
      "Bottleneck features for batch 90 created and saved\n",
      "\n",
      "Batch 91 loaded\n",
      "Creating bottleneck features for batch 91\n",
      "Bottleneck features for batch 91 created and saved\n",
      "\n",
      "Batch 92 loaded\n",
      "Creating bottleneck features for batch 92\n",
      "Bottleneck features for batch 92 created and saved\n",
      "\n",
      "Batch 93 loaded\n",
      "Creating bottleneck features for batch 93\n",
      "Bottleneck features for batch 93 created and saved\n",
      "\n",
      "Batch 94 loaded\n",
      "Creating bottleneck features for batch 94\n",
      "Bottleneck features for batch 94 created and saved\n",
      "\n",
      "Batch 95 loaded\n",
      "Creating bottleneck features for batch 95\n",
      "Bottleneck features for batch 95 created and saved\n",
      "\n",
      "Batch 96 loaded\n",
      "Creating bottleneck features for batch 96\n",
      "Bottleneck features for batch 96 created and saved\n",
      "\n",
      "Batch 97 loaded\n",
      "Creating bottleneck features for batch 97\n",
      "Bottleneck features for batch 97 created and saved\n",
      "\n",
      "Batch 98 loaded\n",
      "Creating bottleneck features for batch 98\n",
      "Bottleneck features for batch 98 created and saved\n",
      "\n",
      "Batch 99 loaded\n",
      "Creating bottleneck features for batch 99\n",
      "Bottleneck features for batch 99 created and saved\n",
      "\n",
      "Batch 100 loaded\n",
      "Creating bottleneck features for batch 100\n",
      "Bottleneck features for batch 100 created and saved\n",
      "\n",
      "Batch 101 loaded\n",
      "Creating bottleneck features for batch 101\n",
      "Bottleneck features for batch 101 created and saved\n",
      "\n",
      "Batch 102 loaded\n",
      "Creating bottleneck features for batch 102\n",
      "Bottleneck features for batch 102 created and saved\n",
      "\n",
      "Batch 103 loaded\n",
      "Creating bottleneck features for batch 103\n",
      "Bottleneck features for batch 103 created and saved\n",
      "\n",
      "Batch 104 loaded\n",
      "Creating bottleneck features for batch 104\n",
      "Bottleneck features for batch 104 created and saved\n",
      "\n",
      "Batch 105 loaded\n",
      "Creating bottleneck features for batch 105\n",
      "Bottleneck features for batch 105 created and saved\n",
      "\n",
      "Batch 106 loaded\n",
      "Creating bottleneck features for batch 106\n",
      "Bottleneck features for batch 106 created and saved\n",
      "\n",
      "Batch 107 loaded\n",
      "Creating bottleneck features for batch 107\n",
      "Bottleneck features for batch 107 created and saved\n",
      "\n",
      "Batch 108 loaded\n",
      "Creating bottleneck features for batch 108\n",
      "Bottleneck features for batch 108 created and saved\n",
      "\n",
      "Batch 109 loaded\n",
      "Creating bottleneck features for batch 109\n",
      "Bottleneck features for batch 109 created and saved\n",
      "\n",
      "Batch 110 loaded\n",
      "Creating bottleneck features for batch 110\n",
      "Bottleneck features for batch 110 created and saved\n",
      "\n",
      "Batch 111 loaded\n",
      "Creating bottleneck features for batch 111\n",
      "Bottleneck features for batch 111 created and saved\n",
      "\n",
      "Batch 112 loaded\n",
      "Creating bottleneck features for batch 112\n",
      "Bottleneck features for batch 112 created and saved\n",
      "\n",
      "Batch 113 loaded\n",
      "Creating bottleneck features for batch 113\n",
      "Bottleneck features for batch 113 created and saved\n",
      "\n",
      "Batch 114 loaded\n",
      "Creating bottleneck features for batch 114\n",
      "Bottleneck features for batch 114 created and saved\n",
      "\n",
      "Batch 115 loaded\n",
      "Creating bottleneck features for batch 115\n",
      "Bottleneck features for batch 115 created and saved\n",
      "\n",
      "Batch 116 loaded\n",
      "Creating bottleneck features for batch 116\n",
      "Bottleneck features for batch 116 created and saved\n",
      "\n",
      "Batch 117 loaded\n",
      "Creating bottleneck features for batch 117\n",
      "Bottleneck features for batch 117 created and saved\n",
      "\n",
      "Batch 118 loaded\n",
      "Creating bottleneck features for batch 118\n",
      "Bottleneck features for batch 118 created and saved\n",
      "\n",
      "Batch 119 loaded\n",
      "Creating bottleneck features for batch 119\n",
      "Bottleneck features for batch 119 created and saved\n",
      "\n",
      "Batch 120 loaded\n",
      "Creating bottleneck features for batch 120\n",
      "Bottleneck features for batch 120 created and saved\n",
      "\n",
      "Batch 121 loaded\n",
      "Creating bottleneck features for batch 121\n",
      "Bottleneck features for batch 121 created and saved\n",
      "\n",
      "Batch 122 loaded\n",
      "Creating bottleneck features for batch 122\n",
      "Bottleneck features for batch 122 created and saved\n",
      "\n",
      "Batch 123 loaded\n",
      "Creating bottleneck features for batch 123\n",
      "Bottleneck features for batch 123 created and saved\n",
      "\n",
      "Batch 124 loaded\n",
      "Creating bottleneck features for batch 124\n",
      "Bottleneck features for batch 124 created and saved\n",
      "\n",
      "Batch 125 loaded\n",
      "Creating bottleneck features for batch 125\n",
      "Bottleneck features for batch 125 created and saved\n",
      "\n",
      "Batch 126 loaded\n",
      "Creating bottleneck features for batch 126\n",
      "Bottleneck features for batch 126 created and saved\n",
      "\n",
      "Batch 127 loaded\n",
      "Creating bottleneck features for batch 127\n",
      "Bottleneck features for batch 127 created and saved\n",
      "\n",
      "Batch 128 loaded\n",
      "Creating bottleneck features for batch 128\n",
      "Bottleneck features for batch 128 created and saved\n",
      "\n",
      "Batch 129 loaded\n",
      "Creating bottleneck features for batch 129\n",
      "Bottleneck features for batch 129 created and saved\n",
      "\n",
      "Batch 130 loaded\n",
      "Creating bottleneck features for batch 130\n",
      "Bottleneck features for batch 130 created and saved\n",
      "\n",
      "Batch 131 loaded\n",
      "Creating bottleneck features for batch 131\n",
      "Bottleneck features for batch 131 created and saved\n",
      "\n",
      "Batch 132 loaded\n",
      "Creating bottleneck features for batch 132\n",
      "Bottleneck features for batch 132 created and saved\n",
      "\n",
      "Batch 133 loaded\n",
      "Creating bottleneck features for batch 133\n",
      "Bottleneck features for batch 133 created and saved\n",
      "\n",
      "Batch 134 loaded\n",
      "Creating bottleneck features for batch 134\n",
      "Bottleneck features for batch 134 created and saved\n",
      "\n",
      "Batch 135 loaded\n",
      "Creating bottleneck features for batch 135\n",
      "Bottleneck features for batch 135 created and saved\n",
      "\n",
      "Batch 136 loaded\n",
      "Creating bottleneck features for batch 136\n",
      "Bottleneck features for batch 136 created and saved\n",
      "\n",
      "Batch 137 loaded\n",
      "Creating bottleneck features for batch 137\n",
      "Bottleneck features for batch 137 created and saved\n",
      "\n",
      "Batch 138 loaded\n",
      "Creating bottleneck features for batch 138\n",
      "Bottleneck features for batch 138 created and saved\n",
      "\n",
      "Batch 139 loaded\n",
      "Creating bottleneck features for batch 139\n",
      "Bottleneck features for batch 139 created and saved\n",
      "\n",
      "Batch 140 loaded\n",
      "Creating bottleneck features for batch 140\n",
      "Bottleneck features for batch 140 created and saved\n",
      "\n",
      "Batch 141 loaded\n",
      "Creating bottleneck features for batch 141\n",
      "Bottleneck features for batch 141 created and saved\n",
      "\n",
      "Batch 142 loaded\n",
      "Creating bottleneck features for batch 142\n",
      "Bottleneck features for batch 142 created and saved\n",
      "\n",
      "Batch 143 loaded\n",
      "Creating bottleneck features for batch 143\n",
      "Bottleneck features for batch 143 created and saved\n",
      "\n",
      "Batch 144 loaded\n",
      "Creating bottleneck features for batch 144\n",
      "Bottleneck features for batch 144 created and saved\n",
      "\n",
      "Batch 145 loaded\n",
      "Creating bottleneck features for batch 145\n",
      "Bottleneck features for batch 145 created and saved\n",
      "\n",
      "Batch 146 loaded\n",
      "Creating bottleneck features for batch 146\n",
      "Bottleneck features for batch 146 created and saved\n",
      "\n",
      "Batch 147 loaded\n",
      "Creating bottleneck features for batch 147\n",
      "Bottleneck features for batch 147 created and saved\n",
      "\n",
      "Batch 148 loaded\n",
      "Creating bottleneck features for batch 148\n",
      "Bottleneck features for batch 148 created and saved\n",
      "\n",
      "Batch 149 loaded\n",
      "Creating bottleneck features for batch 149\n",
      "Bottleneck features for batch 149 created and saved\n",
      "\n",
      "Batch 150 loaded\n",
      "Creating bottleneck features for batch 150\n",
      "Bottleneck features for batch 150 created and saved\n",
      "\n",
      "Batch 151 loaded\n",
      "Creating bottleneck features for batch 151\n",
      "Bottleneck features for batch 151 created and saved\n",
      "\n",
      "Batch 152 loaded\n",
      "Creating bottleneck features for batch 152\n",
      "Bottleneck features for batch 152 created and saved\n",
      "\n",
      "Batch 153 loaded\n",
      "Creating bottleneck features for batch 153\n",
      "Bottleneck features for batch 153 created and saved\n",
      "\n",
      "Batch 154 loaded\n",
      "Creating bottleneck features for batch 154\n",
      "Bottleneck features for batch 154 created and saved\n",
      "\n",
      "Batch 155 loaded\n",
      "Creating bottleneck features for batch 155\n",
      "Bottleneck features for batch 155 created and saved\n",
      "\n",
      "Batch 156 loaded\n",
      "Creating bottleneck features for batch 156\n",
      "Bottleneck features for batch 156 created and saved\n",
      "\n",
      "Batch 157 loaded\n",
      "Creating bottleneck features for batch 157\n",
      "Bottleneck features for batch 157 created and saved\n",
      "\n",
      "Batch 158 loaded\n",
      "Creating bottleneck features for batch 158\n",
      "Bottleneck features for batch 158 created and saved\n",
      "\n",
      "Batch 159 loaded\n",
      "Creating bottleneck features for batch 159\n",
      "Bottleneck features for batch 159 created and saved\n",
      "\n",
      "Batch 160 loaded\n",
      "Creating bottleneck features for batch 160\n",
      "Bottleneck features for batch 160 created and saved\n",
      "\n",
      "Batch 161 loaded\n",
      "Creating bottleneck features for batch 161\n",
      "Bottleneck features for batch 161 created and saved\n",
      "\n",
      "Batch 162 loaded\n",
      "Creating bottleneck features for batch 162\n",
      "Bottleneck features for batch 162 created and saved\n",
      "\n",
      "Batch 163 loaded\n",
      "Creating bottleneck features for batch 163\n",
      "Bottleneck features for batch 163 created and saved\n",
      "\n",
      "Batch 164 loaded\n",
      "Creating bottleneck features for batch 164\n",
      "Bottleneck features for batch 164 created and saved\n",
      "\n",
      "Batch 165 loaded\n",
      "Creating bottleneck features for batch 165\n",
      "Bottleneck features for batch 165 created and saved\n",
      "\n",
      "Batch 166 loaded\n",
      "Creating bottleneck features for batch 166\n",
      "Bottleneck features for batch 166 created and saved\n",
      "\n",
      "Batch 167 loaded\n",
      "Creating bottleneck features for batch 167\n",
      "Bottleneck features for batch 167 created and saved\n",
      "\n",
      "Batch 168 loaded\n",
      "Creating bottleneck features for batch 168\n",
      "Bottleneck features for batch 168 created and saved\n",
      "\n",
      "Batch 169 loaded\n",
      "Creating bottleneck features for batch 169\n",
      "Bottleneck features for batch 169 created and saved\n",
      "\n",
      "Batch 170 loaded\n",
      "Creating bottleneck features for batch 170\n",
      "Bottleneck features for batch 170 created and saved\n",
      "\n",
      "Batch 171 loaded\n",
      "Creating bottleneck features for batch 171\n",
      "Bottleneck features for batch 171 created and saved\n",
      "\n",
      "Batch 172 loaded\n",
      "Creating bottleneck features for batch 172\n",
      "Bottleneck features for batch 172 created and saved\n",
      "\n",
      "Batch 173 loaded\n",
      "Creating bottleneck features for batch 173\n",
      "Bottleneck features for batch 173 created and saved\n",
      "\n",
      "Batch 174 loaded\n",
      "Creating bottleneck features for batch 174\n",
      "Bottleneck features for batch 174 created and saved\n",
      "\n",
      "Batch 175 loaded\n",
      "Creating bottleneck features for batch 175\n",
      "Bottleneck features for batch 175 created and saved\n",
      "\n",
      "Batch 176 loaded\n",
      "Creating bottleneck features for batch 176\n",
      "Bottleneck features for batch 176 created and saved\n",
      "\n",
      "Batch 177 loaded\n",
      "Creating bottleneck features for batch 177\n",
      "Bottleneck features for batch 177 created and saved\n",
      "\n",
      "Batch 178 loaded\n",
      "Creating bottleneck features for batch 178\n",
      "Bottleneck features for batch 178 created and saved\n",
      "\n",
      "Batch 179 loaded\n",
      "Creating bottleneck features for batch 179\n",
      "Bottleneck features for batch 179 created and saved\n",
      "\n",
      "Batch 180 loaded\n",
      "Creating bottleneck features for batch 180\n",
      "Bottleneck features for batch 180 created and saved\n",
      "\n",
      "Batch 181 loaded\n",
      "Creating bottleneck features for batch 181\n",
      "Bottleneck features for batch 181 created and saved\n",
      "\n",
      "Batch 182 loaded\n",
      "Creating bottleneck features for batch 182\n",
      "Bottleneck features for batch 182 created and saved\n",
      "\n",
      "Batch 183 loaded\n",
      "Creating bottleneck features for batch 183\n",
      "Bottleneck features for batch 183 created and saved\n",
      "\n",
      "Batch 184 loaded\n",
      "Creating bottleneck features for batch 184\n",
      "Bottleneck features for batch 184 created and saved\n",
      "\n",
      "Batch 185 loaded\n",
      "Creating bottleneck features for batch 185\n",
      "Bottleneck features for batch 185 created and saved\n",
      "\n",
      "Batch 186 loaded\n",
      "Creating bottleneck features for batch 186\n",
      "Bottleneck features for batch 186 created and saved\n",
      "\n",
      "Batch 187 loaded\n",
      "Creating bottleneck features for batch 187\n",
      "Bottleneck features for batch 187 created and saved\n",
      "\n",
      "Batch 188 loaded\n",
      "Creating bottleneck features for batch 188\n",
      "Bottleneck features for batch 188 created and saved\n",
      "\n",
      "Batch 189 loaded\n",
      "Creating bottleneck features for batch 189\n",
      "Bottleneck features for batch 189 created and saved\n",
      "\n",
      "Batch 190 loaded\n",
      "Creating bottleneck features for batch 190\n",
      "Bottleneck features for batch 190 created and saved\n",
      "\n",
      "Batch 191 loaded\n",
      "Creating bottleneck features for batch 191\n",
      "Bottleneck features for batch 191 created and saved\n",
      "\n",
      "Batch 192 loaded\n",
      "Creating bottleneck features for batch 192\n",
      "Bottleneck features for batch 192 created and saved\n",
      "\n",
      "Batch 193 loaded\n",
      "Creating bottleneck features for batch 193\n",
      "Bottleneck features for batch 193 created and saved\n",
      "\n",
      "Batch 194 loaded\n",
      "Creating bottleneck features for batch 194\n",
      "Bottleneck features for batch 194 created and saved\n",
      "\n",
      "Batch 195 loaded\n",
      "Creating bottleneck features for batch 195\n",
      "Bottleneck features for batch 195 created and saved\n",
      "\n",
      "Batch 196 loaded\n",
      "Creating bottleneck features for batch 196\n",
      "Bottleneck features for batch 196 created and saved\n",
      "\n",
      "Batch 197 loaded\n",
      "Creating bottleneck features for batch 197\n",
      "Bottleneck features for batch 197 created and saved\n",
      "\n",
      "Batch 198 loaded\n",
      "Creating bottleneck features for batch 198\n",
      "Bottleneck features for batch 198 created and saved\n",
      "\n",
      "Batch 199 loaded\n",
      "Creating bottleneck features for batch 199\n",
      "Bottleneck features for batch 199 created and saved\n",
      "\n",
      "Batch 200 loaded\n",
      "Creating bottleneck features for batch 200\n",
      "Bottleneck features for batch 200 created and saved\n",
      "\n",
      "Batch 201 loaded\n",
      "Creating bottleneck features for batch 201\n",
      "Bottleneck features for batch 201 created and saved\n",
      "\n",
      "Batch 202 loaded\n",
      "Creating bottleneck features for batch 202\n",
      "Bottleneck features for batch 202 created and saved\n",
      "\n",
      "Batch 203 loaded\n",
      "Creating bottleneck features for batch 203\n",
      "Bottleneck features for batch 203 created and saved\n",
      "\n",
      "Batch 204 loaded\n",
      "Creating bottleneck features for batch 204\n",
      "Bottleneck features for batch 204 created and saved\n",
      "\n",
      "Batch 205 loaded\n",
      "Creating bottleneck features for batch 205\n",
      "Bottleneck features for batch 205 created and saved\n",
      "\n",
      "Batch 206 loaded\n",
      "Creating bottleneck features for batch 206\n",
      "Bottleneck features for batch 206 created and saved\n",
      "\n",
      "Batch 207 loaded\n",
      "Creating bottleneck features for batch 207\n",
      "Bottleneck features for batch 207 created and saved\n",
      "\n",
      "Batch 208 loaded\n",
      "Creating bottleneck features for batch 208\n",
      "Bottleneck features for batch 208 created and saved\n",
      "\n",
      "Batch 209 loaded\n",
      "Creating bottleneck features for batch 209\n",
      "Bottleneck features for batch 209 created and saved\n",
      "\n",
      "Batch 210 loaded\n",
      "Creating bottleneck features for batch 210\n",
      "Bottleneck features for batch 210 created and saved\n",
      "\n",
      "Batch 211 loaded\n",
      "Creating bottleneck features for batch 211\n",
      "Bottleneck features for batch 211 created and saved\n",
      "\n",
      "Batch 212 loaded\n",
      "Creating bottleneck features for batch 212\n",
      "Bottleneck features for batch 212 created and saved\n",
      "\n",
      "Batch 213 loaded\n",
      "Creating bottleneck features for batch 213\n",
      "Bottleneck features for batch 213 created and saved\n",
      "\n",
      "Batch 214 loaded\n",
      "Creating bottleneck features for batch 214\n",
      "Bottleneck features for batch 214 created and saved\n",
      "\n",
      "Batch 215 loaded\n",
      "Creating bottleneck features for batch 215\n",
      "Bottleneck features for batch 215 created and saved\n",
      "\n",
      "Batch 216 loaded\n",
      "Creating bottleneck features for batch 216\n",
      "Bottleneck features for batch 216 created and saved\n",
      "\n",
      "Batch 217 loaded\n",
      "Creating bottleneck features for batch 217\n",
      "Bottleneck features for batch 217 created and saved\n",
      "\n",
      "Batch 218 loaded\n",
      "Creating bottleneck features for batch 218\n",
      "Bottleneck features for batch 218 created and saved\n",
      "\n",
      "Batch 219 loaded\n",
      "Creating bottleneck features for batch 219\n",
      "Bottleneck features for batch 219 created and saved\n",
      "\n",
      "Batch 220 loaded\n",
      "Creating bottleneck features for batch 220\n",
      "Bottleneck features for batch 220 created and saved\n",
      "\n",
      "Batch 221 loaded\n",
      "Creating bottleneck features for batch 221\n",
      "Bottleneck features for batch 221 created and saved\n",
      "\n",
      "Batch 222 loaded\n",
      "Creating bottleneck features for batch 222\n",
      "Bottleneck features for batch 222 created and saved\n",
      "\n",
      "Batch 223 loaded\n",
      "Creating bottleneck features for batch 223\n",
      "Bottleneck features for batch 223 created and saved\n",
      "\n",
      "Batch 224 loaded\n",
      "Creating bottleneck features for batch 224\n",
      "Bottleneck features for batch 224 created and saved\n",
      "\n",
      "Batch 225 loaded\n",
      "Creating bottleneck features for batch 225\n",
      "Bottleneck features for batch 225 created and saved\n",
      "\n",
      "Batch 226 loaded\n",
      "Creating bottleneck features for batch 226\n",
      "Bottleneck features for batch 226 created and saved\n",
      "\n",
      "Batch 227 loaded\n",
      "Creating bottleneck features for batch 227\n",
      "Bottleneck features for batch 227 created and saved\n",
      "\n",
      "Batch 228 loaded\n",
      "Creating bottleneck features for batch 228\n",
      "Bottleneck features for batch 228 created and saved\n",
      "\n",
      "Batch 229 loaded\n",
      "Creating bottleneck features for batch 229\n",
      "Bottleneck features for batch 229 created and saved\n",
      "\n",
      "Batch 230 loaded\n",
      "Creating bottleneck features for batch 230\n",
      "Bottleneck features for batch 230 created and saved\n",
      "\n",
      "Batch 231 loaded\n",
      "Creating bottleneck features for batch 231\n",
      "Bottleneck features for batch 231 created and saved\n",
      "\n",
      "Batch 232 loaded\n",
      "Creating bottleneck features for batch 232\n",
      "Bottleneck features for batch 232 created and saved\n",
      "\n",
      "Batch 233 loaded\n",
      "Creating bottleneck features for batch 233\n",
      "Bottleneck features for batch 233 created and saved\n",
      "\n",
      "Batch 234 loaded\n",
      "Creating bottleneck features for batch 234\n",
      "Bottleneck features for batch 234 created and saved\n",
      "\n",
      "Batch 235 loaded\n",
      "Creating bottleneck features for batch 235\n",
      "Bottleneck features for batch 235 created and saved\n",
      "\n",
      "Batch 236 loaded\n",
      "Creating bottleneck features for batch 236\n",
      "Bottleneck features for batch 236 created and saved\n",
      "\n",
      "Batch 237 loaded\n",
      "Creating bottleneck features for batch 237\n",
      "Bottleneck features for batch 237 created and saved\n",
      "\n",
      "Batch 238 loaded\n",
      "Creating bottleneck features for batch 238\n",
      "Bottleneck features for batch 238 created and saved\n",
      "\n",
      "Batch 239 loaded\n",
      "Creating bottleneck features for batch 239\n",
      "Bottleneck features for batch 239 created and saved\n",
      "\n",
      "Batch 240 loaded\n",
      "Creating bottleneck features for batch 240\n",
      "Bottleneck features for batch 240 created and saved\n",
      "\n",
      "Batch 241 loaded\n",
      "Creating bottleneck features for batch 241\n",
      "Bottleneck features for batch 241 created and saved\n",
      "\n",
      "Batch 242 loaded\n",
      "Creating bottleneck features for batch 242\n",
      "Bottleneck features for batch 242 created and saved\n",
      "\n",
      "Batch 243 loaded\n",
      "Creating bottleneck features for batch 243\n",
      "Bottleneck features for batch 243 created and saved\n",
      "\n",
      "Batch 244 loaded\n",
      "Creating bottleneck features for batch 244\n",
      "Bottleneck features for batch 244 created and saved\n",
      "\n",
      "Batch 245 loaded\n",
      "Creating bottleneck features for batch 245\n",
      "Bottleneck features for batch 245 created and saved\n",
      "\n",
      "Batch 246 loaded\n",
      "Creating bottleneck features for batch 246\n",
      "Bottleneck features for batch 246 created and saved\n",
      "\n",
      "Batch 247 loaded\n",
      "Creating bottleneck features for batch 247\n",
      "Bottleneck features for batch 247 created and saved\n",
      "\n",
      "Batch 248 loaded\n",
      "Creating bottleneck features for batch 248\n",
      "Bottleneck features for batch 248 created and saved\n",
      "\n",
      "Batch 249 loaded\n",
      "Creating bottleneck features for batch 249\n",
      "Bottleneck features for batch 249 created and saved\n",
      "\n",
      "Batch 250 loaded\n",
      "Creating bottleneck features for batch 250\n",
      "Bottleneck features for batch 250 created and saved\n",
      "\n",
      "Batch 251 loaded\n",
      "Creating bottleneck features for batch 251\n",
      "Bottleneck features for batch 251 created and saved\n",
      "\n",
      "Batch 252 loaded\n",
      "Creating bottleneck features for batch 252\n",
      "Bottleneck features for batch 252 created and saved\n",
      "\n",
      "Batch 253 loaded\n",
      "Creating bottleneck features for batch 253\n",
      "Bottleneck features for batch 253 created and saved\n",
      "\n",
      "Batch 254 loaded\n",
      "Creating bottleneck features for batch 254\n",
      "Bottleneck features for batch 254 created and saved\n",
      "\n",
      "Batch 255 loaded\n",
      "Creating bottleneck features for batch 255\n",
      "Bottleneck features for batch 255 created and saved\n",
      "\n",
      "Batch 256 loaded\n",
      "Creating bottleneck features for batch 256\n",
      "Bottleneck features for batch 256 created and saved\n",
      "\n",
      "Batch 257 loaded\n",
      "Creating bottleneck features for batch 257\n",
      "Bottleneck features for batch 257 created and saved\n",
      "\n",
      "Batch 258 loaded\n",
      "Creating bottleneck features for batch 258\n",
      "Bottleneck features for batch 258 created and saved\n",
      "\n",
      "Batch 259 loaded\n",
      "Creating bottleneck features for batch 259\n",
      "Bottleneck features for batch 259 created and saved\n",
      "\n",
      "Batch 260 loaded\n",
      "Creating bottleneck features for batch 260\n",
      "Bottleneck features for batch 260 created and saved\n",
      "\n",
      "Batch 261 loaded\n",
      "Creating bottleneck features for batch 261\n",
      "Bottleneck features for batch 261 created and saved\n",
      "\n",
      "Batch 262 loaded\n",
      "Creating bottleneck features for batch 262\n",
      "Bottleneck features for batch 262 created and saved\n",
      "\n",
      "Batch 263 loaded\n",
      "Creating bottleneck features for batch 263\n",
      "Bottleneck features for batch 263 created and saved\n",
      "\n",
      "Batch 264 loaded\n",
      "Creating bottleneck features for batch 264\n",
      "Bottleneck features for batch 264 created and saved\n",
      "\n",
      "Batch 265 loaded\n",
      "Creating bottleneck features for batch 265\n",
      "Bottleneck features for batch 265 created and saved\n",
      "\n",
      "Batch 266 loaded\n",
      "Creating bottleneck features for batch 266\n",
      "Bottleneck features for batch 266 created and saved\n",
      "\n",
      "Batch 267 loaded\n",
      "Creating bottleneck features for batch 267\n",
      "Bottleneck features for batch 267 created and saved\n",
      "\n",
      "Batch 268 loaded\n",
      "Creating bottleneck features for batch 268\n",
      "Bottleneck features for batch 268 created and saved\n",
      "\n",
      "Batch 269 loaded\n",
      "Creating bottleneck features for batch 269\n",
      "Bottleneck features for batch 269 created and saved\n",
      "\n",
      "Batch 270 loaded\n",
      "Creating bottleneck features for batch 270\n",
      "Bottleneck features for batch 270 created and saved\n",
      "\n",
      "Batch 271 loaded\n",
      "Creating bottleneck features for batch 271\n",
      "Bottleneck features for batch 271 created and saved\n",
      "\n",
      "Batch 272 loaded\n",
      "Creating bottleneck features for batch 272\n",
      "Bottleneck features for batch 272 created and saved\n",
      "\n",
      "Batch 273 loaded\n",
      "Creating bottleneck features for batch 273\n",
      "Bottleneck features for batch 273 created and saved\n",
      "\n",
      "Batch 274 loaded\n",
      "Creating bottleneck features for batch 274\n",
      "Bottleneck features for batch 274 created and saved\n",
      "\n",
      "Batch 275 loaded\n",
      "Creating bottleneck features for batch 275\n",
      "Bottleneck features for batch 275 created and saved\n",
      "\n",
      "Batch 276 loaded\n",
      "Creating bottleneck features for batch 276\n",
      "Bottleneck features for batch 276 created and saved\n",
      "\n",
      "Batch 277 loaded\n",
      "Creating bottleneck features for batch 277\n",
      "Bottleneck features for batch 277 created and saved\n",
      "\n",
      "Batch 278 loaded\n",
      "Creating bottleneck features for batch 278\n",
      "Bottleneck features for batch 278 created and saved\n",
      "\n",
      "Batch 279 loaded\n",
      "Creating bottleneck features for batch 279\n",
      "Bottleneck features for batch 279 created and saved\n",
      "\n",
      "Batch 280 loaded\n",
      "Creating bottleneck features for batch 280\n",
      "Bottleneck features for batch 280 created and saved\n",
      "\n",
      "Batch 281 loaded\n",
      "Creating bottleneck features for batch 281\n",
      "Bottleneck features for batch 281 created and saved\n",
      "\n",
      "Batch 282 loaded\n",
      "Creating bottleneck features for batch 282\n",
      "Bottleneck features for batch 282 created and saved\n",
      "\n",
      "Batch 283 loaded\n",
      "Creating bottleneck features for batch 283\n",
      "Bottleneck features for batch 283 created and saved\n",
      "\n",
      "Batch 284 loaded\n",
      "Creating bottleneck features for batch 284\n",
      "Bottleneck features for batch 284 created and saved\n",
      "\n",
      "Batch 285 loaded\n",
      "Creating bottleneck features for batch 285\n",
      "Bottleneck features for batch 285 created and saved\n",
      "\n",
      "Batch 286 loaded\n",
      "Creating bottleneck features for batch 286\n",
      "Bottleneck features for batch 286 created and saved\n",
      "\n",
      "Batch 287 loaded\n",
      "Creating bottleneck features for batch 287\n",
      "Bottleneck features for batch 287 created and saved\n",
      "\n",
      "Batch 288 loaded\n",
      "Creating bottleneck features for batch 288\n",
      "Bottleneck features for batch 288 created and saved\n",
      "\n",
      "Batch 289 loaded\n",
      "Creating bottleneck features for batch 289\n",
      "Bottleneck features for batch 289 created and saved\n",
      "\n",
      "Batch 290 loaded\n",
      "Creating bottleneck features for batch 290\n",
      "Bottleneck features for batch 290 created and saved\n",
      "\n",
      "Batch 291 loaded\n",
      "Creating bottleneck features for batch 291\n",
      "Bottleneck features for batch 291 created and saved\n",
      "\n",
      "Batch 292 loaded\n",
      "Creating bottleneck features for batch 292\n",
      "Bottleneck features for batch 292 created and saved\n",
      "\n",
      "Batch 293 loaded\n",
      "Creating bottleneck features for batch 293\n",
      "Bottleneck features for batch 293 created and saved\n",
      "\n",
      "Batch 294 loaded\n",
      "Creating bottleneck features for batch 294\n",
      "Bottleneck features for batch 294 created and saved\n",
      "\n",
      "Batch 295 loaded\n",
      "Creating bottleneck features for batch 295\n",
      "Bottleneck features for batch 295 created and saved\n",
      "\n",
      "Batch 296 loaded\n",
      "Creating bottleneck features for batch 296\n",
      "Bottleneck features for batch 296 created and saved\n",
      "\n",
      "Batch 297 loaded\n",
      "Creating bottleneck features for batch 297\n",
      "Bottleneck features for batch 297 created and saved\n",
      "\n",
      "Batch 298 loaded\n",
      "Creating bottleneck features for batch 298\n",
      "Bottleneck features for batch 298 created and saved\n",
      "\n",
      "Batch 299 loaded\n",
      "Creating bottleneck features for batch 299\n",
      "Bottleneck features for batch 299 created and saved\n",
      "\n",
      "Batch 300 loaded\n",
      "Creating bottleneck features for batch 300\n",
      "Bottleneck features for batch 300 created and saved\n",
      "\n",
      "Batch 301 loaded\n",
      "Creating bottleneck features for batch 301\n",
      "Bottleneck features for batch 301 created and saved\n",
      "\n",
      "Batch 302 loaded\n",
      "Creating bottleneck features for batch 302\n",
      "Bottleneck features for batch 302 created and saved\n",
      "\n",
      "Batch 303 loaded\n",
      "Creating bottleneck features for batch 303\n",
      "Bottleneck features for batch 303 created and saved\n",
      "\n",
      "Batch 304 loaded\n",
      "Creating bottleneck features for batch 304\n",
      "Bottleneck features for batch 304 created and saved\n",
      "\n",
      "Batch 305 loaded\n",
      "Creating bottleneck features for batch 305\n",
      "Bottleneck features for batch 305 created and saved\n",
      "\n",
      "Batch 306 loaded\n",
      "Creating bottleneck features for batch 306\n",
      "Bottleneck features for batch 306 created and saved\n",
      "\n",
      "Batch 307 loaded\n",
      "Creating bottleneck features for batch 307\n",
      "Bottleneck features for batch 307 created and saved\n",
      "\n",
      "Batch 308 loaded\n",
      "Creating bottleneck features for batch 308\n",
      "Bottleneck features for batch 308 created and saved\n",
      "\n",
      "Batch 309 loaded\n",
      "Creating bottleneck features for batch 309\n",
      "Bottleneck features for batch 309 created and saved\n",
      "\n",
      "Batch 310 loaded\n",
      "Creating bottleneck features for batch 310\n",
      "Bottleneck features for batch 310 created and saved\n",
      "\n",
      "Batch 311 loaded\n",
      "Creating bottleneck features for batch 311\n",
      "Bottleneck features for batch 311 created and saved\n",
      "\n",
      "Batch 312 loaded\n",
      "Creating bottleneck features for batch 312\n",
      "Bottleneck features for batch 312 created and saved\n",
      "\n",
      "Batch 313 loaded\n",
      "Creating bottleneck features for batch 313\n",
      "Bottleneck features for batch 313 created and saved\n",
      "\n",
      "Batch 314 loaded\n",
      "Creating bottleneck features for batch 314\n",
      "Bottleneck features for batch 314 created and saved\n",
      "\n",
      "Batch 315 loaded\n",
      "Creating bottleneck features for batch 315\n",
      "Bottleneck features for batch 315 created and saved\n",
      "\n",
      "Batch 316 loaded\n",
      "Creating bottleneck features for batch 316\n",
      "Bottleneck features for batch 316 created and saved\n",
      "\n",
      "Batch 317 loaded\n",
      "Creating bottleneck features for batch 317\n",
      "Bottleneck features for batch 317 created and saved\n",
      "\n",
      "Batch 318 loaded\n",
      "Creating bottleneck features for batch 318\n",
      "Bottleneck features for batch 318 created and saved\n",
      "\n",
      "Batch 319 loaded\n",
      "Creating bottleneck features for batch 319\n",
      "Bottleneck features for batch 319 created and saved\n",
      "\n",
      "Batch 320 loaded\n",
      "Creating bottleneck features for batch 320\n",
      "Bottleneck features for batch 320 created and saved\n",
      "\n",
      "Batch 321 loaded\n",
      "Creating bottleneck features for batch 321\n",
      "Bottleneck features for batch 321 created and saved\n",
      "\n",
      "Batch 322 loaded\n",
      "Creating bottleneck features for batch 322\n",
      "Bottleneck features for batch 322 created and saved\n",
      "\n",
      "Batch 323 loaded\n",
      "Creating bottleneck features for batch 323\n",
      "Bottleneck features for batch 323 created and saved\n",
      "\n",
      "Batch 324 loaded\n",
      "Creating bottleneck features for batch 324\n",
      "Bottleneck features for batch 324 created and saved\n",
      "\n",
      "Batch 325 loaded\n",
      "Creating bottleneck features for batch 325\n",
      "Bottleneck features for batch 325 created and saved\n",
      "\n",
      "Batch 326 loaded\n",
      "Creating bottleneck features for batch 326\n",
      "Bottleneck features for batch 326 created and saved\n",
      "\n",
      "Batch 327 loaded\n",
      "Creating bottleneck features for batch 327\n",
      "Bottleneck features for batch 327 created and saved\n",
      "\n",
      "Batch 328 loaded\n",
      "Creating bottleneck features for batch 328\n",
      "Bottleneck features for batch 328 created and saved\n",
      "\n",
      "Batch 329 loaded\n",
      "Creating bottleneck features for batch 329\n",
      "Bottleneck features for batch 329 created and saved\n",
      "\n",
      "Batch 330 loaded\n",
      "Creating bottleneck features for batch 330\n",
      "Bottleneck features for batch 330 created and saved\n",
      "\n",
      "Batch 331 loaded\n",
      "Creating bottleneck features for batch 331\n",
      "Bottleneck features for batch 331 created and saved\n",
      "\n",
      "Batch 332 loaded\n",
      "Creating bottleneck features for batch 332\n",
      "Bottleneck features for batch 332 created and saved\n",
      "\n",
      "Batch 333 loaded\n",
      "Creating bottleneck features for batch 333\n",
      "Bottleneck features for batch 333 created and saved\n",
      "\n",
      "Batch 334 loaded\n",
      "Creating bottleneck features for batch 334\n",
      "Bottleneck features for batch 334 created and saved\n",
      "\n",
      "Batch 335 loaded\n",
      "Creating bottleneck features for batch 335\n",
      "Bottleneck features for batch 335 created and saved\n",
      "\n",
      "Batch 336 loaded\n",
      "Creating bottleneck features for batch 336\n",
      "Bottleneck features for batch 336 created and saved\n",
      "\n",
      "Batch 337 loaded\n",
      "Creating bottleneck features for batch 337\n",
      "Bottleneck features for batch 337 created and saved\n",
      "\n",
      "Batch 338 loaded\n",
      "Creating bottleneck features for batch 338\n",
      "Bottleneck features for batch 338 created and saved\n",
      "\n",
      "Batch 339 loaded\n",
      "Creating bottleneck features for batch 339\n",
      "Bottleneck features for batch 339 created and saved\n",
      "\n",
      "Batch 340 loaded\n",
      "Creating bottleneck features for batch 340\n",
      "Bottleneck features for batch 340 created and saved\n",
      "\n",
      "Batch 341 loaded\n",
      "Creating bottleneck features for batch 341\n",
      "Bottleneck features for batch 341 created and saved\n",
      "\n",
      "Batch 342 loaded\n",
      "Creating bottleneck features for batch 342\n",
      "Bottleneck features for batch 342 created and saved\n",
      "\n",
      "Batch 343 loaded\n",
      "Creating bottleneck features for batch 343\n",
      "Bottleneck features for batch 343 created and saved\n",
      "\n",
      "Batch 344 loaded\n",
      "Creating bottleneck features for batch 344\n",
      "Bottleneck features for batch 344 created and saved\n",
      "\n",
      "Batch 345 loaded\n",
      "Creating bottleneck features for batch 345\n",
      "Bottleneck features for batch 345 created and saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating bottleneck features for train data using VGG-16- Image-net model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "SAVEDIR = \"../Data/Bottleneck_Features/Bottleneck_CombinedTrain/\"\n",
    "SAVEDIR_LABELS = \"../Data/Bottleneck_Features/CombinedTrain_Labels/\"\n",
    "batch_size = 50\n",
    "for i in range(int(len(Train_Combined)/batch_size)):\n",
    "    x, y = loadCombinedTrainBatch(batch_size)\n",
    "    print(\"Batch {} loaded\".format(i+1))\n",
    "    \n",
    "    np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(i+1)), y)\n",
    "    \n",
    "    print(\"Creating bottleneck features for batch {}\". format(i+1))\n",
    "    bottleneck_features = model.predict(x)\n",
    "    np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(i+1)), bottleneck_features)\n",
    "    print(\"Bottleneck features for batch {} created and saved\\n\".format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck features for CV Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH GOEL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3458, 8)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVHumans_Labels = pd.get_dummies(CV_Humans[\"Labels\"]).as_matrix()\n",
    "CVHumans_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCVHumanBatch(batch_size):\n",
    "    global CVHumans_batch_pointer\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        path1 = CV_Humans.iloc[CVHumans_batch_pointer + i][\"folderName\"]\n",
    "        path2 = CV_Humans.iloc[CVHumans_batch_pointer + i][\"imageName\"]\n",
    "        read_image = cv2.imread(os.path.join(path1, path2))\n",
    "        read_image_final = read_image.resize((48, 48 ,3))\n",
    "        read_image_final = read_image/255.0  #here, we are normalizing the images\n",
    "        batch_images.append(read_image_final)\n",
    "        \n",
    "        batch_labels.append(CVHumans_Labels[CVHumans_batch_pointer + i]) #appending corresponding labels\n",
    "        \n",
    "    CVHumans_batch_pointer += batch_size\n",
    "        \n",
    "    return np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Creating bottleneck features for batch 1\n",
      "Bottleneck features for batch 1 created and saved\n",
      "\n",
      "Batch 2 loaded\n",
      "Creating bottleneck features for batch 2\n",
      "Bottleneck features for batch 2 created and saved\n",
      "\n",
      "Batch 3 loaded\n",
      "Creating bottleneck features for batch 3\n",
      "Bottleneck features for batch 3 created and saved\n",
      "\n",
      "Batch 4 loaded\n",
      "Creating bottleneck features for batch 4\n",
      "Bottleneck features for batch 4 created and saved\n",
      "\n",
      "Batch 5 loaded\n",
      "Creating bottleneck features for batch 5\n",
      "Bottleneck features for batch 5 created and saved\n",
      "\n",
      "Batch 6 loaded\n",
      "Creating bottleneck features for batch 6\n",
      "Bottleneck features for batch 6 created and saved\n",
      "\n",
      "Batch 7 loaded\n",
      "Creating bottleneck features for batch 7\n",
      "Bottleneck features for batch 7 created and saved\n",
      "\n",
      "Batch 8 loaded\n",
      "Creating bottleneck features for batch 8\n",
      "Bottleneck features for batch 8 created and saved\n",
      "\n",
      "Batch 9 loaded\n",
      "Creating bottleneck features for batch 9\n",
      "Bottleneck features for batch 9 created and saved\n",
      "\n",
      "Batch 10 loaded\n",
      "Creating bottleneck features for batch 10\n",
      "Bottleneck features for batch 10 created and saved\n",
      "\n",
      "Batch 11 loaded\n",
      "Creating bottleneck features for batch 11\n",
      "Bottleneck features for batch 11 created and saved\n",
      "\n",
      "Batch 12 loaded\n",
      "Creating bottleneck features for batch 12\n",
      "Bottleneck features for batch 12 created and saved\n",
      "\n",
      "Batch 13 loaded\n",
      "Creating bottleneck features for batch 13\n",
      "Bottleneck features for batch 13 created and saved\n",
      "\n",
      "Batch 14 loaded\n",
      "Creating bottleneck features for batch 14\n",
      "Bottleneck features for batch 14 created and saved\n",
      "\n",
      "Batch 15 loaded\n",
      "Creating bottleneck features for batch 15\n",
      "Bottleneck features for batch 15 created and saved\n",
      "\n",
      "Batch 16 loaded\n",
      "Creating bottleneck features for batch 16\n",
      "Bottleneck features for batch 16 created and saved\n",
      "\n",
      "Batch 17 loaded\n",
      "Creating bottleneck features for batch 17\n",
      "Bottleneck features for batch 17 created and saved\n",
      "\n",
      "Batch 18 loaded\n",
      "Creating bottleneck features for batch 18\n",
      "Bottleneck features for batch 18 created and saved\n",
      "\n",
      "Batch 19 loaded\n",
      "Creating bottleneck features for batch 19\n",
      "Bottleneck features for batch 19 created and saved\n",
      "\n",
      "Batch 20 loaded\n",
      "Creating bottleneck features for batch 20\n",
      "Bottleneck features for batch 20 created and saved\n",
      "\n",
      "Batch 21 loaded\n",
      "Creating bottleneck features for batch 21\n",
      "Bottleneck features for batch 21 created and saved\n",
      "\n",
      "Batch 22 loaded\n",
      "Creating bottleneck features for batch 22\n",
      "Bottleneck features for batch 22 created and saved\n",
      "\n",
      "Batch 23 loaded\n",
      "Creating bottleneck features for batch 23\n",
      "Bottleneck features for batch 23 created and saved\n",
      "\n",
      "Batch 24 loaded\n",
      "Creating bottleneck features for batch 24\n",
      "Bottleneck features for batch 24 created and saved\n",
      "\n",
      "Batch 25 loaded\n",
      "Creating bottleneck features for batch 25\n",
      "Bottleneck features for batch 25 created and saved\n",
      "\n",
      "Batch 26 loaded\n",
      "Creating bottleneck features for batch 26\n",
      "Bottleneck features for batch 26 created and saved\n",
      "\n",
      "Batch 27 loaded\n",
      "Creating bottleneck features for batch 27\n",
      "Bottleneck features for batch 27 created and saved\n",
      "\n",
      "Batch 28 loaded\n",
      "Creating bottleneck features for batch 28\n",
      "Bottleneck features for batch 28 created and saved\n",
      "\n",
      "Batch 29 loaded\n",
      "Creating bottleneck features for batch 29\n",
      "Bottleneck features for batch 29 created and saved\n",
      "\n",
      "Batch 30 loaded\n",
      "Creating bottleneck features for batch 30\n",
      "Bottleneck features for batch 30 created and saved\n",
      "\n",
      "Batch 31 loaded\n",
      "Creating bottleneck features for batch 31\n",
      "Bottleneck features for batch 31 created and saved\n",
      "\n",
      "Batch 32 loaded\n",
      "Creating bottleneck features for batch 32\n",
      "Bottleneck features for batch 32 created and saved\n",
      "\n",
      "Batch 33 loaded\n",
      "Creating bottleneck features for batch 33\n",
      "Bottleneck features for batch 33 created and saved\n",
      "\n",
      "Batch 34 loaded\n",
      "Creating bottleneck features for batch 34\n",
      "Bottleneck features for batch 34 created and saved\n",
      "\n",
      "Batch 35 loaded\n",
      "Creating bottleneck features for batch 35\n",
      "Bottleneck features for batch 35 created and saved\n",
      "\n",
      "Batch 36 loaded\n",
      "Creating bottleneck features for batch 36\n",
      "Bottleneck features for batch 36 created and saved\n",
      "\n",
      "Batch 37 loaded\n",
      "Creating bottleneck features for batch 37\n",
      "Bottleneck features for batch 37 created and saved\n",
      "\n",
      "Batch 38 loaded\n",
      "Creating bottleneck features for batch 38\n",
      "Bottleneck features for batch 38 created and saved\n",
      "\n",
      "Batch 39 loaded\n",
      "Creating bottleneck features for batch 39\n",
      "Bottleneck features for batch 39 created and saved\n",
      "\n",
      "Batch 40 loaded\n",
      "Creating bottleneck features for batch 40\n",
      "Bottleneck features for batch 40 created and saved\n",
      "\n",
      "Batch 41 loaded\n",
      "Creating bottleneck features for batch 41\n",
      "Bottleneck features for batch 41 created and saved\n",
      "\n",
      "Batch 42 loaded\n",
      "Creating bottleneck features for batch 42\n",
      "Bottleneck features for batch 42 created and saved\n",
      "\n",
      "Batch 43 loaded\n",
      "Creating bottleneck features for batch 43\n",
      "Bottleneck features for batch 43 created and saved\n",
      "\n",
      "Batch 44 loaded\n",
      "Creating bottleneck features for batch 44\n",
      "Bottleneck features for batch 44 created and saved\n",
      "\n",
      "Batch 45 loaded\n",
      "Creating bottleneck features for batch 45\n",
      "Bottleneck features for batch 45 created and saved\n",
      "\n",
      "Batch 46 loaded\n",
      "Creating bottleneck features for batch 46\n",
      "Bottleneck features for batch 46 created and saved\n",
      "\n",
      "Batch 47 loaded\n",
      "Creating bottleneck features for batch 47\n",
      "Bottleneck features for batch 47 created and saved\n",
      "\n",
      "Batch 48 loaded\n",
      "Creating bottleneck features for batch 48\n",
      "Bottleneck features for batch 48 created and saved\n",
      "\n",
      "Batch 49 loaded\n",
      "Creating bottleneck features for batch 49\n",
      "Bottleneck features for batch 49 created and saved\n",
      "\n",
      "Batch 50 loaded\n",
      "Creating bottleneck features for batch 50\n",
      "Bottleneck features for batch 50 created and saved\n",
      "\n",
      "Batch 51 loaded\n",
      "Creating bottleneck features for batch 51\n",
      "Bottleneck features for batch 51 created and saved\n",
      "\n",
      "Batch 52 loaded\n",
      "Creating bottleneck features for batch 52\n",
      "Bottleneck features for batch 52 created and saved\n",
      "\n",
      "Batch 53 loaded\n",
      "Creating bottleneck features for batch 53\n",
      "Bottleneck features for batch 53 created and saved\n",
      "\n",
      "Batch 54 loaded\n",
      "Creating bottleneck features for batch 54\n",
      "Bottleneck features for batch 54 created and saved\n",
      "\n",
      "Batch 55 loaded\n",
      "Creating bottleneck features for batch 55\n",
      "Bottleneck features for batch 55 created and saved\n",
      "\n",
      "Batch 56 loaded\n",
      "Creating bottleneck features for batch 56\n",
      "Bottleneck features for batch 56 created and saved\n",
      "\n",
      "Batch 57 loaded\n",
      "Creating bottleneck features for batch 57\n",
      "Bottleneck features for batch 57 created and saved\n",
      "\n",
      "Batch 58 loaded\n",
      "Creating bottleneck features for batch 58\n",
      "Bottleneck features for batch 58 created and saved\n",
      "\n",
      "Batch 59 loaded\n",
      "Creating bottleneck features for batch 59\n",
      "Bottleneck features for batch 59 created and saved\n",
      "\n",
      "Batch 60 loaded\n",
      "Creating bottleneck features for batch 60\n",
      "Bottleneck features for batch 60 created and saved\n",
      "\n",
      "Batch 61 loaded\n",
      "Creating bottleneck features for batch 61\n",
      "Bottleneck features for batch 61 created and saved\n",
      "\n",
      "Batch 62 loaded\n",
      "Creating bottleneck features for batch 62\n",
      "Bottleneck features for batch 62 created and saved\n",
      "\n",
      "Batch 63 loaded\n",
      "Creating bottleneck features for batch 63\n",
      "Bottleneck features for batch 63 created and saved\n",
      "\n",
      "Batch 64 loaded\n",
      "Creating bottleneck features for batch 64\n",
      "Bottleneck features for batch 64 created and saved\n",
      "\n",
      "Batch 65 loaded\n",
      "Creating bottleneck features for batch 65\n",
      "Bottleneck features for batch 65 created and saved\n",
      "\n",
      "Batch 66 loaded\n",
      "Creating bottleneck features for batch 66\n",
      "Bottleneck features for batch 66 created and saved\n",
      "\n",
      "Batch 67 loaded\n",
      "Creating bottleneck features for batch 67\n",
      "Bottleneck features for batch 67 created and saved\n",
      "\n",
      "Batch 68 loaded\n",
      "Creating bottleneck features for batch 68\n",
      "Bottleneck features for batch 68 created and saved\n",
      "\n",
      "Batch 69 loaded\n",
      "Creating bottleneck features for batch 69\n",
      "Bottleneck features for batch 69 created and saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating bottleneck features for CV Human data using VGG-16- Image-net model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "SAVEDIR = \"../Data/Bottleneck_Features/Bottleneck_CVHumans/\"\n",
    "SAVEDIR_LABELS = \"../Data/Bottleneck_Features/CVHumans_Labels/\"\n",
    "batch_size = 50\n",
    "for i in range(int(len(CV_Humans)/batch_size)):\n",
    "    x, y = loadCVHumanBatch(batch_size)\n",
    "    print(\"Batch {} loaded\".format(i+1))\n",
    "    \n",
    "    np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(i+1)), y)\n",
    "    \n",
    "    print(\"Creating bottleneck features for batch {}\". format(i+1))\n",
    "    bottleneck_features = model.predict(x)\n",
    "    np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(i+1)), bottleneck_features)\n",
    "    print(\"Bottleneck features for batch {} created and saved\\n\".format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck Features for Test Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH GOEL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5118, 8)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestHuman_Labels = pd.get_dummies(Test_Humans[\"Labels\"]).as_matrix()\n",
    "TestHuman_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestHumansBatch(batch_size):\n",
    "    global TestHumans_batch_pointer\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        path1 = Test_Humans.iloc[TestHumans_batch_pointer + i][\"folderName\"]\n",
    "        path2 = Test_Humans.iloc[TestHumans_batch_pointer + i][\"imageName\"]\n",
    "        read_image = cv2.imread(os.path.join(path1, path2))\n",
    "        read_image_final = read_image.resize((48, 48 ,3))\n",
    "        read_image_final = read_image/255.0  #here, we are normalizing the images\n",
    "        batch_images.append(read_image_final)\n",
    "        \n",
    "        batch_labels.append(TestHuman_Labels[TestHumans_batch_pointer + i]) #appending corresponding labels\n",
    "        \n",
    "    TestHumans_batch_pointer += batch_size\n",
    "        \n",
    "    return np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Creating bottleneck features for batch 1\n",
      "Bottleneck features for batch 1 created and saved\n",
      "\n",
      "Batch 2 loaded\n",
      "Creating bottleneck features for batch 2\n",
      "Bottleneck features for batch 2 created and saved\n",
      "\n",
      "Batch 3 loaded\n",
      "Creating bottleneck features for batch 3\n",
      "Bottleneck features for batch 3 created and saved\n",
      "\n",
      "Batch 4 loaded\n",
      "Creating bottleneck features for batch 4\n",
      "Bottleneck features for batch 4 created and saved\n",
      "\n",
      "Batch 5 loaded\n",
      "Creating bottleneck features for batch 5\n",
      "Bottleneck features for batch 5 created and saved\n",
      "\n",
      "Batch 6 loaded\n",
      "Creating bottleneck features for batch 6\n",
      "Bottleneck features for batch 6 created and saved\n",
      "\n",
      "Batch 7 loaded\n",
      "Creating bottleneck features for batch 7\n",
      "Bottleneck features for batch 7 created and saved\n",
      "\n",
      "Batch 8 loaded\n",
      "Creating bottleneck features for batch 8\n",
      "Bottleneck features for batch 8 created and saved\n",
      "\n",
      "Batch 9 loaded\n",
      "Creating bottleneck features for batch 9\n",
      "Bottleneck features for batch 9 created and saved\n",
      "\n",
      "Batch 10 loaded\n",
      "Creating bottleneck features for batch 10\n",
      "Bottleneck features for batch 10 created and saved\n",
      "\n",
      "Batch 11 loaded\n",
      "Creating bottleneck features for batch 11\n",
      "Bottleneck features for batch 11 created and saved\n",
      "\n",
      "Batch 12 loaded\n",
      "Creating bottleneck features for batch 12\n",
      "Bottleneck features for batch 12 created and saved\n",
      "\n",
      "Batch 13 loaded\n",
      "Creating bottleneck features for batch 13\n",
      "Bottleneck features for batch 13 created and saved\n",
      "\n",
      "Batch 14 loaded\n",
      "Creating bottleneck features for batch 14\n",
      "Bottleneck features for batch 14 created and saved\n",
      "\n",
      "Batch 15 loaded\n",
      "Creating bottleneck features for batch 15\n",
      "Bottleneck features for batch 15 created and saved\n",
      "\n",
      "Batch 16 loaded\n",
      "Creating bottleneck features for batch 16\n",
      "Bottleneck features for batch 16 created and saved\n",
      "\n",
      "Batch 17 loaded\n",
      "Creating bottleneck features for batch 17\n",
      "Bottleneck features for batch 17 created and saved\n",
      "\n",
      "Batch 18 loaded\n",
      "Creating bottleneck features for batch 18\n",
      "Bottleneck features for batch 18 created and saved\n",
      "\n",
      "Batch 19 loaded\n",
      "Creating bottleneck features for batch 19\n",
      "Bottleneck features for batch 19 created and saved\n",
      "\n",
      "Batch 20 loaded\n",
      "Creating bottleneck features for batch 20\n",
      "Bottleneck features for batch 20 created and saved\n",
      "\n",
      "Batch 21 loaded\n",
      "Creating bottleneck features for batch 21\n",
      "Bottleneck features for batch 21 created and saved\n",
      "\n",
      "Batch 22 loaded\n",
      "Creating bottleneck features for batch 22\n",
      "Bottleneck features for batch 22 created and saved\n",
      "\n",
      "Batch 23 loaded\n",
      "Creating bottleneck features for batch 23\n",
      "Bottleneck features for batch 23 created and saved\n",
      "\n",
      "Batch 24 loaded\n",
      "Creating bottleneck features for batch 24\n",
      "Bottleneck features for batch 24 created and saved\n",
      "\n",
      "Batch 25 loaded\n",
      "Creating bottleneck features for batch 25\n",
      "Bottleneck features for batch 25 created and saved\n",
      "\n",
      "Batch 26 loaded\n",
      "Creating bottleneck features for batch 26\n",
      "Bottleneck features for batch 26 created and saved\n",
      "\n",
      "Batch 27 loaded\n",
      "Creating bottleneck features for batch 27\n",
      "Bottleneck features for batch 27 created and saved\n",
      "\n",
      "Batch 28 loaded\n",
      "Creating bottleneck features for batch 28\n",
      "Bottleneck features for batch 28 created and saved\n",
      "\n",
      "Batch 29 loaded\n",
      "Creating bottleneck features for batch 29\n",
      "Bottleneck features for batch 29 created and saved\n",
      "\n",
      "Batch 30 loaded\n",
      "Creating bottleneck features for batch 30\n",
      "Bottleneck features for batch 30 created and saved\n",
      "\n",
      "Batch 31 loaded\n",
      "Creating bottleneck features for batch 31\n",
      "Bottleneck features for batch 31 created and saved\n",
      "\n",
      "Batch 32 loaded\n",
      "Creating bottleneck features for batch 32\n",
      "Bottleneck features for batch 32 created and saved\n",
      "\n",
      "Batch 33 loaded\n",
      "Creating bottleneck features for batch 33\n",
      "Bottleneck features for batch 33 created and saved\n",
      "\n",
      "Batch 34 loaded\n",
      "Creating bottleneck features for batch 34\n",
      "Bottleneck features for batch 34 created and saved\n",
      "\n",
      "Batch 35 loaded\n",
      "Creating bottleneck features for batch 35\n",
      "Bottleneck features for batch 35 created and saved\n",
      "\n",
      "Batch 36 loaded\n",
      "Creating bottleneck features for batch 36\n",
      "Bottleneck features for batch 36 created and saved\n",
      "\n",
      "Batch 37 loaded\n",
      "Creating bottleneck features for batch 37\n",
      "Bottleneck features for batch 37 created and saved\n",
      "\n",
      "Batch 38 loaded\n",
      "Creating bottleneck features for batch 38\n",
      "Bottleneck features for batch 38 created and saved\n",
      "\n",
      "Batch 39 loaded\n",
      "Creating bottleneck features for batch 39\n",
      "Bottleneck features for batch 39 created and saved\n",
      "\n",
      "Batch 40 loaded\n",
      "Creating bottleneck features for batch 40\n",
      "Bottleneck features for batch 40 created and saved\n",
      "\n",
      "Batch 41 loaded\n",
      "Creating bottleneck features for batch 41\n",
      "Bottleneck features for batch 41 created and saved\n",
      "\n",
      "Batch 42 loaded\n",
      "Creating bottleneck features for batch 42\n",
      "Bottleneck features for batch 42 created and saved\n",
      "\n",
      "Batch 43 loaded\n",
      "Creating bottleneck features for batch 43\n",
      "Bottleneck features for batch 43 created and saved\n",
      "\n",
      "Batch 44 loaded\n",
      "Creating bottleneck features for batch 44\n",
      "Bottleneck features for batch 44 created and saved\n",
      "\n",
      "Batch 45 loaded\n",
      "Creating bottleneck features for batch 45\n",
      "Bottleneck features for batch 45 created and saved\n",
      "\n",
      "Batch 46 loaded\n",
      "Creating bottleneck features for batch 46\n",
      "Bottleneck features for batch 46 created and saved\n",
      "\n",
      "Batch 47 loaded\n",
      "Creating bottleneck features for batch 47\n",
      "Bottleneck features for batch 47 created and saved\n",
      "\n",
      "Batch 48 loaded\n",
      "Creating bottleneck features for batch 48\n",
      "Bottleneck features for batch 48 created and saved\n",
      "\n",
      "Batch 49 loaded\n",
      "Creating bottleneck features for batch 49\n",
      "Bottleneck features for batch 49 created and saved\n",
      "\n",
      "Batch 50 loaded\n",
      "Creating bottleneck features for batch 50\n",
      "Bottleneck features for batch 50 created and saved\n",
      "\n",
      "Batch 51 loaded\n",
      "Creating bottleneck features for batch 51\n",
      "Bottleneck features for batch 51 created and saved\n",
      "\n",
      "Batch 52 loaded\n",
      "Creating bottleneck features for batch 52\n",
      "Bottleneck features for batch 52 created and saved\n",
      "\n",
      "Batch 53 loaded\n",
      "Creating bottleneck features for batch 53\n",
      "Bottleneck features for batch 53 created and saved\n",
      "\n",
      "Batch 54 loaded\n",
      "Creating bottleneck features for batch 54\n",
      "Bottleneck features for batch 54 created and saved\n",
      "\n",
      "Batch 55 loaded\n",
      "Creating bottleneck features for batch 55\n",
      "Bottleneck features for batch 55 created and saved\n",
      "\n",
      "Batch 56 loaded\n",
      "Creating bottleneck features for batch 56\n",
      "Bottleneck features for batch 56 created and saved\n",
      "\n",
      "Batch 57 loaded\n",
      "Creating bottleneck features for batch 57\n",
      "Bottleneck features for batch 57 created and saved\n",
      "\n",
      "Batch 58 loaded\n",
      "Creating bottleneck features for batch 58\n",
      "Bottleneck features for batch 58 created and saved\n",
      "\n",
      "Batch 59 loaded\n",
      "Creating bottleneck features for batch 59\n",
      "Bottleneck features for batch 59 created and saved\n",
      "\n",
      "Batch 60 loaded\n",
      "Creating bottleneck features for batch 60\n",
      "Bottleneck features for batch 60 created and saved\n",
      "\n",
      "Batch 61 loaded\n",
      "Creating bottleneck features for batch 61\n",
      "Bottleneck features for batch 61 created and saved\n",
      "\n",
      "Batch 62 loaded\n",
      "Creating bottleneck features for batch 62\n",
      "Bottleneck features for batch 62 created and saved\n",
      "\n",
      "Batch 63 loaded\n",
      "Creating bottleneck features for batch 63\n",
      "Bottleneck features for batch 63 created and saved\n",
      "\n",
      "Batch 64 loaded\n",
      "Creating bottleneck features for batch 64\n",
      "Bottleneck features for batch 64 created and saved\n",
      "\n",
      "Batch 65 loaded\n",
      "Creating bottleneck features for batch 65\n",
      "Bottleneck features for batch 65 created and saved\n",
      "\n",
      "Batch 66 loaded\n",
      "Creating bottleneck features for batch 66\n",
      "Bottleneck features for batch 66 created and saved\n",
      "\n",
      "Batch 67 loaded\n",
      "Creating bottleneck features for batch 67\n",
      "Bottleneck features for batch 67 created and saved\n",
      "\n",
      "Batch 68 loaded\n",
      "Creating bottleneck features for batch 68\n",
      "Bottleneck features for batch 68 created and saved\n",
      "\n",
      "Batch 69 loaded\n",
      "Creating bottleneck features for batch 69\n",
      "Bottleneck features for batch 69 created and saved\n",
      "\n",
      "Batch 70 loaded\n",
      "Creating bottleneck features for batch 70\n",
      "Bottleneck features for batch 70 created and saved\n",
      "\n",
      "Batch 71 loaded\n",
      "Creating bottleneck features for batch 71\n",
      "Bottleneck features for batch 71 created and saved\n",
      "\n",
      "Batch 72 loaded\n",
      "Creating bottleneck features for batch 72\n",
      "Bottleneck features for batch 72 created and saved\n",
      "\n",
      "Batch 73 loaded\n",
      "Creating bottleneck features for batch 73\n",
      "Bottleneck features for batch 73 created and saved\n",
      "\n",
      "Batch 74 loaded\n",
      "Creating bottleneck features for batch 74\n",
      "Bottleneck features for batch 74 created and saved\n",
      "\n",
      "Batch 75 loaded\n",
      "Creating bottleneck features for batch 75\n",
      "Bottleneck features for batch 75 created and saved\n",
      "\n",
      "Batch 76 loaded\n",
      "Creating bottleneck features for batch 76\n",
      "Bottleneck features for batch 76 created and saved\n",
      "\n",
      "Batch 77 loaded\n",
      "Creating bottleneck features for batch 77\n",
      "Bottleneck features for batch 77 created and saved\n",
      "\n",
      "Batch 78 loaded\n",
      "Creating bottleneck features for batch 78\n",
      "Bottleneck features for batch 78 created and saved\n",
      "\n",
      "Batch 79 loaded\n",
      "Creating bottleneck features for batch 79\n",
      "Bottleneck features for batch 79 created and saved\n",
      "\n",
      "Batch 80 loaded\n",
      "Creating bottleneck features for batch 80\n",
      "Bottleneck features for batch 80 created and saved\n",
      "\n",
      "Batch 81 loaded\n",
      "Creating bottleneck features for batch 81\n",
      "Bottleneck features for batch 81 created and saved\n",
      "\n",
      "Batch 82 loaded\n",
      "Creating bottleneck features for batch 82\n",
      "Bottleneck features for batch 82 created and saved\n",
      "\n",
      "Batch 83 loaded\n",
      "Creating bottleneck features for batch 83\n",
      "Bottleneck features for batch 83 created and saved\n",
      "\n",
      "Batch 84 loaded\n",
      "Creating bottleneck features for batch 84\n",
      "Bottleneck features for batch 84 created and saved\n",
      "\n",
      "Batch 85 loaded\n",
      "Creating bottleneck features for batch 85\n",
      "Bottleneck features for batch 85 created and saved\n",
      "\n",
      "Batch 86 loaded\n",
      "Creating bottleneck features for batch 86\n",
      "Bottleneck features for batch 86 created and saved\n",
      "\n",
      "Batch 87 loaded\n",
      "Creating bottleneck features for batch 87\n",
      "Bottleneck features for batch 87 created and saved\n",
      "\n",
      "Batch 88 loaded\n",
      "Creating bottleneck features for batch 88\n",
      "Bottleneck features for batch 88 created and saved\n",
      "\n",
      "Batch 89 loaded\n",
      "Creating bottleneck features for batch 89\n",
      "Bottleneck features for batch 89 created and saved\n",
      "\n",
      "Batch 90 loaded\n",
      "Creating bottleneck features for batch 90\n",
      "Bottleneck features for batch 90 created and saved\n",
      "\n",
      "Batch 91 loaded\n",
      "Creating bottleneck features for batch 91\n",
      "Bottleneck features for batch 91 created and saved\n",
      "\n",
      "Batch 92 loaded\n",
      "Creating bottleneck features for batch 92\n",
      "Bottleneck features for batch 92 created and saved\n",
      "\n",
      "Batch 93 loaded\n",
      "Creating bottleneck features for batch 93\n",
      "Bottleneck features for batch 93 created and saved\n",
      "\n",
      "Batch 94 loaded\n",
      "Creating bottleneck features for batch 94\n",
      "Bottleneck features for batch 94 created and saved\n",
      "\n",
      "Batch 95 loaded\n",
      "Creating bottleneck features for batch 95\n",
      "Bottleneck features for batch 95 created and saved\n",
      "\n",
      "Batch 96 loaded\n",
      "Creating bottleneck features for batch 96\n",
      "Bottleneck features for batch 96 created and saved\n",
      "\n",
      "Batch 97 loaded\n",
      "Creating bottleneck features for batch 97\n",
      "Bottleneck features for batch 97 created and saved\n",
      "\n",
      "Batch 98 loaded\n",
      "Creating bottleneck features for batch 98\n",
      "Bottleneck features for batch 98 created and saved\n",
      "\n",
      "Batch 99 loaded\n",
      "Creating bottleneck features for batch 99\n",
      "Bottleneck features for batch 99 created and saved\n",
      "\n",
      "Batch 100 loaded\n",
      "Creating bottleneck features for batch 100\n",
      "Bottleneck features for batch 100 created and saved\n",
      "\n",
      "Batch 101 loaded\n",
      "Creating bottleneck features for batch 101\n",
      "Bottleneck features for batch 101 created and saved\n",
      "\n",
      "Batch 102 loaded\n",
      "Creating bottleneck features for batch 102\n",
      "Bottleneck features for batch 102 created and saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating bottleneck features for Test Humans data using VGG-16- Image-net model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "SAVEDIR = \"../Data/Bottleneck_Features/Bottleneck_TestHumans/\"\n",
    "SAVEDIR_LABELS = \"../Data/Bottleneck_Features/TestHumans_Labels/\"\n",
    "batch_size = 50\n",
    "for i in range(int(len(Test_Humans)/batch_size)):\n",
    "    x, y = loadTestHumansBatch(batch_size)\n",
    "    print(\"Batch {} loaded\".format(i+1))\n",
    "    \n",
    "    np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(i+1)), y)\n",
    "    \n",
    "    print(\"Creating bottleneck features for batch {}\". format(i+1))\n",
    "    bottleneck_features = model.predict(x)\n",
    "    np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(i+1)), bottleneck_features)\n",
    "    print(\"Bottleneck features for batch {} created and saved\\n\".format(i+1))\n",
    "\n",
    "leftover_points = len(Test_Humans) - TestHumans_batch_pointer\n",
    "x, y = loadTestHumansBatch(leftover_points)\n",
    "np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(int(len(Test_Humans)/batch_size) + 1)), y)\n",
    "bottleneck_features = model.predict(x)\n",
    "np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(int(len(Test_Humans)/batch_size) + 1)), bottleneck_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture\n",
    "def model(input_shape):\n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Dense(512, activation='relu', input_dim = input_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(output_dim = no_of_classes, activation='softmax')) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 436,168\n",
      "Trainable params: 435,912\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIDDHARTH GOEL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=8)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(345, 69)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "SAVEDIR_COMB_TRAIN = \"../Data/Bottleneck_Features/Bottleneck_CombinedTrain/\"\n",
    "SAVEDIR_COMB_TRAIN_LABELS = \"../Data/Bottleneck_Features/CombinedTrain_Labels/\"\n",
    "\n",
    "SAVEDIR_CV_HUMANS = \"../Data/Bottleneck_Features/Bottleneck_CVHumans/\"\n",
    "SAVEDIR_CV_HUMANS_LABELS = \"../Data/Bottleneck_Features/CVHumans_Labels/\"\n",
    "\n",
    "SAVER = \"../Data/Model_Save/\"\n",
    "\n",
    "input_shape = 512   #this is the shape of bottleneck feature of each image which comes after passing the image through VGG-16\n",
    "\n",
    "model = model(input_shape)\n",
    "# model.load_weights(os.path.join(SAVER, \"model.h5\"))\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "step = 0\n",
    "combTrain_bottleneck_files = int(len(Train_Combined) / batch_size)\n",
    "CVHuman_bottleneck_files = int(len(CV_Humans) / batch_size)\n",
    "combTrain_bottleneck_files,CVHuman_bottleneck_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 346, CombTr_Loss: 2.65, CombTr_Acc: 0.08, CVHum_Loss: 2.06, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 347, CombTr_Loss: 2.43, CombTr_Acc: 0.12, CVHum_Loss: 2.25, CVHum_Acc: 0.04 \n",
      "Epoch: 1, Step: 348, CombTr_Loss: 2.57, CombTr_Acc: 0.12, CVHum_Loss: 2.13, CVHum_Acc: 0.06 \n",
      "Epoch: 1, Step: 349, CombTr_Loss: 2.52, CombTr_Acc: 0.06, CVHum_Loss: 2.22, CVHum_Acc: 0.1 \n",
      "Epoch: 1, Step: 350, CombTr_Loss: 2.31, CombTr_Acc: 0.12, CVHum_Loss: 2.13, CVHum_Acc: 0.04 \n",
      "Epoch: 1, Step: 351, CombTr_Loss: 2.39, CombTr_Acc: 0.16, CVHum_Loss: 2.15, CVHum_Acc: 0.1 \n",
      "Epoch: 1, Step: 352, CombTr_Loss: 2.1, CombTr_Acc: 0.26, CVHum_Loss: 2.18, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 353, CombTr_Loss: 2.01, CombTr_Acc: 0.24, CVHum_Loss: 2.07, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 354, CombTr_Loss: 2.12, CombTr_Acc: 0.3, CVHum_Loss: 2.08, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 355, CombTr_Loss: 2.39, CombTr_Acc: 0.04, CVHum_Loss: 2.24, CVHum_Acc: 0.06 \n",
      "Epoch: 1, Step: 356, CombTr_Loss: 2.41, CombTr_Acc: 0.16, CVHum_Loss: 2.07, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 357, CombTr_Loss: 2.17, CombTr_Acc: 0.2, CVHum_Loss: 2.02, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 358, CombTr_Loss: 2.08, CombTr_Acc: 0.18, CVHum_Loss: 2.1, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 359, CombTr_Loss: 2.27, CombTr_Acc: 0.14, CVHum_Loss: 2.1, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 360, CombTr_Loss: 2.03, CombTr_Acc: 0.26, CVHum_Loss: 2.08, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 361, CombTr_Loss: 2.12, CombTr_Acc: 0.18, CVHum_Loss: 2.13, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 362, CombTr_Loss: 1.95, CombTr_Acc: 0.3, CVHum_Loss: 2.05, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 363, CombTr_Loss: 2.11, CombTr_Acc: 0.08, CVHum_Loss: 2.06, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 364, CombTr_Loss: 1.96, CombTr_Acc: 0.2, CVHum_Loss: 2.08, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 365, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 366, CombTr_Loss: 1.94, CombTr_Acc: 0.3, CVHum_Loss: 1.95, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 367, CombTr_Loss: 1.88, CombTr_Acc: 0.22, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 368, CombTr_Loss: 2.03, CombTr_Acc: 0.18, CVHum_Loss: 2.05, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 369, CombTr_Loss: 1.84, CombTr_Acc: 0.36, CVHum_Loss: 2.17, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 370, CombTr_Loss: 1.89, CombTr_Acc: 0.2, CVHum_Loss: 2.05, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 371, CombTr_Loss: 1.95, CombTr_Acc: 0.26, CVHum_Loss: 2.04, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 372, CombTr_Loss: 1.78, CombTr_Acc: 0.26, CVHum_Loss: 1.95, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 373, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.93, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 374, CombTr_Loss: 1.98, CombTr_Acc: 0.28, CVHum_Loss: 2.01, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 375, CombTr_Loss: 1.82, CombTr_Acc: 0.26, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 376, CombTr_Loss: 2.05, CombTr_Acc: 0.24, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 377, CombTr_Loss: 1.92, CombTr_Acc: 0.28, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 378, CombTr_Loss: 1.98, CombTr_Acc: 0.18, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 379, CombTr_Loss: 1.87, CombTr_Acc: 0.26, CVHum_Loss: 2.07, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 380, CombTr_Loss: 1.9, CombTr_Acc: 0.3, CVHum_Loss: 1.96, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 381, CombTr_Loss: 1.9, CombTr_Acc: 0.12, CVHum_Loss: 1.93, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 382, CombTr_Loss: 1.83, CombTr_Acc: 0.3, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 383, CombTr_Loss: 1.75, CombTr_Acc: 0.24, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 384, CombTr_Loss: 2.0, CombTr_Acc: 0.22, CVHum_Loss: 2.06, CVHum_Acc: 0.1 \n",
      "Epoch: 1, Step: 385, CombTr_Loss: 1.74, CombTr_Acc: 0.26, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 386, CombTr_Loss: 1.9, CombTr_Acc: 0.2, CVHum_Loss: 2.05, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 387, CombTr_Loss: 1.96, CombTr_Acc: 0.26, CVHum_Loss: 1.99, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 388, CombTr_Loss: 1.85, CombTr_Acc: 0.28, CVHum_Loss: 2.02, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 389, CombTr_Loss: 1.78, CombTr_Acc: 0.26, CVHum_Loss: 1.93, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 390, CombTr_Loss: 1.88, CombTr_Acc: 0.18, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 391, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 2.0, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 392, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.99, CVHum_Acc: 0.1 \n",
      "Epoch: 1, Step: 393, CombTr_Loss: 1.98, CombTr_Acc: 0.1, CVHum_Loss: 1.9, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 394, CombTr_Loss: 1.91, CombTr_Acc: 0.22, CVHum_Loss: 1.91, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 395, CombTr_Loss: 1.88, CombTr_Acc: 0.26, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 396, CombTr_Loss: 1.94, CombTr_Acc: 0.18, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 397, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 2.01, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 398, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 2.02, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 399, CombTr_Loss: 1.77, CombTr_Acc: 0.14, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 400, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.91, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 401, CombTr_Loss: 1.79, CombTr_Acc: 0.3, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 402, CombTr_Loss: 1.88, CombTr_Acc: 0.24, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 403, CombTr_Loss: 1.84, CombTr_Acc: 0.28, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 404, CombTr_Loss: 1.84, CombTr_Acc: 0.26, CVHum_Loss: 1.94, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 405, CombTr_Loss: 1.75, CombTr_Acc: 0.36, CVHum_Loss: 1.98, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 406, CombTr_Loss: 2.0, CombTr_Acc: 0.2, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 407, CombTr_Loss: 1.94, CombTr_Acc: 0.2, CVHum_Loss: 1.93, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 408, CombTr_Loss: 1.92, CombTr_Acc: 0.22, CVHum_Loss: 1.95, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 409, CombTr_Loss: 1.91, CombTr_Acc: 0.14, CVHum_Loss: 1.86, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 410, CombTr_Loss: 1.73, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 411, CombTr_Loss: 1.78, CombTr_Acc: 0.3, CVHum_Loss: 1.92, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 412, CombTr_Loss: 1.84, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 413, CombTr_Loss: 1.73, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 414, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.99, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 415, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 416, CombTr_Loss: 1.96, CombTr_Acc: 0.28, CVHum_Loss: 1.97, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 417, CombTr_Loss: 1.85, CombTr_Acc: 0.22, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 418, CombTr_Loss: 1.89, CombTr_Acc: 0.4, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 419, CombTr_Loss: 1.84, CombTr_Acc: 0.22, CVHum_Loss: 2.04, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 420, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 421, CombTr_Loss: 2.09, CombTr_Acc: 0.14, CVHum_Loss: 1.97, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 422, CombTr_Loss: 2.06, CombTr_Acc: 0.22, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 423, CombTr_Loss: 1.93, CombTr_Acc: 0.22, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 424, CombTr_Loss: 1.77, CombTr_Acc: 0.24, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 425, CombTr_Loss: 1.78, CombTr_Acc: 0.28, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 426, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 427, CombTr_Loss: 1.8, CombTr_Acc: 0.26, CVHum_Loss: 2.0, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 428, CombTr_Loss: 1.86, CombTr_Acc: 0.28, CVHum_Loss: 1.91, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 429, CombTr_Loss: 1.77, CombTr_Acc: 0.22, CVHum_Loss: 1.95, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 430, CombTr_Loss: 1.91, CombTr_Acc: 0.16, CVHum_Loss: 1.97, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 431, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.99, CVHum_Acc: 0.1 \n",
      "Epoch: 1, Step: 432, CombTr_Loss: 1.78, CombTr_Acc: 0.26, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 433, CombTr_Loss: 1.88, CombTr_Acc: 0.28, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 434, CombTr_Loss: 1.83, CombTr_Acc: 0.3, CVHum_Loss: 1.94, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 435, CombTr_Loss: 1.78, CombTr_Acc: 0.24, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 436, CombTr_Loss: 1.95, CombTr_Acc: 0.26, CVHum_Loss: 1.91, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 437, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 438, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.98, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 439, CombTr_Loss: 1.87, CombTr_Acc: 0.22, CVHum_Loss: 1.85, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 440, CombTr_Loss: 1.92, CombTr_Acc: 0.26, CVHum_Loss: 2.06, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 441, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 442, CombTr_Loss: 1.76, CombTr_Acc: 0.24, CVHum_Loss: 1.93, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 443, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.97, CVHum_Acc: 0.06 \n",
      "Epoch: 1, Step: 444, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.88, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 445, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 446, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 447, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 448, CombTr_Loss: 1.79, CombTr_Acc: 0.18, CVHum_Loss: 2.01, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 449, CombTr_Loss: 1.77, CombTr_Acc: 0.2, CVHum_Loss: 1.99, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 450, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 451, CombTr_Loss: 1.79, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 452, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 453, CombTr_Loss: 2.04, CombTr_Acc: 0.26, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 454, CombTr_Loss: 1.88, CombTr_Acc: 0.12, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 455, CombTr_Loss: 2.0, CombTr_Acc: 0.22, CVHum_Loss: 2.07, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 456, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 457, CombTr_Loss: 1.95, CombTr_Acc: 0.26, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 458, CombTr_Loss: 1.81, CombTr_Acc: 0.26, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 459, CombTr_Loss: 1.85, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 460, CombTr_Loss: 1.87, CombTr_Acc: 0.28, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 461, CombTr_Loss: 1.79, CombTr_Acc: 0.38, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 462, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 463, CombTr_Loss: 1.71, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 464, CombTr_Loss: 1.73, CombTr_Acc: 0.4, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 465, CombTr_Loss: 1.85, CombTr_Acc: 0.16, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 466, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 2.14, CVHum_Acc: 0.08 \n",
      "Epoch: 1, Step: 467, CombTr_Loss: 1.73, CombTr_Acc: 0.26, CVHum_Loss: 2.06, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 468, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 1.98, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 469, CombTr_Loss: 1.87, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 470, CombTr_Loss: 1.84, CombTr_Acc: 0.22, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 471, CombTr_Loss: 1.82, CombTr_Acc: 0.34, CVHum_Loss: 2.05, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 472, CombTr_Loss: 1.69, CombTr_Acc: 0.38, CVHum_Loss: 2.1, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 473, CombTr_Loss: 1.83, CombTr_Acc: 0.24, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 474, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 475, CombTr_Loss: 1.65, CombTr_Acc: 0.4, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 476, CombTr_Loss: 1.86, CombTr_Acc: 0.18, CVHum_Loss: 1.96, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 477, CombTr_Loss: 1.77, CombTr_Acc: 0.18, CVHum_Loss: 2.22, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 478, CombTr_Loss: 1.82, CombTr_Acc: 0.24, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 479, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 480, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 481, CombTr_Loss: 1.65, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 482, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 483, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 2.08, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 484, CombTr_Loss: 1.91, CombTr_Acc: 0.22, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 485, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 2.01, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 486, CombTr_Loss: 1.69, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 487, CombTr_Loss: 1.83, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 488, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 2.03, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 489, CombTr_Loss: 1.79, CombTr_Acc: 0.22, CVHum_Loss: 1.78, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 490, CombTr_Loss: 1.93, CombTr_Acc: 0.28, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 491, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 492, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 493, CombTr_Loss: 1.74, CombTr_Acc: 0.26, CVHum_Loss: 1.84, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 494, CombTr_Loss: 1.83, CombTr_Acc: 0.36, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 495, CombTr_Loss: 1.82, CombTr_Acc: 0.32, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 496, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 497, CombTr_Loss: 1.75, CombTr_Acc: 0.28, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 498, CombTr_Loss: 1.97, CombTr_Acc: 0.22, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 499, CombTr_Loss: 1.84, CombTr_Acc: 0.22, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 500, CombTr_Loss: 1.87, CombTr_Acc: 0.36, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 501, CombTr_Loss: 1.85, CombTr_Acc: 0.28, CVHum_Loss: 2.14, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 502, CombTr_Loss: 1.78, CombTr_Acc: 0.3, CVHum_Loss: 1.97, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 503, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 504, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 505, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 506, CombTr_Loss: 1.96, CombTr_Acc: 0.2, CVHum_Loss: 2.08, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 507, CombTr_Loss: 1.72, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 508, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 509, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 510, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 511, CombTr_Loss: 1.87, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 512, CombTr_Loss: 1.85, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 513, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 514, CombTr_Loss: 1.85, CombTr_Acc: 0.24, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 515, CombTr_Loss: 1.95, CombTr_Acc: 0.18, CVHum_Loss: 1.78, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 516, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 517, CombTr_Loss: 1.85, CombTr_Acc: 0.3, CVHum_Loss: 2.09, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 518, CombTr_Loss: 1.71, CombTr_Acc: 0.26, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 519, CombTr_Loss: 1.93, CombTr_Acc: 0.18, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 520, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 521, CombTr_Loss: 1.82, CombTr_Acc: 0.22, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 522, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 1.93, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 523, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 524, CombTr_Loss: 1.86, CombTr_Acc: 0.22, CVHum_Loss: 2.01, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 525, CombTr_Loss: 1.78, CombTr_Acc: 0.28, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 526, CombTr_Loss: 1.69, CombTr_Acc: 0.38, CVHum_Loss: 1.96, CVHum_Acc: 0.12 \n",
      "Epoch: 1, Step: 527, CombTr_Loss: 1.84, CombTr_Acc: 0.26, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 528, CombTr_Loss: 1.85, CombTr_Acc: 0.24, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 529, CombTr_Loss: 1.76, CombTr_Acc: 0.36, CVHum_Loss: 1.89, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 530, CombTr_Loss: 1.99, CombTr_Acc: 0.2, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 531, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 532, CombTr_Loss: 1.82, CombTr_Acc: 0.24, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 533, CombTr_Loss: 1.87, CombTr_Acc: 0.24, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 534, CombTr_Loss: 1.79, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 535, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.9, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 536, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.99, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 537, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 538, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 1, Step: 539, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.69, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 540, CombTr_Loss: 1.85, CombTr_Acc: 0.26, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 541, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.91, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 542, CombTr_Loss: 1.84, CombTr_Acc: 0.22, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 543, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 544, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 545, CombTr_Loss: 1.74, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 546, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 547, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 548, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 549, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 550, CombTr_Loss: 1.89, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 551, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 552, CombTr_Loss: 1.68, CombTr_Acc: 0.24, CVHum_Loss: 1.74, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 553, CombTr_Loss: 1.64, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 554, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 555, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 556, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 557, CombTr_Loss: 1.73, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 558, CombTr_Loss: 1.69, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 559, CombTr_Loss: 1.75, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 560, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 561, CombTr_Loss: 1.98, CombTr_Acc: 0.2, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 562, CombTr_Loss: 1.85, CombTr_Acc: 0.26, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 563, CombTr_Loss: 1.75, CombTr_Acc: 0.22, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 564, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 2.05, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 565, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 566, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 567, CombTr_Loss: 1.9, CombTr_Acc: 0.24, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 568, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 569, CombTr_Loss: 1.81, CombTr_Acc: 0.26, CVHum_Loss: 1.99, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 570, CombTr_Loss: 1.74, CombTr_Acc: 0.22, CVHum_Loss: 2.06, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 571, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.87, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 572, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 1, Step: 573, CombTr_Loss: 1.85, CombTr_Acc: 0.28, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 574, CombTr_Loss: 1.81, CombTr_Acc: 0.3, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 575, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.96, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 576, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 577, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 578, CombTr_Loss: 1.94, CombTr_Acc: 0.16, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 579, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 580, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 581, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 582, CombTr_Loss: 2.0, CombTr_Acc: 0.26, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 583, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 584, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 585, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 586, CombTr_Loss: 1.83, CombTr_Acc: 0.24, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 587, CombTr_Loss: 1.81, CombTr_Acc: 0.26, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 588, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 589, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 1, Step: 590, CombTr_Loss: 1.87, CombTr_Acc: 0.28, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 591, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 592, CombTr_Loss: 1.8, CombTr_Acc: 0.22, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 593, CombTr_Loss: 1.75, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 594, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 595, CombTr_Loss: 1.76, CombTr_Acc: 0.28, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 596, CombTr_Loss: 1.84, CombTr_Acc: 0.24, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 597, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 598, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 599, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 600, CombTr_Loss: 1.76, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 601, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 602, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 603, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 604, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 605, CombTr_Loss: 1.84, CombTr_Acc: 0.36, CVHum_Loss: 2.09, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 606, CombTr_Loss: 1.8, CombTr_Acc: 0.22, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 607, CombTr_Loss: 1.76, CombTr_Acc: 0.2, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 608, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 609, CombTr_Loss: 1.78, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 610, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 611, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 612, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 613, CombTr_Loss: 1.61, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 614, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 615, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 616, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 617, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 618, CombTr_Loss: 1.72, CombTr_Acc: 0.14, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 619, CombTr_Loss: 1.92, CombTr_Acc: 0.22, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 620, CombTr_Loss: 1.86, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 621, CombTr_Loss: 1.74, CombTr_Acc: 0.24, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 622, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 623, CombTr_Loss: 1.62, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 624, CombTr_Loss: 1.71, CombTr_Acc: 0.28, CVHum_Loss: 1.77, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 625, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 626, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.91, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 627, CombTr_Loss: 1.83, CombTr_Acc: 0.22, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 628, CombTr_Loss: 1.73, CombTr_Acc: 0.26, CVHum_Loss: 2.06, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 629, CombTr_Loss: 1.93, CombTr_Acc: 0.18, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 630, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 631, CombTr_Loss: 1.71, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 632, CombTr_Loss: 1.82, CombTr_Acc: 0.18, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 633, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.95, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 634, CombTr_Loss: 1.65, CombTr_Acc: 0.3, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 635, CombTr_Loss: 1.87, CombTr_Acc: 0.26, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 636, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 637, CombTr_Loss: 1.93, CombTr_Acc: 0.18, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 638, CombTr_Loss: 1.82, CombTr_Acc: 0.2, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 639, CombTr_Loss: 1.81, CombTr_Acc: 0.26, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 640, CombTr_Loss: 1.76, CombTr_Acc: 0.22, CVHum_Loss: 1.82, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 641, CombTr_Loss: 1.86, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 642, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 643, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 644, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 645, CombTr_Loss: 1.93, CombTr_Acc: 0.16, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 646, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 647, CombTr_Loss: 1.72, CombTr_Acc: 0.24, CVHum_Loss: 2.03, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 648, CombTr_Loss: 1.79, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 649, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 650, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 651, CombTr_Loss: 1.69, CombTr_Acc: 0.3, CVHum_Loss: 1.89, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 652, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 1.98, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 653, CombTr_Loss: 1.72, CombTr_Acc: 0.22, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 654, CombTr_Loss: 1.86, CombTr_Acc: 0.24, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 655, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 656, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 657, CombTr_Loss: 1.73, CombTr_Acc: 0.24, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 658, CombTr_Loss: 1.66, CombTr_Acc: 0.28, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 659, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 1, Step: 660, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 661, CombTr_Loss: 1.86, CombTr_Acc: 0.16, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 662, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 663, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.92, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 664, CombTr_Loss: 1.84, CombTr_Acc: 0.28, CVHum_Loss: 1.98, CVHum_Acc: 0.14 \n",
      "Epoch: 1, Step: 665, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 666, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 1, Step: 667, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 668, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 669, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 670, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 671, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 1, Step: 672, CombTr_Loss: 1.9, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 673, CombTr_Loss: 1.83, CombTr_Acc: 0.22, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 1, Step: 674, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 2.07, CVHum_Acc: 0.16 \n",
      "Epoch: 1, Step: 675, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.94, CVHum_Acc: 0.24 \n",
      "Epoch: 1, Step: 676, CombTr_Loss: 1.86, CombTr_Acc: 0.18, CVHum_Loss: 1.7, CVHum_Acc: 0.46 \n",
      "Epoch: 1, Step: 677, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 1, Step: 678, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 679, CombTr_Loss: 1.8, CombTr_Acc: 0.26, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 680, CombTr_Loss: 1.86, CombTr_Acc: 0.22, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 681, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 1, Step: 682, CombTr_Loss: 1.69, CombTr_Acc: 0.26, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 1, Step: 683, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.98, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 684, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 1, Step: 685, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 686, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 1, Step: 687, CombTr_Loss: 1.78, CombTr_Acc: 0.24, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 1, Step: 688, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.94, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 689, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 1, Step: 690, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Avg_CombTrain_Loss: 1.8, Avg_CombTrain_Acc: 0.28, Avg_CVHum_Loss: 1.89, Avg_CVHum_Acc: 0.24 \n",
      "Model and weights saved at epoch 1\n",
      "Epoch: 2, Step: 691, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 692, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 2.18, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 693, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.88, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 694, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 695, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.97, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 696, CombTr_Loss: 1.77, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 697, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.99, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 698, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 699, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 700, CombTr_Loss: 1.75, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 701, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.74, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 702, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 703, CombTr_Loss: 1.73, CombTr_Acc: 0.24, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 704, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 705, CombTr_Loss: 1.89, CombTr_Acc: 0.28, CVHum_Loss: 1.98, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 706, CombTr_Loss: 1.8, CombTr_Acc: 0.34, CVHum_Loss: 2.09, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 707, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 2.14, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 708, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 2.1, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 709, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 710, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 711, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 712, CombTr_Loss: 1.75, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 713, CombTr_Loss: 1.76, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 714, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 715, CombTr_Loss: 1.66, CombTr_Acc: 0.26, CVHum_Loss: 1.6, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 716, CombTr_Loss: 1.76, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 717, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 718, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.51, CVHum_Acc: 0.46 \n",
      "Epoch: 2, Step: 719, CombTr_Loss: 1.84, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 720, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 721, CombTr_Loss: 1.8, CombTr_Acc: 0.26, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 722, CombTr_Loss: 1.86, CombTr_Acc: 0.24, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 723, CombTr_Loss: 1.85, CombTr_Acc: 0.24, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 724, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 725, CombTr_Loss: 1.77, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 726, CombTr_Loss: 1.89, CombTr_Acc: 0.2, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 727, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 728, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 729, CombTr_Loss: 1.85, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 730, CombTr_Loss: 1.63, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 731, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 732, CombTr_Loss: 1.89, CombTr_Acc: 0.2, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 733, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 734, CombTr_Loss: 1.64, CombTr_Acc: 0.26, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 735, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 736, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 737, CombTr_Loss: 1.66, CombTr_Acc: 0.28, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 738, CombTr_Loss: 1.73, CombTr_Acc: 0.24, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 739, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 740, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 741, CombTr_Loss: 1.73, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 742, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.46 \n",
      "Epoch: 2, Step: 743, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 744, CombTr_Loss: 1.63, CombTr_Acc: 0.3, CVHum_Loss: 1.94, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 745, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 746, CombTr_Loss: 1.66, CombTr_Acc: 0.4, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 747, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 748, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 749, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 750, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 751, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 752, CombTr_Loss: 1.82, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 753, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.9, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 754, CombTr_Loss: 1.71, CombTr_Acc: 0.24, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 755, CombTr_Loss: 1.61, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 756, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 757, CombTr_Loss: 1.75, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 758, CombTr_Loss: 1.55, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 759, CombTr_Loss: 1.57, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 760, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 761, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 762, CombTr_Loss: 1.77, CombTr_Acc: 0.34, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 763, CombTr_Loss: 1.79, CombTr_Acc: 0.38, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 764, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 765, CombTr_Loss: 1.43, CombTr_Acc: 0.36, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 766, CombTr_Loss: 1.9, CombTr_Acc: 0.22, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 767, CombTr_Loss: 1.85, CombTr_Acc: 0.28, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 768, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 769, CombTr_Loss: 1.64, CombTr_Acc: 0.28, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 770, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 771, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 772, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 773, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 774, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 775, CombTr_Loss: 1.82, CombTr_Acc: 0.22, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 776, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.91, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 777, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 778, CombTr_Loss: 1.77, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 779, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 780, CombTr_Loss: 1.71, CombTr_Acc: 0.26, CVHum_Loss: 1.73, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 781, CombTr_Loss: 1.92, CombTr_Acc: 0.26, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 782, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 783, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 784, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 785, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 786, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 787, CombTr_Loss: 1.71, CombTr_Acc: 0.22, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 2, Step: 788, CombTr_Loss: 1.66, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 789, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 790, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 791, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 792, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 793, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 794, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 795, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 796, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 797, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 798, CombTr_Loss: 2.09, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 799, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.54, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 800, CombTr_Loss: 1.83, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 801, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 802, CombTr_Loss: 1.9, CombTr_Acc: 0.3, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 803, CombTr_Loss: 1.74, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 804, CombTr_Loss: 1.82, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 805, CombTr_Loss: 1.8, CombTr_Acc: 0.3, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 806, CombTr_Loss: 1.75, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 807, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 808, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 809, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 810, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 811, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 812, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.95, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 813, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 814, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 815, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 816, CombTr_Loss: 1.8, CombTr_Acc: 0.36, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 817, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 818, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 819, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 820, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 821, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 822, CombTr_Loss: 1.73, CombTr_Acc: 0.2, CVHum_Loss: 2.04, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 823, CombTr_Loss: 1.79, CombTr_Acc: 0.36, CVHum_Loss: 1.93, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 824, CombTr_Loss: 1.77, CombTr_Acc: 0.24, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 825, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 826, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 827, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 828, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 829, CombTr_Loss: 1.82, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 830, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 831, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 2.08, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 832, CombTr_Loss: 1.76, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 833, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 834, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 835, CombTr_Loss: 1.85, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 836, CombTr_Loss: 1.53, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 837, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 838, CombTr_Loss: 1.78, CombTr_Acc: 0.18, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 839, CombTr_Loss: 1.86, CombTr_Acc: 0.3, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 840, CombTr_Loss: 1.82, CombTr_Acc: 0.26, CVHum_Loss: 2.02, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 841, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 2.02, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 842, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 843, CombTr_Loss: 1.89, CombTr_Acc: 0.24, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 844, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 845, CombTr_Loss: 1.75, CombTr_Acc: 0.36, CVHum_Loss: 2.08, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 846, CombTr_Loss: 1.82, CombTr_Acc: 0.38, CVHum_Loss: 2.17, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 847, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 2.05, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 848, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 849, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.79, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 850, CombTr_Loss: 1.55, CombTr_Acc: 0.46, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 851, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 852, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 2.03, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 853, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 854, CombTr_Loss: 1.69, CombTr_Acc: 0.3, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 855, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 856, CombTr_Loss: 1.71, CombTr_Acc: 0.36, CVHum_Loss: 1.43, CVHum_Acc: 0.46 \n",
      "Epoch: 2, Step: 857, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 858, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 859, CombTr_Loss: 1.78, CombTr_Acc: 0.28, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 860, CombTr_Loss: 1.87, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 861, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 862, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 863, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 864, CombTr_Loss: 1.89, CombTr_Acc: 0.26, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 865, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 866, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 867, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 868, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 869, CombTr_Loss: 1.79, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 870, CombTr_Loss: 1.7, CombTr_Acc: 0.2, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 871, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 872, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 873, CombTr_Loss: 1.83, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 874, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 875, CombTr_Loss: 1.91, CombTr_Acc: 0.22, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 876, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 877, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 878, CombTr_Loss: 1.84, CombTr_Acc: 0.24, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 879, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 880, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 881, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 2.0, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 882, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 883, CombTr_Loss: 1.68, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 884, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 885, CombTr_Loss: 1.73, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 886, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 887, CombTr_Loss: 1.84, CombTr_Acc: 0.16, CVHum_Loss: 1.86, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 888, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 889, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 890, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 891, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 892, CombTr_Loss: 1.84, CombTr_Acc: 0.24, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 893, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 894, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 895, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.6, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 896, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 897, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 898, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 899, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 900, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 901, CombTr_Loss: 1.63, CombTr_Acc: 0.3, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 902, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 903, CombTr_Loss: 1.56, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 904, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 905, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 2.15, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 906, CombTr_Loss: 1.86, CombTr_Acc: 0.22, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 907, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 908, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 909, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 2.05, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 910, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 911, CombTr_Loss: 1.46, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 912, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 913, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 914, CombTr_Loss: 1.73, CombTr_Acc: 0.28, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 915, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 2.07, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 916, CombTr_Loss: 1.62, CombTr_Acc: 0.44, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 917, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 918, CombTr_Loss: 1.82, CombTr_Acc: 0.34, CVHum_Loss: 1.79, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 919, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 920, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 921, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 922, CombTr_Loss: 1.81, CombTr_Acc: 0.26, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 923, CombTr_Loss: 1.83, CombTr_Acc: 0.24, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 924, CombTr_Loss: 1.64, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 925, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.48, CVHum_Acc: 0.58 \n",
      "Epoch: 2, Step: 926, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 927, CombTr_Loss: 1.87, CombTr_Acc: 0.3, CVHum_Loss: 1.79, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 928, CombTr_Loss: 1.71, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 929, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 930, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 931, CombTr_Loss: 1.71, CombTr_Acc: 0.26, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 932, CombTr_Loss: 1.77, CombTr_Acc: 0.24, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 933, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 934, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 935, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 936, CombTr_Loss: 1.71, CombTr_Acc: 0.28, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 937, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 938, CombTr_Loss: 1.68, CombTr_Acc: 0.36, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 939, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 940, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 941, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 942, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 943, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 944, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 945, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 946, CombTr_Loss: 1.79, CombTr_Acc: 0.22, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 947, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 948, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 949, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 950, CombTr_Loss: 1.74, CombTr_Acc: 0.34, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 951, CombTr_Loss: 1.78, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 952, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 953, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 954, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 955, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 956, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 957, CombTr_Loss: 1.72, CombTr_Acc: 0.28, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 958, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 959, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 960, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 961, CombTr_Loss: 1.72, CombTr_Acc: 0.24, CVHum_Loss: 1.89, CVHum_Acc: 0.14 \n",
      "Epoch: 2, Step: 962, CombTr_Loss: 1.78, CombTr_Acc: 0.3, CVHum_Loss: 1.73, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 963, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 964, CombTr_Loss: 1.91, CombTr_Acc: 0.28, CVHum_Loss: 1.7, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 965, CombTr_Loss: 1.77, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 966, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.67, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 967, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 968, CombTr_Loss: 1.57, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 969, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 970, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 971, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 972, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 973, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 974, CombTr_Loss: 1.91, CombTr_Acc: 0.22, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 975, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 976, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 977, CombTr_Loss: 1.82, CombTr_Acc: 0.2, CVHum_Loss: 1.87, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 978, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 979, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 980, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 981, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 982, CombTr_Loss: 1.93, CombTr_Acc: 0.18, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 983, CombTr_Loss: 1.84, CombTr_Acc: 0.24, CVHum_Loss: 1.99, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 984, CombTr_Loss: 1.69, CombTr_Acc: 0.44, CVHum_Loss: 2.04, CVHum_Acc: 0.16 \n",
      "Epoch: 2, Step: 985, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 986, CombTr_Loss: 1.78, CombTr_Acc: 0.3, CVHum_Loss: 1.58, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 987, CombTr_Loss: 1.62, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 988, CombTr_Loss: 1.54, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 989, CombTr_Loss: 1.87, CombTr_Acc: 0.26, CVHum_Loss: 1.8, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 990, CombTr_Loss: 1.82, CombTr_Acc: 0.16, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 991, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 992, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 993, CombTr_Loss: 1.66, CombTr_Acc: 0.42, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 2, Step: 994, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 2, Step: 995, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 996, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 997, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 998, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 999, CombTr_Loss: 1.78, CombTr_Acc: 0.24, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 1000, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 1001, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 1002, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 1003, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 1004, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 2, Step: 1005, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 1006, CombTr_Loss: 1.75, CombTr_Acc: 0.24, CVHum_Loss: 1.52, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 1007, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 2, Step: 1008, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 1009, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 1010, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 1011, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 1012, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 1013, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 2, Step: 1014, CombTr_Loss: 1.59, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 2, Step: 1015, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.49, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 1016, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 1017, CombTr_Loss: 1.84, CombTr_Acc: 0.32, CVHum_Loss: 1.61, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 1018, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 1019, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 1020, CombTr_Loss: 1.78, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 1021, CombTr_Loss: 1.9, CombTr_Acc: 0.26, CVHum_Loss: 1.59, CVHum_Acc: 0.5 \n",
      "Epoch: 2, Step: 1022, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 1023, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.78, CVHum_Acc: 0.42 \n",
      "Epoch: 2, Step: 1024, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 1025, CombTr_Loss: 1.82, CombTr_Acc: 0.32, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 2, Step: 1026, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 2, Step: 1027, CombTr_Loss: 1.65, CombTr_Acc: 0.26, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 1028, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.14 \n",
      "Epoch: 2, Step: 1029, CombTr_Loss: 1.54, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 2, Step: 1030, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.2 \n",
      "Epoch: 2, Step: 1031, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 2, Step: 1032, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 2, Step: 1033, CombTr_Loss: 1.59, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.18 \n",
      "Epoch: 2, Step: 1034, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 2, Step: 1035, CombTr_Loss: 1.6, CombTr_Acc: 0.3, CVHum_Loss: 1.63, CVHum_Acc: 0.28 \n",
      "Avg_CombTrain_Loss: 1.69, Avg_CombTrain_Acc: 0.33, Avg_CVHum_Loss: 1.77, Avg_CVHum_Acc: 0.29 \n",
      "Model and weights saved at epoch 2\n",
      "Epoch: 3, Step: 1036, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1037, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1038, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.16 \n",
      "Epoch: 3, Step: 1039, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1040, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1041, CombTr_Loss: 1.65, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1042, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1043, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1044, CombTr_Loss: 1.6, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1045, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1046, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1047, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1048, CombTr_Loss: 1.7, CombTr_Acc: 0.24, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1049, CombTr_Loss: 1.69, CombTr_Acc: 0.26, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1050, CombTr_Loss: 1.82, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1051, CombTr_Loss: 1.79, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1052, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1053, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.96, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1054, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1055, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1056, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1057, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1058, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1059, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1060, CombTr_Loss: 1.57, CombTr_Acc: 0.26, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1061, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1062, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1063, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.47, CVHum_Acc: 0.46 \n",
      "Epoch: 3, Step: 1064, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1065, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1066, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.83, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1067, CombTr_Loss: 1.7, CombTr_Acc: 0.26, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1068, CombTr_Loss: 1.76, CombTr_Acc: 0.28, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1069, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1070, CombTr_Loss: 1.69, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1071, CombTr_Loss: 1.9, CombTr_Acc: 0.18, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1072, CombTr_Loss: 1.62, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1073, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.55, CVHum_Acc: 0.48 \n",
      "Epoch: 3, Step: 1074, CombTr_Loss: 1.81, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1075, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1076, CombTr_Loss: 1.77, CombTr_Acc: 0.22, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1077, CombTr_Loss: 1.87, CombTr_Acc: 0.28, CVHum_Loss: 2.07, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1078, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 2.43, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1079, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 2.3, CVHum_Acc: 0.16 \n",
      "Epoch: 3, Step: 1080, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 2.05, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1081, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 2.33, CVHum_Acc: 0.14 \n",
      "Epoch: 3, Step: 1082, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 2.27, CVHum_Acc: 0.16 \n",
      "Epoch: 3, Step: 1083, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1084, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1085, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 2.12, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1086, CombTr_Loss: 1.7, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.14 \n",
      "Epoch: 3, Step: 1087, CombTr_Loss: 1.4, CombTr_Acc: 0.54, CVHum_Loss: 2.06, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1088, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.99, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1089, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 2.01, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1090, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1091, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1092, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1093, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1094, CombTr_Loss: 1.66, CombTr_Acc: 0.4, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1095, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1096, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1097, CombTr_Loss: 1.8, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1098, CombTr_Loss: 1.72, CombTr_Acc: 0.22, CVHum_Loss: 1.9, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1099, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1100, CombTr_Loss: 1.57, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1101, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1102, CombTr_Loss: 1.57, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1103, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1104, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1105, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1106, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1107, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1108, CombTr_Loss: 1.78, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1109, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 2.0, CVHum_Acc: 0.14 \n",
      "Epoch: 3, Step: 1110, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1111, CombTr_Loss: 1.82, CombTr_Acc: 0.24, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1112, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1113, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1114, CombTr_Loss: 1.56, CombTr_Acc: 0.28, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1115, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1116, CombTr_Loss: 1.62, CombTr_Acc: 0.24, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1117, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1118, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1119, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1120, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1121, CombTr_Loss: 1.65, CombTr_Acc: 0.28, CVHum_Loss: 1.99, CVHum_Acc: 0.12 \n",
      "Epoch: 3, Step: 1122, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 2.1, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1123, CombTr_Loss: 1.68, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1124, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1125, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1126, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1127, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1128, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 2.17, CVHum_Acc: 0.14 \n",
      "Epoch: 3, Step: 1129, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1130, CombTr_Loss: 1.73, CombTr_Acc: 0.36, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1131, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1132, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1133, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 2.03, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1134, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1135, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1136, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1137, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1138, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 2.02, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1139, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1140, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1141, CombTr_Loss: 1.63, CombTr_Acc: 0.24, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1142, CombTr_Loss: 1.5, CombTr_Acc: 0.34, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1143, CombTr_Loss: 2.1, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1144, CombTr_Loss: 1.79, CombTr_Acc: 0.28, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1145, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1146, CombTr_Loss: 1.71, CombTr_Acc: 0.28, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1147, CombTr_Loss: 1.9, CombTr_Acc: 0.28, CVHum_Loss: 1.95, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1148, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1149, CombTr_Loss: 1.83, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1150, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1151, CombTr_Loss: 1.71, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1152, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1153, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1154, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1155, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1156, CombTr_Loss: 1.61, CombTr_Acc: 0.3, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1157, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1158, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1159, CombTr_Loss: 1.76, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.48 \n",
      "Epoch: 3, Step: 1160, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1161, CombTr_Loss: 1.82, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1162, CombTr_Loss: 1.7, CombTr_Acc: 0.24, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1163, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1164, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1165, CombTr_Loss: 1.57, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1166, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1167, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 2.01, CVHum_Acc: 0.14 \n",
      "Epoch: 3, Step: 1168, CombTr_Loss: 1.77, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1169, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1170, CombTr_Loss: 1.79, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1171, CombTr_Loss: 1.51, CombTr_Acc: 0.5, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1172, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1173, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1174, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1175, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1176, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1177, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1178, CombTr_Loss: 1.69, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1179, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1180, CombTr_Loss: 1.81, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1181, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1182, CombTr_Loss: 1.54, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1183, CombTr_Loss: 1.71, CombTr_Acc: 0.22, CVHum_Loss: 1.57, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1184, CombTr_Loss: 1.77, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1185, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1186, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1187, CombTr_Loss: 1.66, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1188, CombTr_Loss: 1.86, CombTr_Acc: 0.24, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1189, CombTr_Loss: 1.66, CombTr_Acc: 0.2, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1190, CombTr_Loss: 1.65, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1191, CombTr_Loss: 1.81, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1192, CombTr_Loss: 1.73, CombTr_Acc: 0.24, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1193, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1194, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1195, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1196, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1197, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1198, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 1.47, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1199, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1200, CombTr_Loss: 1.62, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1201, CombTr_Loss: 1.69, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 3, Step: 1202, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1203, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1204, CombTr_Loss: 1.78, CombTr_Acc: 0.26, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1205, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1206, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.64, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1207, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1208, CombTr_Loss: 1.61, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1209, CombTr_Loss: 1.89, CombTr_Acc: 0.24, CVHum_Loss: 1.66, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1210, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1211, CombTr_Loss: 1.72, CombTr_Acc: 0.28, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1212, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1213, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1214, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1215, CombTr_Loss: 1.71, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1216, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1217, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1218, CombTr_Loss: 1.84, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1219, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.83, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1220, CombTr_Loss: 2.03, CombTr_Acc: 0.22, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1221, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1222, CombTr_Loss: 1.77, CombTr_Acc: 0.24, CVHum_Loss: 1.53, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1223, CombTr_Loss: 1.79, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1224, CombTr_Loss: 1.73, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1225, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 3, Step: 1226, CombTr_Loss: 1.65, CombTr_Acc: 0.3, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1227, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1228, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.48 \n",
      "Epoch: 3, Step: 1229, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.58, CVHum_Acc: 0.5 \n",
      "Epoch: 3, Step: 1230, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1231, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1232, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1233, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1234, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1235, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1236, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1237, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.71, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1238, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1239, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1240, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.66, CVHum_Acc: 0.48 \n",
      "Epoch: 3, Step: 1241, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1242, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1243, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1244, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1245, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1246, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1247, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1248, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1249, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1250, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1251, CombTr_Loss: 1.92, CombTr_Acc: 0.24, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1252, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.18 \n",
      "Epoch: 3, Step: 1253, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1254, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1255, CombTr_Loss: 1.53, CombTr_Acc: 0.32, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1256, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1257, CombTr_Loss: 1.84, CombTr_Acc: 0.32, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1258, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1259, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1260, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1261, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1262, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.56, CVHum_Acc: 0.46 \n",
      "Epoch: 3, Step: 1263, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1264, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1265, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1266, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1267, CombTr_Loss: 1.78, CombTr_Acc: 0.24, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1268, CombTr_Loss: 1.75, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1269, CombTr_Loss: 1.55, CombTr_Acc: 0.28, CVHum_Loss: 1.66, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1270, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.42, CVHum_Acc: 0.56 \n",
      "Epoch: 3, Step: 1271, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1272, CombTr_Loss: 1.81, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1273, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1274, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1275, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1276, CombTr_Loss: 1.73, CombTr_Acc: 0.28, CVHum_Loss: 1.79, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1277, CombTr_Loss: 1.74, CombTr_Acc: 0.24, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1278, CombTr_Loss: 1.55, CombTr_Acc: 0.3, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1279, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1280, CombTr_Loss: 1.75, CombTr_Acc: 0.4, CVHum_Loss: 1.49, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1281, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1282, CombTr_Loss: 1.72, CombTr_Acc: 0.24, CVHum_Loss: 1.51, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1283, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1284, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1285, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.95, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1286, CombTr_Loss: 1.78, CombTr_Acc: 0.3, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1287, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1288, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1289, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1290, CombTr_Loss: 1.69, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1291, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1292, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1293, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1294, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1295, CombTr_Loss: 1.65, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1296, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1297, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1298, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.53, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1299, CombTr_Loss: 1.73, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1300, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1301, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1302, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1303, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1304, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1305, CombTr_Loss: 1.74, CombTr_Acc: 0.22, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1306, CombTr_Loss: 1.75, CombTr_Acc: 0.28, CVHum_Loss: 1.91, CVHum_Acc: 0.16 \n",
      "Epoch: 3, Step: 1307, CombTr_Loss: 1.78, CombTr_Acc: 0.2, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 3, Step: 1308, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1309, CombTr_Loss: 1.82, CombTr_Acc: 0.22, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1310, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1311, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1312, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1313, CombTr_Loss: 1.52, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1314, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1315, CombTr_Loss: 1.74, CombTr_Acc: 0.26, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1316, CombTr_Loss: 1.59, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1317, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 1.5, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1318, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1319, CombTr_Loss: 1.89, CombTr_Acc: 0.28, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1320, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1321, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1322, CombTr_Loss: 1.78, CombTr_Acc: 0.2, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1323, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1324, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1325, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1326, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1327, CombTr_Loss: 1.94, CombTr_Acc: 0.2, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1328, CombTr_Loss: 1.8, CombTr_Acc: 0.18, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1329, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 2.02, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1330, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1331, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.51, CVHum_Acc: 0.48 \n",
      "Epoch: 3, Step: 1332, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1333, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 1.57, CVHum_Acc: 0.46 \n",
      "Epoch: 3, Step: 1334, CombTr_Loss: 1.84, CombTr_Acc: 0.18, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1335, CombTr_Loss: 1.89, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1336, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.57, CVHum_Acc: 0.56 \n",
      "Epoch: 3, Step: 1337, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1338, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1339, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1340, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1341, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1342, CombTr_Loss: 1.65, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1343, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1344, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1345, CombTr_Loss: 1.7, CombTr_Acc: 0.26, CVHum_Loss: 1.73, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1346, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 3, Step: 1347, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1348, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1349, CombTr_Loss: 1.44, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1350, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1351, CombTr_Loss: 1.71, CombTr_Acc: 0.28, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1352, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1353, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.93, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1354, CombTr_Loss: 1.83, CombTr_Acc: 0.22, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1355, CombTr_Loss: 1.64, CombTr_Acc: 0.44, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1356, CombTr_Loss: 1.39, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1357, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1358, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1359, CombTr_Loss: 1.51, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 3, Step: 1360, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1361, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1362, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1363, CombTr_Loss: 1.76, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1364, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 2.07, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1365, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1366, CombTr_Loss: 1.84, CombTr_Acc: 0.16, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 3, Step: 1367, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 3, Step: 1368, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1369, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1370, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 3, Step: 1371, CombTr_Loss: 1.57, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1372, CombTr_Loss: 1.66, CombTr_Acc: 0.26, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 3, Step: 1373, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.2 \n",
      "Epoch: 3, Step: 1374, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 3, Step: 1375, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 3, Step: 1376, CombTr_Loss: 1.74, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1377, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 3, Step: 1378, CombTr_Loss: 1.6, CombTr_Acc: 0.3, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 3, Step: 1379, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 3, Step: 1380, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Avg_CombTrain_Loss: 1.65, Avg_CombTrain_Acc: 0.35, Avg_CVHum_Loss: 1.75, Avg_CVHum_Acc: 0.31 \n",
      "Model and weights saved at epoch 3\n",
      "Epoch: 4, Step: 1381, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1382, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1383, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1384, CombTr_Loss: 1.61, CombTr_Acc: 0.2, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1385, CombTr_Loss: 1.64, CombTr_Acc: 0.26, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1386, CombTr_Loss: 1.56, CombTr_Acc: 0.48, CVHum_Loss: 1.47, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1387, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1388, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1389, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1390, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.61, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1391, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1392, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1393, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1394, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1395, CombTr_Loss: 1.83, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1396, CombTr_Loss: 1.77, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1397, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1398, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 2.04, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1399, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1400, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1401, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1402, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1403, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1404, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1405, CombTr_Loss: 1.63, CombTr_Acc: 0.3, CVHum_Loss: 1.56, CVHum_Acc: 0.48 \n",
      "Epoch: 4, Step: 1406, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1407, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1408, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.47, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1409, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1410, CombTr_Loss: 1.48, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1411, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1412, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1413, CombTr_Loss: 1.79, CombTr_Acc: 0.26, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1414, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1415, CombTr_Loss: 1.76, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1416, CombTr_Loss: 1.86, CombTr_Acc: 0.2, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1417, CombTr_Loss: 1.52, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1418, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 4, Step: 1419, CombTr_Loss: 1.8, CombTr_Acc: 0.3, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1420, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1421, CombTr_Loss: 1.71, CombTr_Acc: 0.2, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1422, CombTr_Loss: 1.83, CombTr_Acc: 0.32, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1423, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 2.01, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1424, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1425, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1426, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1427, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1428, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1429, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1430, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1431, CombTr_Loss: 1.71, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1432, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1433, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1434, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1435, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1436, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1437, CombTr_Loss: 1.63, CombTr_Acc: 0.24, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1438, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1439, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1440, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1441, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1442, CombTr_Loss: 1.75, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1443, CombTr_Loss: 1.74, CombTr_Acc: 0.26, CVHum_Loss: 2.03, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1444, CombTr_Loss: 1.63, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1445, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1446, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1447, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1448, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1449, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1450, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1451, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1452, CombTr_Loss: 1.73, CombTr_Acc: 0.38, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1453, CombTr_Loss: 1.72, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1454, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.88, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1455, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.47, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1456, CombTr_Loss: 1.75, CombTr_Acc: 0.24, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1457, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1458, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1459, CombTr_Loss: 1.61, CombTr_Acc: 0.28, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1460, CombTr_Loss: 1.69, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1461, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 2.01, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1462, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1463, CombTr_Loss: 1.73, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1464, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1465, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1466, CombTr_Loss: 1.61, CombTr_Acc: 0.26, CVHum_Loss: 1.94, CVHum_Acc: 0.16 \n",
      "Epoch: 4, Step: 1467, CombTr_Loss: 1.51, CombTr_Acc: 0.48, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 4, Step: 1468, CombTr_Loss: 1.64, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1469, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 4, Step: 1470, CombTr_Loss: 1.63, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1471, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1472, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1473, CombTr_Loss: 1.63, CombTr_Acc: 0.24, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1474, CombTr_Loss: 1.63, CombTr_Acc: 0.24, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1475, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1476, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.61, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1477, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1478, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1479, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1480, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1481, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1482, CombTr_Loss: 1.57, CombTr_Acc: 0.3, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1483, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1484, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1485, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1486, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1487, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1488, CombTr_Loss: 1.99, CombTr_Acc: 0.3, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1489, CombTr_Loss: 1.7, CombTr_Acc: 0.24, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1490, CombTr_Loss: 1.74, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1491, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1492, CombTr_Loss: 1.86, CombTr_Acc: 0.36, CVHum_Loss: 2.0, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1493, CombTr_Loss: 1.66, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1494, CombTr_Loss: 1.71, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1495, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1496, CombTr_Loss: 1.69, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1497, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1498, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1499, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1500, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1501, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1502, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1503, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 2.0, CVHum_Acc: 0.18 \n",
      "Epoch: 4, Step: 1504, CombTr_Loss: 1.72, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.5 \n",
      "Epoch: 4, Step: 1505, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.53, CVHum_Acc: 0.46 \n",
      "Epoch: 4, Step: 1506, CombTr_Loss: 1.73, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1507, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1508, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1509, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1510, CombTr_Loss: 1.5, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1511, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1512, CombTr_Loss: 1.72, CombTr_Acc: 0.28, CVHum_Loss: 1.97, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1513, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.16 \n",
      "Epoch: 4, Step: 1514, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1515, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1516, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1517, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1518, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1519, CombTr_Loss: 1.74, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1520, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1521, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1522, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1523, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1524, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1525, CombTr_Loss: 1.71, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1526, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1527, CombTr_Loss: 1.57, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1528, CombTr_Loss: 1.69, CombTr_Acc: 0.24, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1529, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1530, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1531, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1532, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1533, CombTr_Loss: 1.86, CombTr_Acc: 0.2, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1534, CombTr_Loss: 1.61, CombTr_Acc: 0.28, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1535, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.89, CVHum_Acc: 0.18 \n",
      "Epoch: 4, Step: 1536, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 2.08, CVHum_Acc: 0.16 \n",
      "Epoch: 4, Step: 1537, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1538, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1539, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1540, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1541, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1542, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1543, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1544, CombTr_Loss: 1.6, CombTr_Acc: 0.28, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1545, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1546, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1547, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1548, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1549, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1550, CombTr_Loss: 1.81, CombTr_Acc: 0.34, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1551, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1552, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1553, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1554, CombTr_Loss: 1.79, CombTr_Acc: 0.36, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1555, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1556, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1557, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1558, CombTr_Loss: 1.53, CombTr_Acc: 0.48, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1559, CombTr_Loss: 1.72, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1560, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1561, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1562, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1563, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1564, CombTr_Loss: 1.53, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1565, CombTr_Loss: 1.94, CombTr_Acc: 0.24, CVHum_Loss: 1.57, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1566, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1567, CombTr_Loss: 1.69, CombTr_Acc: 0.22, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1568, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1569, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1570, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1571, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1572, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1573, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 4, Step: 1574, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1575, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1576, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1577, CombTr_Loss: 1.84, CombTr_Acc: 0.3, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1578, CombTr_Loss: 1.5, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1579, CombTr_Loss: 1.5, CombTr_Acc: 0.54, CVHum_Loss: 1.43, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1580, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1581, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1582, CombTr_Loss: 1.82, CombTr_Acc: 0.24, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1583, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1584, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1585, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1586, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1587, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1588, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1589, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1590, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1591, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1592, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1593, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1594, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1595, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.99, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1596, CombTr_Loss: 1.91, CombTr_Acc: 0.22, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1597, CombTr_Loss: 1.7, CombTr_Acc: 0.26, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1598, CombTr_Loss: 1.59, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1599, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.99, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1600, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1601, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1602, CombTr_Loss: 1.76, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1603, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1604, CombTr_Loss: 1.59, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1605, CombTr_Loss: 1.68, CombTr_Acc: 0.36, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1606, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1607, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1608, CombTr_Loss: 1.64, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1609, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1610, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1611, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1612, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1613, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1614, CombTr_Loss: 1.54, CombTr_Acc: 0.24, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1615, CombTr_Loss: 1.55, CombTr_Acc: 0.3, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1616, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1617, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1618, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 2.99, CVHum_Acc: 0.14 \n",
      "Epoch: 4, Step: 1619, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 3.06, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1620, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 2.83, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1621, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 2.51, CVHum_Acc: 0.16 \n",
      "Epoch: 4, Step: 1622, CombTr_Loss: 1.69, CombTr_Acc: 0.26, CVHum_Loss: 2.16, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1623, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 2.47, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1624, CombTr_Loss: 1.3, CombTr_Acc: 0.44, CVHum_Loss: 2.42, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1625, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 2.12, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1626, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 2.51, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1627, CombTr_Loss: 1.67, CombTr_Acc: 0.26, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1628, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 2.12, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1629, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 2.19, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1630, CombTr_Loss: 1.51, CombTr_Acc: 0.48, CVHum_Loss: 2.27, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1631, CombTr_Loss: 1.75, CombTr_Acc: 0.36, CVHum_Loss: 2.26, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1632, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1633, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1634, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1635, CombTr_Loss: 1.66, CombTr_Acc: 0.38, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1636, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1637, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1638, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1639, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1640, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.97, CVHum_Acc: 0.16 \n",
      "Epoch: 4, Step: 1641, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1642, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1643, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1644, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1645, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1646, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1647, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1648, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1649, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1650, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1651, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 2.03, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1652, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1653, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1654, CombTr_Loss: 1.82, CombTr_Acc: 0.26, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1655, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1656, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1657, CombTr_Loss: 1.72, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1658, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1659, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1660, CombTr_Loss: 1.73, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1661, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1662, CombTr_Loss: 1.72, CombTr_Acc: 0.28, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1663, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1664, CombTr_Loss: 1.82, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1665, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1666, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.81, CVHum_Acc: 0.2 \n",
      "Epoch: 4, Step: 1667, CombTr_Loss: 1.79, CombTr_Acc: 0.18, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1668, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1669, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1670, CombTr_Loss: 1.79, CombTr_Acc: 0.32, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1671, CombTr_Loss: 1.61, CombTr_Acc: 0.24, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1672, CombTr_Loss: 1.92, CombTr_Acc: 0.2, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1673, CombTr_Loss: 1.76, CombTr_Acc: 0.24, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1674, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 2.07, CVHum_Acc: 0.14 \n",
      "Epoch: 4, Step: 1675, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1676, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.49, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1677, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1678, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1679, CombTr_Loss: 1.81, CombTr_Acc: 0.3, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1680, CombTr_Loss: 1.81, CombTr_Acc: 0.32, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1681, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1682, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1683, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1684, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1685, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1686, CombTr_Loss: 1.51, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 4, Step: 1687, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1688, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1689, CombTr_Loss: 1.75, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1690, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1691, CombTr_Loss: 1.56, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1692, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1693, CombTr_Loss: 1.5, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 4, Step: 1694, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1695, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1696, CombTr_Loss: 1.76, CombTr_Acc: 0.2, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 4, Step: 1697, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1698, CombTr_Loss: 1.7, CombTr_Acc: 0.24, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1699, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 4, Step: 1700, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1701, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1702, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1703, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1704, CombTr_Loss: 1.48, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1705, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.49, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1706, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1707, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 4, Step: 1708, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1709, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.97, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1710, CombTr_Loss: 1.73, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1711, CombTr_Loss: 1.81, CombTr_Acc: 0.2, CVHum_Loss: 1.63, CVHum_Acc: 0.44 \n",
      "Epoch: 4, Step: 1712, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1713, CombTr_Loss: 1.66, CombTr_Acc: 0.24, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 4, Step: 1714, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1715, CombTr_Loss: 1.74, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1716, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1717, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 4, Step: 1718, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 4, Step: 1719, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1720, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 4, Step: 1721, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1722, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 4, Step: 1723, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 4, Step: 1724, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.24 \n",
      "Epoch: 4, Step: 1725, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Avg_CombTrain_Loss: 1.61, Avg_CombTrain_Acc: 0.36, Avg_CVHum_Loss: 1.77, Avg_CVHum_Acc: 0.31 \n",
      "Model and weights saved at epoch 4\n",
      "Epoch: 5, Step: 1726, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1727, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.99, CVHum_Acc: 0.16 \n",
      "Epoch: 5, Step: 1728, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1729, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1730, CombTr_Loss: 1.67, CombTr_Acc: 0.26, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1731, CombTr_Loss: 1.6, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1732, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1733, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1734, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1735, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1736, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1737, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1738, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1739, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1740, CombTr_Loss: 1.81, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1741, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1742, CombTr_Loss: 1.51, CombTr_Acc: 0.52, CVHum_Loss: 1.87, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1743, CombTr_Loss: 1.64, CombTr_Acc: 0.26, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1744, CombTr_Loss: 1.54, CombTr_Acc: 0.3, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1745, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1746, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1747, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1748, CombTr_Loss: 1.72, CombTr_Acc: 0.24, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1749, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1750, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1751, CombTr_Loss: 1.73, CombTr_Acc: 0.26, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1752, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1753, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1754, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1755, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1756, CombTr_Loss: 1.67, CombTr_Acc: 0.26, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1757, CombTr_Loss: 1.69, CombTr_Acc: 0.26, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1758, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1759, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1760, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1761, CombTr_Loss: 1.81, CombTr_Acc: 0.24, CVHum_Loss: 1.58, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1762, CombTr_Loss: 1.49, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1763, CombTr_Loss: 1.43, CombTr_Acc: 0.52, CVHum_Loss: 1.55, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1764, CombTr_Loss: 1.72, CombTr_Acc: 0.28, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1765, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.56, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1766, CombTr_Loss: 1.67, CombTr_Acc: 0.22, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1767, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1768, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 2.15, CVHum_Acc: 0.1 \n",
      "Epoch: 5, Step: 1769, CombTr_Loss: 1.57, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1770, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1771, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.16 \n",
      "Epoch: 5, Step: 1772, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1773, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1774, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1775, CombTr_Loss: 1.52, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1776, CombTr_Loss: 1.6, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1777, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1778, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1779, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1780, CombTr_Loss: 1.58, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1781, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1782, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1783, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1784, CombTr_Loss: 1.55, CombTr_Acc: 0.48, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1785, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1786, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.53, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1787, CombTr_Loss: 1.77, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1788, CombTr_Loss: 1.73, CombTr_Acc: 0.32, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1789, CombTr_Loss: 1.63, CombTr_Acc: 0.28, CVHum_Loss: 1.82, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1790, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1791, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1792, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.58, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1793, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1794, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1795, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1796, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1797, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1798, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1799, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1800, CombTr_Loss: 1.34, CombTr_Acc: 0.42, CVHum_Loss: 1.42, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1801, CombTr_Loss: 1.76, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1802, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1803, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1804, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1805, CombTr_Loss: 1.7, CombTr_Acc: 0.26, CVHum_Loss: 1.73, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1806, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1807, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1808, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1809, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1810, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1811, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.16 \n",
      "Epoch: 5, Step: 1812, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 2.07, CVHum_Acc: 0.16 \n",
      "Epoch: 5, Step: 1813, CombTr_Loss: 1.63, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1814, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1815, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1816, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1817, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1818, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1819, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1820, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1821, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1822, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.42, CVHum_Acc: 0.46 \n",
      "Epoch: 5, Step: 1823, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1824, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1825, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1826, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1827, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1828, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1829, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1830, CombTr_Loss: 1.69, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1831, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1832, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1833, CombTr_Loss: 1.96, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1834, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.45, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1835, CombTr_Loss: 1.8, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1836, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1837, CombTr_Loss: 1.8, CombTr_Acc: 0.42, CVHum_Loss: 2.03, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1838, CombTr_Loss: 1.65, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1839, CombTr_Loss: 1.68, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1840, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1841, CombTr_Loss: 1.58, CombTr_Acc: 0.46, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1842, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1843, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1844, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1845, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1846, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1847, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1848, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.98, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1849, CombTr_Loss: 1.69, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1850, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.54 \n",
      "Epoch: 5, Step: 1851, CombTr_Loss: 1.72, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1852, CombTr_Loss: 1.66, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1853, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1854, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1855, CombTr_Loss: 1.49, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1856, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1857, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1858, CombTr_Loss: 1.58, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1859, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.46 \n",
      "Epoch: 5, Step: 1860, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1861, CombTr_Loss: 1.45, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1862, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1863, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1864, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1865, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1866, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1867, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1868, CombTr_Loss: 1.57, CombTr_Acc: 0.44, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1869, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1870, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1871, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1872, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1873, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.62, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1874, CombTr_Loss: 1.72, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1875, CombTr_Loss: 1.6, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1876, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1877, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1878, CombTr_Loss: 1.76, CombTr_Acc: 0.28, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1879, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1880, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1881, CombTr_Loss: 1.76, CombTr_Acc: 0.38, CVHum_Loss: 2.12, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1882, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1883, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1884, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1885, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.53, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1886, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1887, CombTr_Loss: 1.67, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1888, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1889, CombTr_Loss: 1.59, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1890, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1891, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.49, CVHum_Acc: 0.5 \n",
      "Epoch: 5, Step: 1892, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1893, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1894, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 5, Step: 1895, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1896, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1897, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1898, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1899, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1900, CombTr_Loss: 1.45, CombTr_Acc: 0.52, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1901, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1902, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1903, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1904, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1905, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1906, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 2.02, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1907, CombTr_Loss: 1.63, CombTr_Acc: 0.28, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1908, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1909, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1910, CombTr_Loss: 1.97, CombTr_Acc: 0.28, CVHum_Loss: 1.7, CVHum_Acc: 0.46 \n",
      "Epoch: 5, Step: 1911, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 2.15, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1912, CombTr_Loss: 1.68, CombTr_Acc: 0.24, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1913, CombTr_Loss: 1.68, CombTr_Acc: 0.42, CVHum_Loss: 2.05, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1914, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1915, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1916, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 2.22, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1917, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1918, CombTr_Loss: 1.6, CombTr_Acc: 0.44, CVHum_Loss: 2.02, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1919, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 2.08, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1920, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 2.06, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1921, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 2.28, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1922, CombTr_Loss: 1.75, CombTr_Acc: 0.28, CVHum_Loss: 2.14, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1923, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 2.14, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1924, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1925, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 2.02, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1926, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 2.23, CVHum_Acc: 0.14 \n",
      "Epoch: 5, Step: 1927, CombTr_Loss: 1.77, CombTr_Acc: 0.24, CVHum_Loss: 2.14, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1928, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 2.22, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1929, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1930, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1931, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1932, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1933, CombTr_Loss: 1.48, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1934, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.91, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1935, CombTr_Loss: 1.4, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1936, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.95, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1937, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1938, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1939, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1940, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.98, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1941, CombTr_Loss: 1.87, CombTr_Acc: 0.22, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 1942, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1943, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1944, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 2.21, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1945, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1946, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1947, CombTr_Loss: 1.77, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1948, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1949, CombTr_Loss: 1.55, CombTr_Acc: 0.28, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1950, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 2.19, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 1951, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1952, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1953, CombTr_Loss: 1.66, CombTr_Acc: 0.44, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1954, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.92, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 1955, CombTr_Loss: 1.54, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1956, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1957, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1958, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1959, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.92, CVHum_Acc: 0.16 \n",
      "Epoch: 5, Step: 1960, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1961, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 1962, CombTr_Loss: 1.8, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1963, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1964, CombTr_Loss: 1.44, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1965, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1966, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 1967, CombTr_Loss: 1.65, CombTr_Acc: 0.24, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1968, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1969, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1970, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1971, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1972, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1973, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1974, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1975, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 1976, CombTr_Loss: 1.68, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1977, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1978, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 1979, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1980, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1981, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1982, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1983, CombTr_Loss: 1.47, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1984, CombTr_Loss: 1.54, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1985, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1986, CombTr_Loss: 1.71, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1987, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1988, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 1989, CombTr_Loss: 1.73, CombTr_Acc: 0.3, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1990, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 1991, CombTr_Loss: 1.46, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1992, CombTr_Loss: 1.59, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 1993, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.54, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1994, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1995, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 1996, CombTr_Loss: 1.64, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 1997, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 1998, CombTr_Loss: 1.61, CombTr_Acc: 0.3, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 1999, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2000, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2001, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 2002, CombTr_Loss: 1.76, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2003, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2004, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2005, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2006, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2007, CombTr_Loss: 1.76, CombTr_Acc: 0.22, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2008, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 2009, CombTr_Loss: 1.83, CombTr_Acc: 0.28, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2010, CombTr_Loss: 1.49, CombTr_Acc: 0.5, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2011, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 2012, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2013, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 2014, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2015, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 2016, CombTr_Loss: 1.57, CombTr_Acc: 0.22, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2017, CombTr_Loss: 1.91, CombTr_Acc: 0.2, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2018, CombTr_Loss: 1.7, CombTr_Acc: 0.24, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2019, CombTr_Loss: 1.59, CombTr_Acc: 0.46, CVHum_Loss: 2.13, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 2020, CombTr_Loss: 1.54, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 2021, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2022, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2023, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2024, CombTr_Loss: 1.85, CombTr_Acc: 0.22, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 2025, CombTr_Loss: 1.8, CombTr_Acc: 0.2, CVHum_Loss: 1.95, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2026, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.5 \n",
      "Epoch: 5, Step: 2027, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2028, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2029, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2030, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2031, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2032, CombTr_Loss: 1.61, CombTr_Acc: 0.26, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 2033, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 2034, CombTr_Loss: 1.71, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2035, CombTr_Loss: 1.69, CombTr_Acc: 0.28, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 2036, CombTr_Loss: 1.51, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2037, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 5, Step: 2038, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 2039, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2040, CombTr_Loss: 1.5, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2041, CombTr_Loss: 1.65, CombTr_Acc: 0.28, CVHum_Loss: 1.49, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 2042, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2043, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2044, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.93, CVHum_Acc: 0.18 \n",
      "Epoch: 5, Step: 2045, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2046, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2047, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2048, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 5, Step: 2049, CombTr_Loss: 1.41, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2050, CombTr_Loss: 1.6, CombTr_Acc: 0.26, CVHum_Loss: 1.46, CVHum_Acc: 0.52 \n",
      "Epoch: 5, Step: 2051, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 5, Step: 2052, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2053, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 5, Step: 2054, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 2055, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 2056, CombTr_Loss: 1.77, CombTr_Acc: 0.26, CVHum_Loss: 1.5, CVHum_Acc: 0.52 \n",
      "Epoch: 5, Step: 2057, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 5, Step: 2058, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2059, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 5, Step: 2060, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 5, Step: 2061, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.22 \n",
      "Epoch: 5, Step: 2062, CombTr_Loss: 1.6, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2063, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 5, Step: 2064, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 5, Step: 2065, CombTr_Loss: 1.4, CombTr_Acc: 0.56, CVHum_Loss: 1.78, CVHum_Acc: 0.2 \n",
      "Epoch: 5, Step: 2066, CombTr_Loss: 1.61, CombTr_Acc: 0.28, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 5, Step: 2067, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 5, Step: 2068, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 2069, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 5, Step: 2070, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Avg_CombTrain_Loss: 1.58, Avg_CombTrain_Acc: 0.38, Avg_CVHum_Loss: 1.75, Avg_CVHum_Acc: 0.31 \n",
      "Model and weights saved at epoch 5\n",
      "Epoch: 6, Step: 2071, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.68, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2072, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 2.0, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2073, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2074, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2075, CombTr_Loss: 1.66, CombTr_Acc: 0.28, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2076, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2077, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2078, CombTr_Loss: 1.45, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2079, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2080, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2081, CombTr_Loss: 1.39, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2082, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2083, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2084, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2085, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2086, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2087, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2088, CombTr_Loss: 1.63, CombTr_Acc: 0.48, CVHum_Loss: 2.1, CVHum_Acc: 0.18 \n",
      "Epoch: 6, Step: 2089, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2090, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2091, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2092, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2093, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2094, CombTr_Loss: 1.52, CombTr_Acc: 0.46, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2095, CombTr_Loss: 1.63, CombTr_Acc: 0.34, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2096, CombTr_Loss: 1.71, CombTr_Acc: 0.24, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2097, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2098, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.47, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2099, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.56, CVHum_Acc: 0.48 \n",
      "Epoch: 6, Step: 2100, CombTr_Loss: 1.35, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2101, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2102, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2103, CombTr_Loss: 1.64, CombTr_Acc: 0.26, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2104, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2105, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2106, CombTr_Loss: 1.8, CombTr_Acc: 0.2, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2107, CombTr_Loss: 1.39, CombTr_Acc: 0.54, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2108, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2109, CombTr_Loss: 1.69, CombTr_Acc: 0.38, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2110, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2111, CombTr_Loss: 1.66, CombTr_Acc: 0.26, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2112, CombTr_Loss: 1.82, CombTr_Acc: 0.22, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2113, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 2.06, CVHum_Acc: 0.16 \n",
      "Epoch: 6, Step: 2114, CombTr_Loss: 1.55, CombTr_Acc: 0.3, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2115, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2116, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2117, CombTr_Loss: 1.59, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2118, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2119, CombTr_Loss: 1.54, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2120, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2121, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2122, CombTr_Loss: 1.29, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2123, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2124, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 2.01, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2125, CombTr_Loss: 1.57, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2126, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2127, CombTr_Loss: 1.54, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2128, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2129, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2130, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2131, CombTr_Loss: 1.48, CombTr_Acc: 0.32, CVHum_Loss: 1.46, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2132, CombTr_Loss: 1.68, CombTr_Acc: 0.24, CVHum_Loss: 1.71, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2133, CombTr_Loss: 1.67, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2134, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.2 \n",
      "Epoch: 6, Step: 2135, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2136, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2137, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2138, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2139, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2140, CombTr_Loss: 1.36, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2141, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2142, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2143, CombTr_Loss: 1.64, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2144, CombTr_Loss: 1.55, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2145, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.38, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2146, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2147, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2148, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2149, CombTr_Loss: 1.57, CombTr_Acc: 0.3, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2150, CombTr_Loss: 1.68, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2151, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 2.0, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2152, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2153, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2154, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2155, CombTr_Loss: 1.74, CombTr_Acc: 0.22, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2156, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2157, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 2.11, CVHum_Acc: 0.16 \n",
      "Epoch: 6, Step: 2158, CombTr_Loss: 1.63, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2159, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2160, CombTr_Loss: 1.59, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2161, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2162, CombTr_Loss: 1.47, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2163, CombTr_Loss: 1.6, CombTr_Acc: 0.28, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2164, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.43, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2165, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2166, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2167, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.5, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2168, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2169, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2170, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2171, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2172, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.61, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2173, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2174, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2175, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2176, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2177, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2178, CombTr_Loss: 1.91, CombTr_Acc: 0.32, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2179, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2180, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2181, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2182, CombTr_Loss: 1.82, CombTr_Acc: 0.28, CVHum_Loss: 2.04, CVHum_Acc: 0.16 \n",
      "Epoch: 6, Step: 2183, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2184, CombTr_Loss: 1.61, CombTr_Acc: 0.46, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2185, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2186, CombTr_Loss: 1.67, CombTr_Acc: 0.46, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2187, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2188, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2189, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2190, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2191, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2192, CombTr_Loss: 1.46, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2193, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.99, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2194, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.55, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2195, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2196, CombTr_Loss: 1.71, CombTr_Acc: 0.4, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2197, CombTr_Loss: 1.65, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2198, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2199, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2200, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2201, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2202, CombTr_Loss: 1.59, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2203, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2204, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2205, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2206, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2207, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2208, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2209, CombTr_Loss: 1.66, CombTr_Acc: 0.42, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2210, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2211, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2212, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2213, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2214, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2215, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2216, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2217, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2218, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.2 \n",
      "Epoch: 6, Step: 2219, CombTr_Loss: 1.78, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2220, CombTr_Loss: 1.57, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2221, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2222, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2223, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2224, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2225, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2226, CombTr_Loss: 1.61, CombTr_Acc: 0.5, CVHum_Loss: 2.09, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2227, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2228, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2229, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.2 \n",
      "Epoch: 6, Step: 2230, CombTr_Loss: 1.42, CombTr_Acc: 0.54, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2231, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2232, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2233, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2234, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2235, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2236, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.55, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2237, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2238, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2239, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2240, CombTr_Loss: 1.73, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2241, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2242, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2243, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2244, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2245, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2246, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2247, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2248, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2249, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2250, CombTr_Loss: 1.68, CombTr_Acc: 0.28, CVHum_Loss: 1.78, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2251, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2252, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2253, CombTr_Loss: 1.76, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2254, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2255, CombTr_Loss: 1.93, CombTr_Acc: 0.26, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2256, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2257, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.53, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2258, CombTr_Loss: 1.59, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2259, CombTr_Loss: 1.6, CombTr_Acc: 0.28, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2260, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.53, CVHum_Acc: 0.48 \n",
      "Epoch: 6, Step: 2261, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2262, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2263, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2264, CombTr_Loss: 1.39, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2265, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2266, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2267, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2268, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2269, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.48, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2270, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2271, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2272, CombTr_Loss: 1.83, CombTr_Acc: 0.28, CVHum_Loss: 1.84, CVHum_Acc: 0.18 \n",
      "Epoch: 6, Step: 2273, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.18 \n",
      "Epoch: 6, Step: 2274, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2275, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2276, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2277, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.57, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2278, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2279, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2280, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2281, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2282, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2283, CombTr_Loss: 1.47, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2284, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2285, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2286, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2287, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2288, CombTr_Loss: 1.5, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2289, CombTr_Loss: 1.45, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2290, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2291, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2292, CombTr_Loss: 1.7, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2293, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2294, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.8, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2295, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2296, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2297, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2298, CombTr_Loss: 1.58, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2299, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2300, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2301, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2302, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2303, CombTr_Loss: 1.68, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2304, CombTr_Loss: 1.47, CombTr_Acc: 0.3, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2305, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.5, CVHum_Acc: 0.54 \n",
      "Epoch: 6, Step: 2306, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2307, CombTr_Loss: 1.72, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2308, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2309, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2310, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2311, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2312, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2313, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2314, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2315, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.42, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2316, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2317, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.58, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2318, CombTr_Loss: 1.48, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2319, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2320, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.99, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2321, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2322, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2323, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2324, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2325, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2326, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.53, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2327, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2328, CombTr_Loss: 1.52, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2329, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2330, CombTr_Loss: 1.47, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2331, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2332, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2333, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2334, CombTr_Loss: 1.75, CombTr_Acc: 0.3, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2335, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2336, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2337, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2338, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.44, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2339, CombTr_Loss: 1.33, CombTr_Acc: 0.56, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2340, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2341, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2342, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2343, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2344, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2345, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2346, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2347, CombTr_Loss: 1.75, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2348, CombTr_Loss: 1.47, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2349, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2350, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2351, CombTr_Loss: 1.49, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2352, CombTr_Loss: 1.7, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2353, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2354, CombTr_Loss: 1.81, CombTr_Acc: 0.3, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2355, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2356, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2357, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2358, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2359, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2360, CombTr_Loss: 1.64, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2361, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2362, CombTr_Loss: 1.79, CombTr_Acc: 0.24, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2363, CombTr_Loss: 1.78, CombTr_Acc: 0.2, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2364, CombTr_Loss: 1.62, CombTr_Acc: 0.44, CVHum_Loss: 2.09, CVHum_Acc: 0.12 \n",
      "Epoch: 6, Step: 2365, CombTr_Loss: 1.52, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2366, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.42, CVHum_Acc: 0.48 \n",
      "Epoch: 6, Step: 2367, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2368, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 6, Step: 2369, CombTr_Loss: 1.7, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2370, CombTr_Loss: 1.79, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2371, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.48 \n",
      "Epoch: 6, Step: 2372, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2373, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2374, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2375, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2376, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2377, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2378, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2379, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2380, CombTr_Loss: 1.67, CombTr_Acc: 0.28, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2381, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2382, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.54, CVHum_Acc: 0.48 \n",
      "Epoch: 6, Step: 2383, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2384, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.5, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2385, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2386, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2387, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 6, Step: 2388, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2389, CombTr_Loss: 1.74, CombTr_Acc: 0.36, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2390, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2391, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2392, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2393, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2394, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2395, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2396, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2397, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2398, CombTr_Loss: 1.7, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 6, Step: 2399, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2400, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2401, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.6, CVHum_Acc: 0.46 \n",
      "Epoch: 6, Step: 2402, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2403, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2404, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 6, Step: 2405, CombTr_Loss: 1.72, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2406, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.72, CVHum_Acc: 0.22 \n",
      "Epoch: 6, Step: 2407, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 6, Step: 2408, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 6, Step: 2409, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 6, Step: 2410, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 6, Step: 2411, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 6, Step: 2412, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2413, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 6, Step: 2414, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 6, Step: 2415, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.51, CVHum_Acc: 0.34 \n",
      "Avg_CombTrain_Loss: 1.55, Avg_CombTrain_Acc: 0.39, Avg_CVHum_Loss: 1.7, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 6\n",
      "Epoch: 7, Step: 2416, CombTr_Loss: 1.52, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2417, CombTr_Loss: 1.52, CombTr_Acc: 0.3, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2418, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2419, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2420, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2421, CombTr_Loss: 1.56, CombTr_Acc: 0.46, CVHum_Loss: 1.48, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2422, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2423, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2424, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2425, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2426, CombTr_Loss: 1.38, CombTr_Acc: 0.54, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2427, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2428, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.61, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2429, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2430, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2431, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2432, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2433, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2434, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2435, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2436, CombTr_Loss: 1.33, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.16 \n",
      "Epoch: 7, Step: 2437, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2438, CombTr_Loss: 1.65, CombTr_Acc: 0.28, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2439, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2440, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2441, CombTr_Loss: 1.65, CombTr_Acc: 0.28, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2442, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2443, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.39, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2444, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2445, CombTr_Loss: 1.33, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2446, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2447, CombTr_Loss: 1.53, CombTr_Acc: 0.32, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2448, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2449, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2450, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2451, CombTr_Loss: 1.69, CombTr_Acc: 0.2, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2452, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2453, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.55, CVHum_Acc: 0.46 \n",
      "Epoch: 7, Step: 2454, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2455, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.56, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2456, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2457, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2458, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 2.02, CVHum_Acc: 0.2 \n",
      "Epoch: 7, Step: 2459, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2460, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2461, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2462, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2463, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2464, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2465, CombTr_Loss: 1.49, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2466, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.18 \n",
      "Epoch: 7, Step: 2467, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2468, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2469, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 7, Step: 2470, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2471, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2472, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2473, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2474, CombTr_Loss: 1.45, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2475, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2476, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2477, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2478, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2479, CombTr_Loss: 1.52, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2480, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2481, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2482, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.58, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2483, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2484, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.48 \n",
      "Epoch: 7, Step: 2485, CombTr_Loss: 1.35, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2486, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2487, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2488, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2489, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2490, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.33, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2491, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2492, CombTr_Loss: 1.61, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2493, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2494, CombTr_Loss: 1.48, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2495, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2496, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2497, CombTr_Loss: 1.33, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2498, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2499, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2500, CombTr_Loss: 1.68, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2501, CombTr_Loss: 1.46, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2502, CombTr_Loss: 1.49, CombTr_Acc: 0.48, CVHum_Loss: 2.15, CVHum_Acc: 0.18 \n",
      "Epoch: 7, Step: 2503, CombTr_Loss: 1.56, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2504, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2505, CombTr_Loss: 1.58, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.18 \n",
      "Epoch: 7, Step: 2506, CombTr_Loss: 1.69, CombTr_Acc: 0.34, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2507, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2508, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2509, CombTr_Loss: 1.59, CombTr_Acc: 0.28, CVHum_Loss: 1.48, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2510, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2511, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2512, CombTr_Loss: 1.53, CombTr_Acc: 0.28, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2513, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2514, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2515, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2516, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2517, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2518, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2519, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2520, CombTr_Loss: 1.62, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2521, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2522, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.54, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2523, CombTr_Loss: 1.83, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2524, CombTr_Loss: 1.63, CombTr_Acc: 0.3, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2525, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2526, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2527, CombTr_Loss: 1.72, CombTr_Acc: 0.4, CVHum_Loss: 2.09, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2528, CombTr_Loss: 1.66, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2529, CombTr_Loss: 1.64, CombTr_Acc: 0.48, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2530, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2531, CombTr_Loss: 1.54, CombTr_Acc: 0.48, CVHum_Loss: 1.47, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2532, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2533, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2534, CombTr_Loss: 1.47, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2535, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2536, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2537, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2538, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2539, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2540, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.54, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2541, CombTr_Loss: 1.64, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2542, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2543, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2544, CombTr_Loss: 1.36, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2545, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2546, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2547, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2548, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2549, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2550, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2551, CombTr_Loss: 1.44, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2552, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2553, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2554, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2555, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2556, CombTr_Loss: 1.38, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2557, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2558, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2559, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2560, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2561, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2562, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2563, CombTr_Loss: 1.58, CombTr_Acc: 0.28, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2564, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2565, CombTr_Loss: 1.59, CombTr_Acc: 0.48, CVHum_Loss: 1.91, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2566, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2567, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2568, CombTr_Loss: 1.8, CombTr_Acc: 0.26, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2569, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2570, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2571, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2572, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2573, CombTr_Loss: 1.48, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2574, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2575, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2576, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2577, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2578, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.43, CVHum_Acc: 0.46 \n",
      "Epoch: 7, Step: 2579, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2580, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2581, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.5, CVHum_Acc: 0.46 \n",
      "Epoch: 7, Step: 2582, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2583, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2584, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2585, CombTr_Loss: 1.73, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2586, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2587, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2588, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2589, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2590, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2591, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2592, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2593, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.6, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2594, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2595, CombTr_Loss: 1.59, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2596, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2597, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2598, CombTr_Loss: 1.71, CombTr_Acc: 0.34, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2599, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2600, CombTr_Loss: 1.85, CombTr_Acc: 0.28, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2601, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2602, CombTr_Loss: 1.57, CombTr_Acc: 0.28, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2603, CombTr_Loss: 1.55, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2604, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2605, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2606, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2607, CombTr_Loss: 1.54, CombTr_Acc: 0.28, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2608, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2609, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2610, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2611, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2612, CombTr_Loss: 1.69, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2613, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2614, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.46, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2615, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2616, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2617, CombTr_Loss: 1.76, CombTr_Acc: 0.26, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2618, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2619, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2620, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2621, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2622, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2623, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2624, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2625, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2626, CombTr_Loss: 1.56, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2627, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2628, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2629, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2630, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2631, CombTr_Loss: 1.77, CombTr_Acc: 0.32, CVHum_Loss: 1.5, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2632, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2633, CombTr_Loss: 1.51, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2634, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2635, CombTr_Loss: 1.4, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2636, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2637, CombTr_Loss: 1.74, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2638, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2639, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2640, CombTr_Loss: 1.58, CombTr_Acc: 0.28, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2641, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2642, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2643, CombTr_Loss: 1.52, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2644, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2645, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2646, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2647, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2648, CombTr_Loss: 1.8, CombTr_Acc: 0.26, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2649, CombTr_Loss: 1.6, CombTr_Acc: 0.24, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2650, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.39, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2651, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2652, CombTr_Loss: 1.64, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2653, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2654, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2655, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2656, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2657, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2658, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2659, CombTr_Loss: 1.23, CombTr_Acc: 0.6, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2660, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.47, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2661, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2662, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2663, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2664, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2665, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2666, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2667, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2668, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2669, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2670, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2671, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2672, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2673, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2674, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2675, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2676, CombTr_Loss: 1.6, CombTr_Acc: 0.32, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2677, CombTr_Loss: 1.52, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2678, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2679, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2680, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2681, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2682, CombTr_Loss: 1.48, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2683, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.41, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2684, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2685, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2686, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.85, CVHum_Acc: 0.14 \n",
      "Epoch: 7, Step: 2687, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2688, CombTr_Loss: 1.52, CombTr_Acc: 0.3, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2689, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.42, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2690, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2691, CombTr_Loss: 1.44, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2692, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2693, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2694, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2695, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2696, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2697, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2698, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2699, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.73, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2700, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2701, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.2 \n",
      "Epoch: 7, Step: 2702, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2703, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2704, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2705, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2706, CombTr_Loss: 1.47, CombTr_Acc: 0.36, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2707, CombTr_Loss: 1.72, CombTr_Acc: 0.26, CVHum_Loss: 1.58, CVHum_Acc: 0.48 \n",
      "Epoch: 7, Step: 2708, CombTr_Loss: 1.71, CombTr_Acc: 0.22, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2709, CombTr_Loss: 1.59, CombTr_Acc: 0.42, CVHum_Loss: 2.15, CVHum_Acc: 0.14 \n",
      "Epoch: 7, Step: 2710, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2711, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.43, CVHum_Acc: 0.46 \n",
      "Epoch: 7, Step: 2712, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.16 \n",
      "Epoch: 7, Step: 2713, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.48 \n",
      "Epoch: 7, Step: 2714, CombTr_Loss: 1.7, CombTr_Acc: 0.28, CVHum_Loss: 2.42, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2715, CombTr_Loss: 1.75, CombTr_Acc: 0.26, CVHum_Loss: 2.1, CVHum_Acc: 0.18 \n",
      "Epoch: 7, Step: 2716, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.46 \n",
      "Epoch: 7, Step: 2717, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2718, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2719, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.44 \n",
      "Epoch: 7, Step: 2720, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2721, CombTr_Loss: 1.47, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2722, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 2.22, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2723, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 7, Step: 2724, CombTr_Loss: 1.59, CombTr_Acc: 0.32, CVHum_Loss: 2.32, CVHum_Acc: 0.14 \n",
      "Epoch: 7, Step: 2725, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 2.3, CVHum_Acc: 0.18 \n",
      "Epoch: 7, Step: 2726, CombTr_Loss: 1.49, CombTr_Acc: 0.5, CVHum_Loss: 2.02, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2727, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2728, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2729, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2730, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2731, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2732, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2733, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2734, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2735, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2736, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2737, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2738, CombTr_Loss: 1.52, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2739, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2740, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2741, CombTr_Loss: 1.47, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 7, Step: 2742, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2743, CombTr_Loss: 1.72, CombTr_Acc: 0.3, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2744, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2745, CombTr_Loss: 1.64, CombTr_Acc: 0.42, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2746, CombTr_Loss: 1.69, CombTr_Acc: 0.26, CVHum_Loss: 1.65, CVHum_Acc: 0.5 \n",
      "Epoch: 7, Step: 2747, CombTr_Loss: 1.37, CombTr_Acc: 0.54, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2748, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 7, Step: 2749, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 7, Step: 2750, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 7, Step: 2751, CombTr_Loss: 1.37, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 7, Step: 2752, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2753, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 7, Step: 2754, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 7, Step: 2755, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 7, Step: 2756, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2757, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 7, Step: 2758, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 7, Step: 2759, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 7, Step: 2760, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Avg_CombTrain_Loss: 1.51, Avg_CombTrain_Acc: 0.41, Avg_CVHum_Loss: 1.72, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 7\n",
      "Epoch: 8, Step: 2761, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2762, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 2.0, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2763, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2764, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2765, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2766, CombTr_Loss: 1.51, CombTr_Acc: 0.48, CVHum_Loss: 1.55, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2767, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2768, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2769, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2770, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.18 \n",
      "Epoch: 8, Step: 2771, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2772, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2773, CombTr_Loss: 1.47, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2774, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2775, CombTr_Loss: 1.63, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2776, CombTr_Loss: 1.6, CombTr_Acc: 0.34, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2777, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2778, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 2.02, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2779, CombTr_Loss: 1.43, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2780, CombTr_Loss: 1.3, CombTr_Acc: 0.6, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2781, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2782, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2783, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.75, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2784, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2785, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.48, CVHum_Acc: 0.48 \n",
      "Epoch: 8, Step: 2786, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2787, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2788, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.41, CVHum_Acc: 0.56 \n",
      "Epoch: 8, Step: 2789, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.5, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2790, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2791, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2792, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2793, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2794, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2795, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2796, CombTr_Loss: 1.75, CombTr_Acc: 0.22, CVHum_Loss: 1.56, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2797, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2798, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2799, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2800, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2801, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2802, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2803, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 2.16, CVHum_Acc: 0.18 \n",
      "Epoch: 8, Step: 2804, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2805, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2806, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.94, CVHum_Acc: 0.16 \n",
      "Epoch: 8, Step: 2807, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2808, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2809, CombTr_Loss: 1.55, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2810, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2811, CombTr_Loss: 1.49, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2812, CombTr_Loss: 1.21, CombTr_Acc: 0.58, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2813, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2814, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2815, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2816, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2817, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2818, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2819, CombTr_Loss: 1.52, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2820, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2821, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2822, CombTr_Loss: 1.58, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2823, CombTr_Loss: 1.65, CombTr_Acc: 0.34, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2824, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.16 \n",
      "Epoch: 8, Step: 2825, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2826, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2827, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2828, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2829, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2830, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2831, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.92, CVHum_Acc: 0.2 \n",
      "Epoch: 8, Step: 2832, CombTr_Loss: 1.61, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2833, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2834, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2835, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.35, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2836, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2837, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2838, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2839, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2840, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2841, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2842, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2843, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2844, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2845, CombTr_Loss: 1.64, CombTr_Acc: 0.28, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2846, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2847, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2848, CombTr_Loss: 1.54, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2849, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2850, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.78, CVHum_Acc: 0.16 \n",
      "Epoch: 8, Step: 2851, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2852, CombTr_Loss: 1.36, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2853, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2854, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.42, CVHum_Acc: 0.48 \n",
      "Epoch: 8, Step: 2855, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2856, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2857, CombTr_Loss: 1.47, CombTr_Acc: 0.32, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2858, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2859, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2860, CombTr_Loss: 1.43, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2861, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2862, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2863, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2864, CombTr_Loss: 1.61, CombTr_Acc: 0.42, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2865, CombTr_Loss: 1.6, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2866, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2867, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.46, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2868, CombTr_Loss: 1.79, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2869, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.53, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2870, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2871, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2872, CombTr_Loss: 1.67, CombTr_Acc: 0.4, CVHum_Loss: 2.11, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2873, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2874, CombTr_Loss: 1.68, CombTr_Acc: 0.42, CVHum_Loss: 1.44, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2875, CombTr_Loss: 1.34, CombTr_Acc: 0.56, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2876, CombTr_Loss: 1.45, CombTr_Acc: 0.5, CVHum_Loss: 1.5, CVHum_Acc: 0.5 \n",
      "Epoch: 8, Step: 2877, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2878, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.65, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2879, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2880, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2881, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.54, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2882, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2883, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 2.02, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2884, CombTr_Loss: 1.66, CombTr_Acc: 0.32, CVHum_Loss: 1.51, CVHum_Acc: 0.5 \n",
      "Epoch: 8, Step: 2885, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2886, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2887, CombTr_Loss: 1.46, CombTr_Acc: 0.36, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2888, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2889, CombTr_Loss: 1.28, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2890, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.45, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2891, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2892, CombTr_Loss: 1.63, CombTr_Acc: 0.28, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2893, CombTr_Loss: 1.43, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2894, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2895, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2896, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2897, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2898, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2899, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2900, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2901, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2902, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2903, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2904, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2905, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2906, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2907, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2908, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2909, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2910, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2911, CombTr_Loss: 1.64, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2912, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2913, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2914, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2915, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2916, CombTr_Loss: 1.52, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2917, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2918, CombTr_Loss: 1.45, CombTr_Acc: 0.32, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2919, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2920, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.47, CVHum_Acc: 0.54 \n",
      "Epoch: 8, Step: 2921, CombTr_Loss: 1.46, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2922, CombTr_Loss: 1.6, CombTr_Acc: 0.44, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2923, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.48, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2924, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2925, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2926, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.38, CVHum_Acc: 0.62 \n",
      "Epoch: 8, Step: 2927, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2928, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2929, CombTr_Loss: 1.7, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2930, CombTr_Loss: 1.7, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2931, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2932, CombTr_Loss: 1.56, CombTr_Acc: 0.3, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2933, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2934, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2935, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2936, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.44, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2937, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2938, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2939, CombTr_Loss: 1.61, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2940, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2941, CombTr_Loss: 1.32, CombTr_Acc: 0.42, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2942, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2943, CombTr_Loss: 1.69, CombTr_Acc: 0.32, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2944, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2945, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2946, CombTr_Loss: 1.45, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2947, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2948, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2949, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2950, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2951, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2952, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2953, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2954, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2955, CombTr_Loss: 1.39, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2956, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2957, CombTr_Loss: 1.69, CombTr_Acc: 0.36, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2958, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2959, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.33, CVHum_Acc: 0.52 \n",
      "Epoch: 8, Step: 2960, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2961, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 2962, CombTr_Loss: 1.8, CombTr_Acc: 0.24, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2963, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2964, CombTr_Loss: 1.38, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2965, CombTr_Loss: 1.49, CombTr_Acc: 0.52, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2966, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2967, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2968, CombTr_Loss: 1.45, CombTr_Acc: 0.54, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2969, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2970, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2971, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 2972, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2973, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.5, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2974, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2975, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2976, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.47, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2977, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2978, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2979, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2980, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 2981, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2982, CombTr_Loss: 1.79, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2983, CombTr_Loss: 1.41, CombTr_Acc: 0.54, CVHum_Loss: 1.49, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2984, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2985, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 2986, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2987, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2988, CombTr_Loss: 1.6, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 2989, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 2990, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2991, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 2992, CombTr_Loss: 1.66, CombTr_Acc: 0.36, CVHum_Loss: 1.52, CVHum_Acc: 0.46 \n",
      "Epoch: 8, Step: 2993, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 2994, CombTr_Loss: 1.53, CombTr_Acc: 0.32, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 2995, CombTr_Loss: 1.37, CombTr_Acc: 0.38, CVHum_Loss: 1.38, CVHum_Acc: 0.58 \n",
      "Epoch: 8, Step: 2996, CombTr_Loss: 1.37, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 2997, CombTr_Loss: 1.66, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 2998, CombTr_Loss: 1.47, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 2999, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 3000, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3001, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 3002, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3003, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3004, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3005, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 3006, CombTr_Loss: 1.46, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3007, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3008, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3009, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3010, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 2.1, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3011, CombTr_Loss: 1.67, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3012, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 3013, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3014, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 3015, CombTr_Loss: 1.58, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 3016, CombTr_Loss: 1.58, CombTr_Acc: 0.3, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3017, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3018, CombTr_Loss: 1.46, CombTr_Acc: 0.52, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3019, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 3020, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3021, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3022, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 3023, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.49, CVHum_Acc: 0.48 \n",
      "Epoch: 8, Step: 3024, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3025, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3026, CombTr_Loss: 1.32, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3027, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3028, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3029, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3030, CombTr_Loss: 1.51, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3031, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.91, CVHum_Acc: 0.18 \n",
      "Epoch: 8, Step: 3032, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 3033, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3034, CombTr_Loss: 1.6, CombTr_Acc: 0.3, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 3035, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3036, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3037, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3038, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3039, CombTr_Loss: 1.46, CombTr_Acc: 0.34, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3040, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 3041, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3042, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3043, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 8, Step: 3044, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3045, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3046, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 3047, CombTr_Loss: 1.62, CombTr_Acc: 0.24, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3048, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3049, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3050, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3051, CombTr_Loss: 1.51, CombTr_Acc: 0.32, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3052, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 1.49, CVHum_Acc: 0.48 \n",
      "Epoch: 8, Step: 3053, CombTr_Loss: 1.71, CombTr_Acc: 0.24, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 3054, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 2.13, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 3055, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3056, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.46, CVHum_Acc: 0.5 \n",
      "Epoch: 8, Step: 3057, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3058, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3059, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3060, CombTr_Loss: 1.74, CombTr_Acc: 0.32, CVHum_Loss: 2.13, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 3061, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3062, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3063, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 2.12, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3064, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.48 \n",
      "Epoch: 8, Step: 3065, CombTr_Loss: 1.45, CombTr_Acc: 0.5, CVHum_Loss: 2.29, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3066, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 2.25, CVHum_Acc: 0.12 \n",
      "Epoch: 8, Step: 3067, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 2.33, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3068, CombTr_Loss: 1.44, CombTr_Acc: 0.36, CVHum_Loss: 2.18, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 3069, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3070, CombTr_Loss: 1.71, CombTr_Acc: 0.3, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 3071, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3072, CombTr_Loss: 1.5, CombTr_Acc: 0.5, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3073, CombTr_Loss: 1.3, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.42 \n",
      "Epoch: 8, Step: 3074, CombTr_Loss: 1.41, CombTr_Acc: 0.36, CVHum_Loss: 1.97, CVHum_Acc: 0.22 \n",
      "Epoch: 8, Step: 3075, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3076, CombTr_Loss: 1.6, CombTr_Acc: 0.3, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3077, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3078, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3079, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3080, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3081, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3082, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3083, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3084, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.92, CVHum_Acc: 0.2 \n",
      "Epoch: 8, Step: 3085, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3086, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3087, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 8, Step: 3088, CombTr_Loss: 1.77, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3089, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 2.15, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 3090, CombTr_Loss: 1.68, CombTr_Acc: 0.4, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3091, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 3092, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3093, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3094, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 8, Step: 3095, CombTr_Loss: 1.62, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3096, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3097, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 8, Step: 3098, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 8, Step: 3099, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3100, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 8, Step: 3101, CombTr_Loss: 1.48, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 8, Step: 3102, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 8, Step: 3103, CombTr_Loss: 1.48, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 8, Step: 3104, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 8, Step: 3105, CombTr_Loss: 1.42, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Avg_CombTrain_Loss: 1.48, Avg_CombTrain_Acc: 0.42, Avg_CVHum_Loss: 1.72, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 8\n",
      "Epoch: 9, Step: 3106, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3107, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 2.13, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3108, CombTr_Loss: 1.34, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.2 \n",
      "Epoch: 9, Step: 3109, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3110, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3111, CombTr_Loss: 1.49, CombTr_Acc: 0.5, CVHum_Loss: 1.59, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3112, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3113, CombTr_Loss: 1.33, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3114, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3115, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3116, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3117, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.94, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3118, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3119, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3120, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3121, CombTr_Loss: 1.52, CombTr_Acc: 0.32, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3122, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3123, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 2.18, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3124, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3125, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.54, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3126, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3127, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3128, CombTr_Loss: 1.65, CombTr_Acc: 0.32, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3129, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3130, CombTr_Loss: 1.45, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3131, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3132, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3133, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.42, CVHum_Acc: 0.54 \n",
      "Epoch: 9, Step: 3134, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3135, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3136, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3137, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3138, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.56, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3139, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3140, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3141, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3142, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 1.68, CVHum_Acc: 0.5 \n",
      "Epoch: 9, Step: 3143, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3144, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3145, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.52, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3146, CombTr_Loss: 1.52, CombTr_Acc: 0.28, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3147, CombTr_Loss: 1.68, CombTr_Acc: 0.26, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3148, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 2.17, CVHum_Acc: 0.18 \n",
      "Epoch: 9, Step: 3149, CombTr_Loss: 1.48, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3150, CombTr_Loss: 1.35, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3151, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.2 \n",
      "Epoch: 9, Step: 3152, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3153, CombTr_Loss: 1.33, CombTr_Acc: 0.56, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3154, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 1.51, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3155, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3156, CombTr_Loss: 1.66, CombTr_Acc: 0.44, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3157, CombTr_Loss: 1.18, CombTr_Acc: 0.62, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3158, CombTr_Loss: 1.33, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3159, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3160, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3161, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.52, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3162, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3163, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3164, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3165, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3166, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.42, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3167, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3168, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3169, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3170, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3171, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3172, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.45, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3173, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3174, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3175, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3176, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3177, CombTr_Loss: 1.54, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3178, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3179, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3180, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.31, CVHum_Acc: 0.5 \n",
      "Epoch: 9, Step: 3181, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3182, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3183, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3184, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3185, CombTr_Loss: 1.61, CombTr_Acc: 0.32, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3186, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 2.11, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3187, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3188, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3189, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3190, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3191, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3192, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 2.23, CVHum_Acc: 0.14 \n",
      "Epoch: 9, Step: 3193, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3194, CombTr_Loss: 1.46, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3195, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.2 \n",
      "Epoch: 9, Step: 3196, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.53, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3197, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3198, CombTr_Loss: 1.52, CombTr_Acc: 0.32, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3199, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.43, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3200, CombTr_Loss: 1.65, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3201, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3202, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3203, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3204, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3205, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3206, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3207, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3208, CombTr_Loss: 1.55, CombTr_Acc: 0.44, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3209, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3210, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3211, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3212, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3213, CombTr_Loss: 1.74, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3214, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.55, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3215, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3216, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3217, CombTr_Loss: 1.65, CombTr_Acc: 0.38, CVHum_Loss: 2.31, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3218, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3219, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3220, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3221, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3222, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3223, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3224, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3225, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3226, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3227, CombTr_Loss: 1.37, CombTr_Acc: 0.38, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3228, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3229, CombTr_Loss: 1.66, CombTr_Acc: 0.44, CVHum_Loss: 1.53, CVHum_Acc: 0.52 \n",
      "Epoch: 9, Step: 3230, CombTr_Loss: 1.35, CombTr_Acc: 0.38, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3231, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3232, CombTr_Loss: 1.57, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3233, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3234, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3235, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.41, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3236, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.54, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3237, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3238, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3239, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3240, CombTr_Loss: 1.46, CombTr_Acc: 0.36, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3241, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.53, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3242, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3243, CombTr_Loss: 1.3, CombTr_Acc: 0.62, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3244, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3245, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3246, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3247, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3248, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3249, CombTr_Loss: 1.38, CombTr_Acc: 0.4, CVHum_Loss: 1.47, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3250, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3251, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.79, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3252, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3253, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3254, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3255, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3256, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3257, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3258, CombTr_Loss: 1.74, CombTr_Acc: 0.24, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3259, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3260, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3261, CombTr_Loss: 1.4, CombTr_Acc: 0.52, CVHum_Loss: 2.04, CVHum_Acc: 0.18 \n",
      "Epoch: 9, Step: 3262, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3263, CombTr_Loss: 1.38, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3264, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3265, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.45, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3266, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3267, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3268, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3269, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3270, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3271, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.42, CVHum_Acc: 0.58 \n",
      "Epoch: 9, Step: 3272, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3273, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.6, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3274, CombTr_Loss: 1.57, CombTr_Acc: 0.34, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3275, CombTr_Loss: 1.7, CombTr_Acc: 0.32, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3276, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3277, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3278, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3279, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3280, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3281, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.56, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3282, CombTr_Loss: 1.27, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3283, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.5, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3284, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3285, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3286, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3287, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3288, CombTr_Loss: 1.68, CombTr_Acc: 0.32, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3289, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3290, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3291, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3292, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3293, CombTr_Loss: 1.48, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3294, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3295, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3296, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3297, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3298, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3299, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3300, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3301, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3302, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3303, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3304, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.43, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3305, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3306, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3307, CombTr_Loss: 1.64, CombTr_Acc: 0.32, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3308, CombTr_Loss: 1.33, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3309, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3310, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3311, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3312, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3313, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3314, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3315, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3316, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3317, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3318, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.54, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3319, CombTr_Loss: 1.38, CombTr_Acc: 0.4, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3320, CombTr_Loss: 1.5, CombTr_Acc: 0.32, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3321, CombTr_Loss: 1.71, CombTr_Acc: 0.32, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3322, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3323, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3324, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3325, CombTr_Loss: 1.39, CombTr_Acc: 0.34, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3326, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3327, CombTr_Loss: 1.69, CombTr_Acc: 0.36, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3328, CombTr_Loss: 1.33, CombTr_Acc: 0.56, CVHum_Loss: 1.48, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3329, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3330, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 2.0, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3331, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3332, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3333, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3334, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.5 \n",
      "Epoch: 9, Step: 3335, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3336, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 1.99, CVHum_Acc: 0.18 \n",
      "Epoch: 9, Step: 3337, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3338, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3339, CombTr_Loss: 1.47, CombTr_Acc: 0.28, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3340, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.35, CVHum_Acc: 0.62 \n",
      "Epoch: 9, Step: 3341, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3342, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3343, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3344, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.2 \n",
      "Epoch: 9, Step: 3345, CombTr_Loss: 1.38, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3346, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.88, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3347, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3348, CombTr_Loss: 1.35, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3349, CombTr_Loss: 1.17, CombTr_Acc: 0.64, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3350, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3351, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.79, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3352, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3353, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3354, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3355, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3356, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3357, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3358, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3359, CombTr_Loss: 1.54, CombTr_Acc: 0.42, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3360, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3361, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.53, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3362, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3363, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3364, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3365, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3366, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.2 \n",
      "Epoch: 9, Step: 3367, CombTr_Loss: 1.44, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.48 \n",
      "Epoch: 9, Step: 3368, CombTr_Loss: 1.3, CombTr_Acc: 0.56, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3369, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3370, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3371, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3372, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3373, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3374, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3375, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3376, CombTr_Loss: 1.5, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 9, Step: 3377, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3378, CombTr_Loss: 1.45, CombTr_Acc: 0.34, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3379, CombTr_Loss: 1.63, CombTr_Acc: 0.38, CVHum_Loss: 1.43, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3380, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3381, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3382, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3383, CombTr_Loss: 1.35, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3384, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3385, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3386, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3387, CombTr_Loss: 1.53, CombTr_Acc: 0.46, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3388, CombTr_Loss: 1.47, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3389, CombTr_Loss: 1.81, CombTr_Acc: 0.28, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3390, CombTr_Loss: 1.47, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3391, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3392, CombTr_Loss: 1.49, CombTr_Acc: 0.28, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3393, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3394, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3395, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3396, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3397, CombTr_Loss: 1.68, CombTr_Acc: 0.34, CVHum_Loss: 1.56, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3398, CombTr_Loss: 1.56, CombTr_Acc: 0.32, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3399, CombTr_Loss: 1.55, CombTr_Acc: 0.5, CVHum_Loss: 2.17, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3400, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3401, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.47, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3402, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3403, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3404, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3405, CombTr_Loss: 1.71, CombTr_Acc: 0.24, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3406, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3407, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3408, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3409, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.5, CVHum_Acc: 0.5 \n",
      "Epoch: 9, Step: 3410, CombTr_Loss: 1.36, CombTr_Acc: 0.54, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3411, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3412, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3413, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3414, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3415, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3416, CombTr_Loss: 1.43, CombTr_Acc: 0.52, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3417, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3418, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 9, Step: 3419, CombTr_Loss: 1.42, CombTr_Acc: 0.32, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3420, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3421, CombTr_Loss: 1.57, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.18 \n",
      "Epoch: 9, Step: 3422, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3423, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3424, CombTr_Loss: 1.64, CombTr_Acc: 0.34, CVHum_Loss: 2.07, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3425, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3426, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3427, CombTr_Loss: 1.45, CombTr_Acc: 0.52, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 9, Step: 3428, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3429, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3430, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.52, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3431, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3432, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3433, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 9, Step: 3434, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 2.22, CVHum_Acc: 0.16 \n",
      "Epoch: 9, Step: 3435, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 9, Step: 3436, CombTr_Loss: 1.77, CombTr_Acc: 0.28, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3437, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 9, Step: 3438, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3439, CombTr_Loss: 1.46, CombTr_Acc: 0.5, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3440, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3441, CombTr_Loss: 1.37, CombTr_Acc: 0.42, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3442, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 9, Step: 3443, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 9, Step: 3444, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 9, Step: 3445, CombTr_Loss: 1.21, CombTr_Acc: 0.62, CVHum_Loss: 1.68, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3446, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 9, Step: 3447, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 9, Step: 3448, CombTr_Loss: 1.5, CombTr_Acc: 0.32, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 9, Step: 3449, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 9, Step: 3450, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Avg_CombTrain_Loss: 1.45, Avg_CombTrain_Acc: 0.43, Avg_CVHum_Loss: 1.72, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 9\n",
      "Epoch: 10, Step: 3451, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3452, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 2.2, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3453, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3454, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3455, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.74, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3456, CombTr_Loss: 1.45, CombTr_Acc: 0.5, CVHum_Loss: 1.58, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3457, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3458, CombTr_Loss: 1.21, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3459, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3460, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.85, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3461, CombTr_Loss: 1.32, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3462, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 2.09, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3463, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3464, CombTr_Loss: 1.34, CombTr_Acc: 0.58, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3465, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3466, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3467, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3468, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 2.11, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3469, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3470, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3471, CombTr_Loss: 1.3, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3472, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3473, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3474, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3475, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.47, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3476, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3477, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3478, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3479, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.45, CVHum_Acc: 0.5 \n",
      "Epoch: 10, Step: 3480, CombTr_Loss: 1.29, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3481, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3482, CombTr_Loss: 1.39, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3483, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3484, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3485, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3486, CombTr_Loss: 1.7, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3487, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3488, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3489, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3490, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3491, CombTr_Loss: 1.54, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3492, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3493, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 2.05, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3494, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3495, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3496, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.18 \n",
      "Epoch: 10, Step: 3497, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3498, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3499, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3500, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.16 \n",
      "Epoch: 10, Step: 3501, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3502, CombTr_Loss: 1.12, CombTr_Acc: 0.66, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3503, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3504, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 2.14, CVHum_Acc: 0.14 \n",
      "Epoch: 10, Step: 3505, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3506, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.52, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3507, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3508, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.99, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3509, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3510, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3511, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.58, CVHum_Acc: 0.48 \n",
      "Epoch: 10, Step: 3512, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3513, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3514, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.18 \n",
      "Epoch: 10, Step: 3515, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3516, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3517, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3518, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3519, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3520, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3521, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 2.01, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3522, CombTr_Loss: 1.46, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3523, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3524, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 2.14, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3525, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 1.4, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3526, CombTr_Loss: 1.44, CombTr_Acc: 0.38, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3527, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 2.08, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3528, CombTr_Loss: 1.33, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3529, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3530, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3531, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 2.16, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3532, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3533, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3534, CombTr_Loss: 1.39, CombTr_Acc: 0.38, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3535, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3536, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3537, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 2.28, CVHum_Acc: 0.16 \n",
      "Epoch: 10, Step: 3538, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3539, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3540, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.16 \n",
      "Epoch: 10, Step: 3541, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3542, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3543, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3544, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.47, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3545, CombTr_Loss: 1.62, CombTr_Acc: 0.3, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3546, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3547, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3548, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3549, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3550, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3551, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3552, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3553, CombTr_Loss: 1.63, CombTr_Acc: 0.46, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3554, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3555, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3556, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3557, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3558, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3559, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3560, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3561, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3562, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 2.28, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3563, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3564, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.55, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3565, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3566, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3567, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3568, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3569, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3570, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3571, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3572, CombTr_Loss: 1.43, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3573, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 2.05, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3574, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3575, CombTr_Loss: 1.36, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3576, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.99, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3577, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3578, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3579, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3580, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.53, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3581, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.65, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3582, CombTr_Loss: 1.52, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3583, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3584, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3585, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3586, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3587, CombTr_Loss: 1.33, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3588, CombTr_Loss: 1.3, CombTr_Acc: 0.58, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3589, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3590, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3591, CombTr_Loss: 1.37, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3592, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3593, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3594, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3595, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3596, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3597, CombTr_Loss: 1.43, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3598, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3599, CombTr_Loss: 1.59, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3600, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.95, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3601, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3602, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3603, CombTr_Loss: 1.68, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3604, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3605, CombTr_Loss: 1.36, CombTr_Acc: 0.38, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3606, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 2.23, CVHum_Acc: 0.14 \n",
      "Epoch: 10, Step: 3607, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3608, CombTr_Loss: 1.32, CombTr_Acc: 0.58, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3609, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3610, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3611, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3612, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3613, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.57, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3614, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3615, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.85, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3616, CombTr_Loss: 1.55, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.5 \n",
      "Epoch: 10, Step: 3617, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3618, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3619, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3620, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3621, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3622, CombTr_Loss: 1.52, CombTr_Acc: 0.34, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3623, CombTr_Loss: 1.54, CombTr_Acc: 0.34, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3624, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3625, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3626, CombTr_Loss: 1.61, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3627, CombTr_Loss: 1.24, CombTr_Acc: 0.46, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3628, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3629, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.48 \n",
      "Epoch: 10, Step: 3630, CombTr_Loss: 1.51, CombTr_Acc: 0.32, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3631, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 2.14, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3632, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3633, CombTr_Loss: 1.62, CombTr_Acc: 0.28, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3634, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3635, CombTr_Loss: 1.82, CombTr_Acc: 0.3, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3636, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3637, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.46, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3638, CombTr_Loss: 1.52, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.18 \n",
      "Epoch: 10, Step: 3639, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3640, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3641, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3642, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3643, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3644, CombTr_Loss: 1.22, CombTr_Acc: 0.48, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3645, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3646, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3647, CombTr_Loss: 1.59, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3648, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3649, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.44, CVHum_Acc: 0.52 \n",
      "Epoch: 10, Step: 3650, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3651, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3652, CombTr_Loss: 1.55, CombTr_Acc: 0.48, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3653, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3654, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3655, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3656, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3657, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.56, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3658, CombTr_Loss: 1.47, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3659, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3660, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3661, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3662, CombTr_Loss: 1.5, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3663, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3664, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3665, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3666, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.58, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3667, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3668, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3669, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3670, CombTr_Loss: 1.33, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3671, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3672, CombTr_Loss: 1.73, CombTr_Acc: 0.34, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3673, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.51, CVHum_Acc: 0.52 \n",
      "Epoch: 10, Step: 3674, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3675, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3676, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3677, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3678, CombTr_Loss: 1.58, CombTr_Acc: 0.46, CVHum_Loss: 1.81, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3679, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.63, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3680, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3681, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3682, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3683, CombTr_Loss: 1.66, CombTr_Acc: 0.3, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3684, CombTr_Loss: 1.42, CombTr_Acc: 0.34, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3685, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.36, CVHum_Acc: 0.54 \n",
      "Epoch: 10, Step: 3686, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3687, CombTr_Loss: 1.58, CombTr_Acc: 0.4, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3688, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3689, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3690, CombTr_Loss: 1.37, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3691, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3692, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3693, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3694, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 10, Step: 3695, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3696, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3697, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.68, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3698, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3699, CombTr_Loss: 1.42, CombTr_Acc: 0.54, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3700, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3701, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3702, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.48, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3703, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3704, CombTr_Loss: 1.42, CombTr_Acc: 0.54, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3705, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3706, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.52, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3707, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3708, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3709, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3710, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3711, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3712, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3713, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3714, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3715, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3716, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3717, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3718, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.41, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3719, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3720, CombTr_Loss: 1.38, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3721, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.9, CVHum_Acc: 0.2 \n",
      "Epoch: 10, Step: 3722, CombTr_Loss: 1.58, CombTr_Acc: 0.32, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3723, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3724, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.44, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3725, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3726, CombTr_Loss: 1.32, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3727, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3728, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3729, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3730, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3731, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.87, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3732, CombTr_Loss: 1.49, CombTr_Acc: 0.5, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3733, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3734, CombTr_Loss: 1.66, CombTr_Acc: 0.34, CVHum_Loss: 2.34, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3735, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3736, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3737, CombTr_Loss: 1.42, CombTr_Acc: 0.38, CVHum_Loss: 2.18, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3738, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 2.1, CVHum_Acc: 0.18 \n",
      "Epoch: 10, Step: 3739, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3740, CombTr_Loss: 1.5, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3741, CombTr_Loss: 1.44, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3742, CombTr_Loss: 1.59, CombTr_Acc: 0.34, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3743, CombTr_Loss: 1.53, CombTr_Acc: 0.28, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3744, CombTr_Loss: 1.44, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.22 \n",
      "Epoch: 10, Step: 3745, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3746, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3747, CombTr_Loss: 1.25, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3748, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3749, CombTr_Loss: 1.61, CombTr_Acc: 0.3, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3750, CombTr_Loss: 1.66, CombTr_Acc: 0.4, CVHum_Loss: 2.18, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3751, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.48 \n",
      "Epoch: 10, Step: 3752, CombTr_Loss: 1.37, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3753, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3754, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3755, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3756, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3757, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.18 \n",
      "Epoch: 10, Step: 3758, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.24 \n",
      "Epoch: 10, Step: 3759, CombTr_Loss: 1.6, CombTr_Acc: 0.36, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3760, CombTr_Loss: 1.72, CombTr_Acc: 0.32, CVHum_Loss: 1.96, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3761, CombTr_Loss: 1.38, CombTr_Acc: 0.54, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3762, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3763, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.5, CVHum_Acc: 0.48 \n",
      "Epoch: 10, Step: 3764, CombTr_Loss: 1.35, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3765, CombTr_Loss: 1.32, CombTr_Acc: 0.58, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3766, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3767, CombTr_Loss: 1.37, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3768, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3769, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3770, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.75, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3771, CombTr_Loss: 1.27, CombTr_Acc: 0.6, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 10, Step: 3772, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3773, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.44 \n",
      "Epoch: 10, Step: 3774, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3775, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3776, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3777, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3778, CombTr_Loss: 1.6, CombTr_Acc: 0.38, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3779, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 2.11, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3780, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 10, Step: 3781, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3782, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3783, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3784, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3785, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3786, CombTr_Loss: 1.24, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3787, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 10, Step: 3788, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 10, Step: 3789, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3790, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 10, Step: 3791, CombTr_Loss: 1.52, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 10, Step: 3792, CombTr_Loss: 1.49, CombTr_Acc: 0.36, CVHum_Loss: 1.9, CVHum_Acc: 0.36 \n",
      "Epoch: 10, Step: 3793, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 10, Step: 3794, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 10, Step: 3795, CombTr_Loss: 1.35, CombTr_Acc: 0.4, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Avg_CombTrain_Loss: 1.41, Avg_CombTrain_Acc: 0.45, Avg_CVHum_Loss: 1.76, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 10\n",
      "Epoch: 11, Step: 3796, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3797, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 2.26, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3798, CombTr_Loss: 1.22, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3799, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3800, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.46 \n",
      "Epoch: 11, Step: 3801, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.56, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3802, CombTr_Loss: 1.33, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3803, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3804, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3805, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3806, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3807, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3808, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.51, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3809, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3810, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3811, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3812, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3813, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 2.09, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3814, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3815, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3816, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3817, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3818, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3819, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3820, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3821, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3822, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 2.02, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3823, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.56, CVHum_Acc: 0.46 \n",
      "Epoch: 11, Step: 3824, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3825, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3826, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3827, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3828, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3829, CombTr_Loss: 1.32, CombTr_Acc: 0.36, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3830, CombTr_Loss: 1.39, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3831, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.5, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3832, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3833, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.55, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3834, CombTr_Loss: 1.45, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3835, CombTr_Loss: 1.36, CombTr_Acc: 0.54, CVHum_Loss: 1.49, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3836, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3837, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3838, CombTr_Loss: 1.46, CombTr_Acc: 0.44, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3839, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3840, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3841, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3842, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3843, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3844, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3845, CombTr_Loss: 1.29, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3846, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.2 \n",
      "Epoch: 11, Step: 3847, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3848, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3849, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3850, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.5, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3851, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3852, CombTr_Loss: 1.33, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3853, CombTr_Loss: 1.35, CombTr_Acc: 0.4, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3854, CombTr_Loss: 1.43, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3855, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.95, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3856, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.41, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3857, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3858, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3859, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3860, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3861, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3862, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3863, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3864, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3865, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3866, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3867, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3868, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3869, CombTr_Loss: 1.36, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3870, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.31, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3871, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3872, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 2.01, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3873, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3874, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3875, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3876, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.24, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3877, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3878, CombTr_Loss: 1.27, CombTr_Acc: 0.42, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3879, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3880, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3881, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3882, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 2.25, CVHum_Acc: 0.1 \n",
      "Epoch: 11, Step: 3883, CombTr_Loss: 1.38, CombTr_Acc: 0.56, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3884, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3885, CombTr_Loss: 1.34, CombTr_Acc: 0.56, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3886, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3887, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3888, CombTr_Loss: 1.35, CombTr_Acc: 0.38, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3889, CombTr_Loss: 1.6, CombTr_Acc: 0.42, CVHum_Loss: 1.44, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3890, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3891, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3892, CombTr_Loss: 1.43, CombTr_Acc: 0.34, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3893, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 2.01, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3894, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3895, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3896, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.9, CVHum_Acc: 0.18 \n",
      "Epoch: 11, Step: 3897, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3898, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3899, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3900, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3901, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.93, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3902, CombTr_Loss: 1.31, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3903, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3904, CombTr_Loss: 1.49, CombTr_Acc: 0.32, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3905, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.71, CVHum_Acc: 0.46 \n",
      "Epoch: 11, Step: 3906, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3907, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 2.28, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3908, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 3909, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3910, CombTr_Loss: 1.24, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3911, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3912, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3913, CombTr_Loss: 1.37, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3914, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.18 \n",
      "Epoch: 11, Step: 3915, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.18 \n",
      "Epoch: 11, Step: 3916, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.45, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3917, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3918, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3919, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3920, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.56, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3921, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3922, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3923, CombTr_Loss: 1.48, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3924, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3925, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.45, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3926, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.64, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3927, CombTr_Loss: 1.43, CombTr_Acc: 0.4, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3928, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.78, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3929, CombTr_Loss: 1.52, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3930, CombTr_Loss: 1.41, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3931, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3932, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3933, CombTr_Loss: 1.13, CombTr_Acc: 0.68, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3934, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3935, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3936, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3937, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3938, CombTr_Loss: 1.42, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3939, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3940, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3941, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3942, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3943, CombTr_Loss: 1.56, CombTr_Acc: 0.22, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3944, CombTr_Loss: 1.61, CombTr_Acc: 0.36, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3945, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3946, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3947, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3948, CombTr_Loss: 1.64, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3949, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3950, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3951, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 2.25, CVHum_Acc: 0.18 \n",
      "Epoch: 11, Step: 3952, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3953, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3954, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.85, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3955, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3956, CombTr_Loss: 1.25, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3957, CombTr_Loss: 1.54, CombTr_Acc: 0.48, CVHum_Loss: 2.02, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3958, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3959, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.62, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3960, CombTr_Loss: 1.55, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3961, CombTr_Loss: 1.64, CombTr_Acc: 0.3, CVHum_Loss: 1.51, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3962, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3963, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3964, CombTr_Loss: 1.53, CombTr_Acc: 0.44, CVHum_Loss: 1.86, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3965, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.85, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3966, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.74, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3967, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3968, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 3969, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3970, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3971, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.51, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3972, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3973, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3974, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3975, CombTr_Loss: 1.5, CombTr_Acc: 0.38, CVHum_Loss: 1.93, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3976, CombTr_Loss: 1.19, CombTr_Acc: 0.6, CVHum_Loss: 2.18, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3977, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3978, CombTr_Loss: 1.62, CombTr_Acc: 0.34, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 3979, CombTr_Loss: 1.22, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3980, CombTr_Loss: 1.67, CombTr_Acc: 0.36, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 3981, CombTr_Loss: 1.19, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3982, CombTr_Loss: 1.57, CombTr_Acc: 0.32, CVHum_Loss: 1.69, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3983, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3984, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3985, CombTr_Loss: 1.16, CombTr_Acc: 0.62, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3986, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3987, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 3988, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 3989, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.45, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 3990, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3991, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 3992, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 3993, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 3994, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.41, CVHum_Acc: 0.5 \n",
      "Epoch: 11, Step: 3995, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 3996, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 3997, CombTr_Loss: 1.66, CombTr_Acc: 0.28, CVHum_Loss: 1.86, CVHum_Acc: 0.2 \n",
      "Epoch: 11, Step: 3998, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 3999, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4000, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4001, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4002, CombTr_Loss: 1.27, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4003, CombTr_Loss: 1.45, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4004, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4005, CombTr_Loss: 1.09, CombTr_Acc: 0.64, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4006, CombTr_Loss: 1.4, CombTr_Acc: 0.36, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4007, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 1.95, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4008, CombTr_Loss: 1.34, CombTr_Acc: 0.42, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4009, CombTr_Loss: 1.44, CombTr_Acc: 0.42, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4010, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 2.06, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4011, CombTr_Loss: 1.53, CombTr_Acc: 0.34, CVHum_Loss: 1.45, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4012, CombTr_Loss: 1.43, CombTr_Acc: 0.36, CVHum_Loss: 1.82, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 4013, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4014, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4015, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4016, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4017, CombTr_Loss: 1.67, CombTr_Acc: 0.3, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4018, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4019, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4020, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4021, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4022, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.54, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4023, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4024, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4025, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.85, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4026, CombTr_Loss: 1.07, CombTr_Acc: 0.68, CVHum_Loss: 2.1, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 4027, CombTr_Loss: 1.65, CombTr_Acc: 0.42, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4028, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4029, CombTr_Loss: 1.3, CombTr_Acc: 0.34, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4030, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.43, CVHum_Acc: 0.46 \n",
      "Epoch: 11, Step: 4031, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4032, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.66, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4033, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4034, CombTr_Loss: 1.27, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4035, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4036, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.2 \n",
      "Epoch: 11, Step: 4037, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4038, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4039, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 1.69, CVHum_Acc: 0.46 \n",
      "Epoch: 11, Step: 4040, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4041, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4042, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4043, CombTr_Loss: 1.23, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4044, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4045, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4046, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4047, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4048, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4049, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4050, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 4051, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4052, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4053, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4054, CombTr_Loss: 1.33, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4055, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4056, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4057, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4058, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.52, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4059, CombTr_Loss: 1.57, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4060, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.95, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4061, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4062, CombTr_Loss: 1.34, CombTr_Acc: 0.4, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4063, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.44, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4064, CombTr_Loss: 1.19, CombTr_Acc: 0.66, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4065, CombTr_Loss: 1.31, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4066, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4067, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4068, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4069, CombTr_Loss: 1.56, CombTr_Acc: 0.4, CVHum_Loss: 1.43, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4070, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4071, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4072, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4073, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4074, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4075, CombTr_Loss: 1.45, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4076, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4077, CombTr_Loss: 1.58, CombTr_Acc: 0.38, CVHum_Loss: 1.4, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4078, CombTr_Loss: 1.4, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4079, CombTr_Loss: 1.59, CombTr_Acc: 0.36, CVHum_Loss: 2.03, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4080, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4081, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4082, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4083, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4084, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4085, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 2.06, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4086, CombTr_Loss: 1.39, CombTr_Acc: 0.38, CVHum_Loss: 1.62, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4087, CombTr_Loss: 1.49, CombTr_Acc: 0.34, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4088, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4089, CombTr_Loss: 1.45, CombTr_Acc: 0.54, CVHum_Loss: 2.31, CVHum_Acc: 0.14 \n",
      "Epoch: 11, Step: 4090, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4091, CombTr_Loss: 1.49, CombTr_Acc: 0.46, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4092, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4093, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4094, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4095, CombTr_Loss: 1.7, CombTr_Acc: 0.3, CVHum_Loss: 2.11, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4096, CombTr_Loss: 1.38, CombTr_Acc: 0.36, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 11, Step: 4097, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4098, CombTr_Loss: 1.33, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4099, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 1.55, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4100, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4101, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.57, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4102, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.2 \n",
      "Epoch: 11, Step: 4103, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4104, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4105, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4106, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4107, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4108, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.48 \n",
      "Epoch: 11, Step: 4109, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4110, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4111, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.6, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4112, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4113, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4114, CombTr_Loss: 1.55, CombTr_Acc: 0.34, CVHum_Loss: 2.15, CVHum_Acc: 0.24 \n",
      "Epoch: 11, Step: 4115, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 11, Step: 4116, CombTr_Loss: 1.16, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4117, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4118, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4119, CombTr_Loss: 1.26, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 4120, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.57, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4121, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4122, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 11, Step: 4123, CombTr_Loss: 1.62, CombTr_Acc: 0.38, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 11, Step: 4124, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 2.27, CVHum_Acc: 0.18 \n",
      "Epoch: 11, Step: 4125, CombTr_Loss: 1.63, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4126, CombTr_Loss: 1.54, CombTr_Acc: 0.38, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 11, Step: 4127, CombTr_Loss: 1.24, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 11, Step: 4128, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 2.17, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4129, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4130, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 2.11, CVHum_Acc: 0.22 \n",
      "Epoch: 11, Step: 4131, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 11, Step: 4132, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4133, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 2.13, CVHum_Acc: 0.2 \n",
      "Epoch: 11, Step: 4134, CombTr_Loss: 1.17, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4135, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.16 \n",
      "Epoch: 11, Step: 4136, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 11, Step: 4137, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.94, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4138, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 11, Step: 4139, CombTr_Loss: 1.17, CombTr_Acc: 0.64, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 11, Step: 4140, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.3 \n",
      "Avg_CombTrain_Loss: 1.37, Avg_CombTrain_Acc: 0.47, Avg_CVHum_Loss: 1.76, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 11\n",
      "Epoch: 12, Step: 4141, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4142, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 2.46, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4143, CombTr_Loss: 1.24, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4144, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4145, CombTr_Loss: 1.32, CombTr_Acc: 0.44, CVHum_Loss: 1.88, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4146, CombTr_Loss: 1.34, CombTr_Acc: 0.56, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4147, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4148, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4149, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.62, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4150, CombTr_Loss: 1.22, CombTr_Acc: 0.62, CVHum_Loss: 1.89, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4151, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 2.04, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4152, CombTr_Loss: 1.22, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4153, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4154, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4155, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4156, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4157, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4158, CombTr_Loss: 1.41, CombTr_Acc: 0.36, CVHum_Loss: 2.22, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4159, CombTr_Loss: 1.28, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4160, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4161, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4162, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4163, CombTr_Loss: 1.54, CombTr_Acc: 0.36, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4164, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 2.44, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4165, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.79, CVHum_Acc: 0.52 \n",
      "Epoch: 12, Step: 4166, CombTr_Loss: 1.51, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4167, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 2.23, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4168, CombTr_Loss: 1.32, CombTr_Acc: 0.4, CVHum_Loss: 1.49, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4169, CombTr_Loss: 1.53, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4170, CombTr_Loss: 1.18, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4171, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 2.19, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4172, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4173, CombTr_Loss: 1.27, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4174, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 2.14, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4175, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4176, CombTr_Loss: 1.51, CombTr_Acc: 0.36, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4177, CombTr_Loss: 1.22, CombTr_Acc: 0.46, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4178, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 12, Step: 4179, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4180, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4181, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4182, CombTr_Loss: 1.63, CombTr_Acc: 0.3, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4183, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 2.15, CVHum_Acc: 0.18 \n",
      "Epoch: 12, Step: 4184, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4185, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4186, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 2.1, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4187, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4188, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4189, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4190, CombTr_Loss: 1.32, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4191, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4192, CombTr_Loss: 1.07, CombTr_Acc: 0.64, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4193, CombTr_Loss: 1.32, CombTr_Acc: 0.6, CVHum_Loss: 2.11, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4194, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 2.09, CVHum_Acc: 0.14 \n",
      "Epoch: 12, Step: 4195, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4196, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4197, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4198, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4199, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4200, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.96, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4201, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 1.41, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4202, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4203, CombTr_Loss: 1.55, CombTr_Acc: 0.32, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4204, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4205, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4206, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4207, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4208, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4209, CombTr_Loss: 1.24, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4210, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4211, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4212, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4213, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4214, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4215, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 1.36, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4216, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4217, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 2.14, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4218, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4219, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4220, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4221, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 2.07, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4222, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4223, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4224, CombTr_Loss: 1.32, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4225, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.59, CVHum_Acc: 0.48 \n",
      "Epoch: 12, Step: 4226, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4227, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 2.13, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4228, CombTr_Loss: 1.37, CombTr_Acc: 0.54, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4229, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4230, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4231, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4232, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4233, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 2.11, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4234, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4235, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4236, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4237, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4238, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4239, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4240, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4241, CombTr_Loss: 1.01, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4242, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4243, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 2.04, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4244, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4245, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4246, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4247, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.5, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4248, CombTr_Loss: 1.54, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4249, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4250, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4251, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4252, CombTr_Loss: 1.57, CombTr_Acc: 0.48, CVHum_Loss: 2.37, CVHum_Acc: 0.12 \n",
      "Epoch: 12, Step: 4253, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4254, CombTr_Loss: 1.52, CombTr_Acc: 0.48, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4255, CombTr_Loss: 1.17, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4256, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4257, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4258, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4259, CombTr_Loss: 1.56, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4260, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.78, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4261, CombTr_Loss: 1.27, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4262, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4263, CombTr_Loss: 1.35, CombTr_Acc: 0.54, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4264, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4265, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4266, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 2.01, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4267, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4268, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4269, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4270, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4271, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4272, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4273, CombTr_Loss: 1.38, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4274, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4275, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4276, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4277, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.48 \n",
      "Epoch: 12, Step: 4278, CombTr_Loss: 1.11, CombTr_Acc: 0.68, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4279, CombTr_Loss: 1.42, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4280, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4281, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4282, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4283, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4284, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.46, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4285, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4286, CombTr_Loss: 1.06, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4287, CombTr_Loss: 1.2, CombTr_Acc: 0.62, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4288, CombTr_Loss: 1.45, CombTr_Acc: 0.36, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4289, CombTr_Loss: 1.51, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4290, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.99, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4291, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4292, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.93, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4293, CombTr_Loss: 1.51, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4294, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4295, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4296, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 2.31, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4297, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4298, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4299, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4300, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4301, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4302, CombTr_Loss: 1.34, CombTr_Acc: 0.58, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4303, CombTr_Loss: 1.15, CombTr_Acc: 0.62, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4304, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4305, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4306, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.53, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4307, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4308, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4309, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.85, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4310, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4311, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4312, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4313, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.98, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4314, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4315, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4316, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4317, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4318, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4319, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4320, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4321, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4322, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4323, CombTr_Loss: 1.58, CombTr_Acc: 0.34, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4324, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.93, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4325, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4326, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4327, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4328, CombTr_Loss: 1.37, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4329, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4330, CombTr_Loss: 1.08, CombTr_Acc: 0.52, CVHum_Loss: 1.52, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4331, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4332, CombTr_Loss: 1.47, CombTr_Acc: 0.4, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4333, CombTr_Loss: 1.3, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4334, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.52, CVHum_Acc: 0.46 \n",
      "Epoch: 12, Step: 4335, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4336, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4337, CombTr_Loss: 1.56, CombTr_Acc: 0.34, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4338, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4339, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.52, CVHum_Acc: 0.52 \n",
      "Epoch: 12, Step: 4340, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4341, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4342, CombTr_Loss: 1.58, CombTr_Acc: 0.36, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4343, CombTr_Loss: 1.27, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4344, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4345, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4346, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4347, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4348, CombTr_Loss: 1.41, CombTr_Acc: 0.54, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4349, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4350, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4351, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4352, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4353, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.6, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4354, CombTr_Loss: 1.32, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4355, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4356, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.54, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4357, CombTr_Loss: 1.5, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4358, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4359, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4360, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4361, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4362, CombTr_Loss: 1.64, CombTr_Acc: 0.38, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4363, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4364, CombTr_Loss: 1.35, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4365, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 2.08, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4366, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4367, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4368, CombTr_Loss: 1.4, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4369, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4370, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4371, CombTr_Loss: 1.01, CombTr_Acc: 0.66, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4372, CombTr_Loss: 1.67, CombTr_Acc: 0.32, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4373, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4374, CombTr_Loss: 1.43, CombTr_Acc: 0.32, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4375, CombTr_Loss: 1.24, CombTr_Acc: 0.46, CVHum_Loss: 1.38, CVHum_Acc: 0.6 \n",
      "Epoch: 12, Step: 4376, CombTr_Loss: 1.26, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4377, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4378, CombTr_Loss: 1.3, CombTr_Acc: 0.42, CVHum_Loss: 1.97, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4379, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4380, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4381, CombTr_Loss: 1.3, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4382, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4383, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4384, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4385, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.45, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4386, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4387, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4388, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4389, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4390, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 2.15, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4391, CombTr_Loss: 1.54, CombTr_Acc: 0.44, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4392, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4393, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4394, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4395, CombTr_Loss: 1.49, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4396, CombTr_Loss: 1.41, CombTr_Acc: 0.52, CVHum_Loss: 1.47, CVHum_Acc: 0.46 \n",
      "Epoch: 12, Step: 4397, CombTr_Loss: 1.19, CombTr_Acc: 0.62, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4398, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4399, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4400, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4401, CombTr_Loss: 1.37, CombTr_Acc: 0.42, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4402, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4403, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.48, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4404, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.92, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4405, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4406, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4407, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4408, CombTr_Loss: 1.23, CombTr_Acc: 0.48, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4409, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4410, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4411, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4412, CombTr_Loss: 1.5, CombTr_Acc: 0.4, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4413, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4414, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.48, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4415, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4416, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.56, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4417, CombTr_Loss: 1.34, CombTr_Acc: 0.38, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4418, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4419, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4420, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4421, CombTr_Loss: 1.33, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4422, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.43, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4423, CombTr_Loss: 1.49, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4424, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.94, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4425, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.58, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4426, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.18 \n",
      "Epoch: 12, Step: 4427, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4428, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.9, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4429, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4430, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4431, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4432, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.49, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4433, CombTr_Loss: 1.48, CombTr_Acc: 0.28, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4434, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 2.24, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4435, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4436, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.43, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4437, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4438, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4439, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4440, CombTr_Loss: 1.65, CombTr_Acc: 0.28, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4441, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.48 \n",
      "Epoch: 12, Step: 4442, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4443, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4444, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.54, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4445, CombTr_Loss: 1.24, CombTr_Acc: 0.62, CVHum_Loss: 1.47, CVHum_Acc: 0.56 \n",
      "Epoch: 12, Step: 4446, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4447, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.16 \n",
      "Epoch: 12, Step: 4448, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.2 \n",
      "Epoch: 12, Step: 4449, CombTr_Loss: 1.42, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4450, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4451, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4452, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4453, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.56, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4454, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4455, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4456, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4457, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 12, Step: 4458, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4459, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 2.15, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4460, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4461, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.48, CVHum_Acc: 0.46 \n",
      "Epoch: 12, Step: 4462, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4463, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4464, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4465, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 12, Step: 4466, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 1.69, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4467, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4468, CombTr_Loss: 1.56, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4469, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 2.26, CVHum_Acc: 0.18 \n",
      "Epoch: 12, Step: 4470, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 2.01, CVHum_Acc: 0.22 \n",
      "Epoch: 12, Step: 4471, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 12, Step: 4472, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 12, Step: 4473, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4474, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 2.11, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4475, CombTr_Loss: 1.58, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4476, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 2.06, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4477, CombTr_Loss: 1.32, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.5 \n",
      "Epoch: 12, Step: 4478, CombTr_Loss: 1.28, CombTr_Acc: 0.4, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 12, Step: 4479, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 12, Step: 4480, CombTr_Loss: 1.24, CombTr_Acc: 0.6, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 12, Step: 4481, CombTr_Loss: 1.32, CombTr_Acc: 0.42, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 12, Step: 4482, CombTr_Loss: 1.48, CombTr_Acc: 0.44, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 12, Step: 4483, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 12, Step: 4484, CombTr_Loss: 1.17, CombTr_Acc: 0.58, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 12, Step: 4485, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.32 \n",
      "Avg_CombTrain_Loss: 1.33, Avg_CombTrain_Acc: 0.49, Avg_CVHum_Loss: 1.79, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 12\n",
      "Epoch: 13, Step: 4486, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4487, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 2.54, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4488, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4489, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 2.07, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4490, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.91, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4491, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4492, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 2.07, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4493, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.13, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4494, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4495, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4496, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 2.13, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4497, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 2.08, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4498, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4499, CombTr_Loss: 1.21, CombTr_Acc: 0.58, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4500, CombTr_Loss: 1.33, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4501, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4502, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4503, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.53, CVHum_Acc: 0.2 \n",
      "Epoch: 13, Step: 4504, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4505, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4506, CombTr_Loss: 1.09, CombTr_Acc: 0.64, CVHum_Loss: 1.97, CVHum_Acc: 0.16 \n",
      "Epoch: 13, Step: 4507, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4508, CombTr_Loss: 1.53, CombTr_Acc: 0.36, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4509, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 2.48, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4510, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4511, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4512, CombTr_Loss: 1.16, CombTr_Acc: 0.5, CVHum_Loss: 2.16, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4513, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 13, Step: 4514, CombTr_Loss: 1.45, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4515, CombTr_Loss: 1.19, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4516, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 2.24, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4517, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4518, CombTr_Loss: 1.24, CombTr_Acc: 0.42, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4519, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 2.24, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4520, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4521, CombTr_Loss: 1.48, CombTr_Acc: 0.36, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4522, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.74, CVHum_Acc: 0.5 \n",
      "Epoch: 13, Step: 4523, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4524, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4525, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4526, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.96, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4527, CombTr_Loss: 1.6, CombTr_Acc: 0.4, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4528, CombTr_Loss: 1.45, CombTr_Acc: 0.54, CVHum_Loss: 2.2, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4529, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4530, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4531, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.24, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4532, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4533, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4534, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4535, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4536, CombTr_Loss: 1.38, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4537, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4538, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 2.23, CVHum_Acc: 0.18 \n",
      "Epoch: 13, Step: 4539, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 2.11, CVHum_Acc: 0.18 \n",
      "Epoch: 13, Step: 4540, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.54, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4541, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.62, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4542, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4543, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4544, CombTr_Loss: 1.38, CombTr_Acc: 0.58, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4545, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 2.11, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4546, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 1.49, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4547, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4548, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4549, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4550, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4551, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4552, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 1.46, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4553, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4554, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.48, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4555, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4556, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4557, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4558, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4559, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4560, CombTr_Loss: 1.04, CombTr_Acc: 0.68, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4561, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4562, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4563, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4564, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4565, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4566, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 2.09, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4567, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4568, CombTr_Loss: 1.09, CombTr_Acc: 0.52, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4569, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4570, CombTr_Loss: 1.49, CombTr_Acc: 0.4, CVHum_Loss: 1.68, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4571, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4572, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 2.23, CVHum_Acc: 0.14 \n",
      "Epoch: 13, Step: 4573, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 13, Step: 4574, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4575, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.86, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4576, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4577, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.78, CVHum_Acc: 0.5 \n",
      "Epoch: 13, Step: 4578, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 2.16, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4579, CombTr_Loss: 1.53, CombTr_Acc: 0.38, CVHum_Loss: 1.48, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4580, CombTr_Loss: 1.44, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4581, CombTr_Loss: 1.28, CombTr_Acc: 0.58, CVHum_Loss: 2.23, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4582, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4583, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4584, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4585, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4586, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4587, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4588, CombTr_Loss: 1.38, CombTr_Acc: 0.54, CVHum_Loss: 2.25, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4589, CombTr_Loss: 1.21, CombTr_Acc: 0.46, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4590, CombTr_Loss: 1.3, CombTr_Acc: 0.42, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4591, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4592, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.51, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4593, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4594, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4595, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4596, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4597, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 2.53, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4598, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4599, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4600, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4601, CombTr_Loss: 1.14, CombTr_Acc: 0.66, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4602, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4603, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4604, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4605, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.87, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4606, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4607, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 2.19, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4608, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4609, CombTr_Loss: 1.46, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4610, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.59, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4611, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4612, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4613, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4614, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4615, CombTr_Loss: 1.07, CombTr_Acc: 0.64, CVHum_Loss: 1.53, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4616, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4617, CombTr_Loss: 1.43, CombTr_Acc: 0.36, CVHum_Loss: 2.0, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4618, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4619, CombTr_Loss: 1.47, CombTr_Acc: 0.34, CVHum_Loss: 1.75, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4620, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4621, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4622, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4623, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4624, CombTr_Loss: 1.32, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4625, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4626, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4627, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4628, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4629, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4630, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4631, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4632, CombTr_Loss: 1.23, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4633, CombTr_Loss: 1.33, CombTr_Acc: 0.36, CVHum_Loss: 1.7, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4634, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4635, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 2.07, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4636, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4637, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4638, CombTr_Loss: 1.51, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4639, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4640, CombTr_Loss: 1.35, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4641, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.32, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4642, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4643, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4644, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 1.78, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4645, CombTr_Loss: 1.03, CombTr_Acc: 0.7, CVHum_Loss: 1.43, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4646, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4647, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4648, CombTr_Loss: 1.09, CombTr_Acc: 0.66, CVHum_Loss: 1.56, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4649, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4650, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.7, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4651, CombTr_Loss: 1.4, CombTr_Acc: 0.4, CVHum_Loss: 1.49, CVHum_Acc: 0.48 \n",
      "Epoch: 13, Step: 4652, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4653, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4654, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4655, CombTr_Loss: 1.46, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4656, CombTr_Loss: 1.05, CombTr_Acc: 0.52, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4657, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4658, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4659, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4660, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4661, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4662, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4663, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4664, CombTr_Loss: 1.52, CombTr_Acc: 0.32, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4665, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4666, CombTr_Loss: 1.21, CombTr_Acc: 0.6, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4667, CombTr_Loss: 1.17, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4668, CombTr_Loss: 1.58, CombTr_Acc: 0.44, CVHum_Loss: 1.42, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4669, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4670, CombTr_Loss: 1.48, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4671, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4672, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4673, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4674, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4675, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4676, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4677, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4678, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4679, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4680, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4681, CombTr_Loss: 1.28, CombTr_Acc: 0.4, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4682, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4683, CombTr_Loss: 1.23, CombTr_Acc: 0.48, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4684, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.39, CVHum_Acc: 0.52 \n",
      "Epoch: 13, Step: 4685, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4686, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4687, CombTr_Loss: 1.5, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.2 \n",
      "Epoch: 13, Step: 4688, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.8, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4689, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4690, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4691, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4692, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4693, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4694, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4695, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4696, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4697, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 2.04, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4698, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.51, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4699, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4700, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4701, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.48, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4702, CombTr_Loss: 1.42, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4703, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4704, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4705, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4706, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4707, CombTr_Loss: 1.63, CombTr_Acc: 0.32, CVHum_Loss: 1.65, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4708, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.52, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4709, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4710, CombTr_Loss: 1.51, CombTr_Acc: 0.38, CVHum_Loss: 2.17, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4711, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4712, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4713, CombTr_Loss: 1.56, CombTr_Acc: 0.44, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4714, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4715, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4716, CombTr_Loss: 1.0, CombTr_Acc: 0.68, CVHum_Loss: 2.39, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4717, CombTr_Loss: 1.57, CombTr_Acc: 0.46, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4718, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4719, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.6, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4720, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.32, CVHum_Acc: 0.54 \n",
      "Epoch: 13, Step: 4721, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4722, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4723, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 2.14, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4724, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4725, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4726, CombTr_Loss: 1.26, CombTr_Acc: 0.44, CVHum_Loss: 2.08, CVHum_Acc: 0.22 \n",
      "Epoch: 13, Step: 4727, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4728, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 2.02, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4729, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4730, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4731, CombTr_Loss: 1.43, CombTr_Acc: 0.42, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4732, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4733, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4734, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4735, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 2.25, CVHum_Acc: 0.2 \n",
      "Epoch: 13, Step: 4736, CombTr_Loss: 1.4, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4737, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4738, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 2.08, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4739, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.72, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4740, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4741, CombTr_Loss: 1.41, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4742, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4743, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4744, CombTr_Loss: 1.33, CombTr_Acc: 0.54, CVHum_Loss: 1.62, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4745, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4746, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4747, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.65, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4748, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4749, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4750, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4751, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4752, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4753, CombTr_Loss: 1.16, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4754, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4755, CombTr_Loss: 1.24, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4756, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4757, CombTr_Loss: 1.46, CombTr_Acc: 0.52, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4758, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4759, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4760, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.58, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4761, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4762, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4763, CombTr_Loss: 1.21, CombTr_Acc: 0.58, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4764, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4765, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4766, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4767, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.49, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4768, CombTr_Loss: 1.42, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4769, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 2.02, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4770, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4771, CombTr_Loss: 1.19, CombTr_Acc: 0.64, CVHum_Loss: 2.01, CVHum_Acc: 0.16 \n",
      "Epoch: 13, Step: 4772, CombTr_Loss: 1.26, CombTr_Acc: 0.38, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4773, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4774, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.59, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4775, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4776, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4777, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4778, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4779, CombTr_Loss: 1.37, CombTr_Acc: 0.52, CVHum_Loss: 2.34, CVHum_Acc: 0.14 \n",
      "Epoch: 13, Step: 4780, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4781, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4782, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4783, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4784, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4785, CombTr_Loss: 1.62, CombTr_Acc: 0.36, CVHum_Loss: 2.23, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4786, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 1.75, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4787, CombTr_Loss: 1.09, CombTr_Acc: 0.52, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4788, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4789, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.51, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4790, CombTr_Loss: 1.16, CombTr_Acc: 0.62, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4791, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4792, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 2.1, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4793, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4794, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4795, CombTr_Loss: 1.56, CombTr_Acc: 0.38, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4796, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4797, CombTr_Loss: 1.47, CombTr_Acc: 0.38, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4798, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4799, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.5, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4800, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4801, CombTr_Loss: 1.46, CombTr_Acc: 0.38, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4802, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4803, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4804, CombTr_Loss: 1.5, CombTr_Acc: 0.46, CVHum_Loss: 2.4, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4805, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4806, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.47, CVHum_Acc: 0.42 \n",
      "Epoch: 13, Step: 4807, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 2.11, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4808, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4809, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4810, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 13, Step: 4811, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4812, CombTr_Loss: 1.23, CombTr_Acc: 0.42, CVHum_Loss: 1.73, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4813, CombTr_Loss: 1.67, CombTr_Acc: 0.42, CVHum_Loss: 1.56, CVHum_Acc: 0.5 \n",
      "Epoch: 13, Step: 4814, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 2.38, CVHum_Acc: 0.18 \n",
      "Epoch: 13, Step: 4815, CombTr_Loss: 1.44, CombTr_Acc: 0.54, CVHum_Loss: 2.01, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4816, CombTr_Loss: 1.52, CombTr_Acc: 0.36, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 13, Step: 4817, CombTr_Loss: 1.26, CombTr_Acc: 0.6, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 13, Step: 4818, CombTr_Loss: 1.52, CombTr_Acc: 0.4, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 13, Step: 4819, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 2.11, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4820, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4821, CombTr_Loss: 1.25, CombTr_Acc: 0.4, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4822, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4823, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 2.2, CVHum_Acc: 0.24 \n",
      "Epoch: 13, Step: 4824, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 13, Step: 4825, CombTr_Loss: 1.22, CombTr_Acc: 0.6, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 13, Step: 4826, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.95, CVHum_Acc: 0.38 \n",
      "Epoch: 13, Step: 4827, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 13, Step: 4828, CombTr_Loss: 1.29, CombTr_Acc: 0.36, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 13, Step: 4829, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.36 \n",
      "Epoch: 13, Step: 4830, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.59, CVHum_Acc: 0.32 \n",
      "Avg_CombTrain_Loss: 1.28, Avg_CombTrain_Acc: 0.51, Avg_CVHum_Loss: 1.83, Avg_CVHum_Acc: 0.33 \n",
      "Model and weights saved at epoch 13\n",
      "Epoch: 14, Step: 4831, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4832, CombTr_Loss: 1.33, CombTr_Acc: 0.44, CVHum_Loss: 2.55, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4833, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4834, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4835, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 2.01, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 4836, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4837, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4838, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 2.15, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4839, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4840, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4841, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 2.15, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4842, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4843, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4844, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 2.03, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4845, CombTr_Loss: 1.34, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4846, CombTr_Loss: 1.38, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4847, CombTr_Loss: 1.15, CombTr_Acc: 0.64, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4848, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 2.37, CVHum_Acc: 0.18 \n",
      "Epoch: 14, Step: 4849, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4850, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4851, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4852, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4853, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.99, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4854, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 2.46, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4855, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4856, CombTr_Loss: 1.41, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4857, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.22, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4858, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.58, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 4859, CombTr_Loss: 1.48, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 4860, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4861, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 2.12, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4862, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4863, CombTr_Loss: 1.22, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4864, CombTr_Loss: 1.16, CombTr_Acc: 0.64, CVHum_Loss: 2.19, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4865, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4866, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.47, CVHum_Acc: 0.5 \n",
      "Epoch: 14, Step: 4867, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 1.86, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 4868, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 4869, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4870, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 1.56, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4871, CombTr_Loss: 1.29, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4872, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4873, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4874, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4875, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4876, CombTr_Loss: 1.13, CombTr_Acc: 0.5, CVHum_Loss: 2.18, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 4877, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4878, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4879, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4880, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4881, CombTr_Loss: 1.33, CombTr_Acc: 0.52, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4882, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4883, CombTr_Loss: 1.19, CombTr_Acc: 0.6, CVHum_Loss: 2.27, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4884, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 2.12, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 4885, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.53, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4886, CombTr_Loss: 1.13, CombTr_Acc: 0.62, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4887, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.91, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4888, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.99, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 4889, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4890, CombTr_Loss: 1.15, CombTr_Acc: 0.62, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4891, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4892, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4893, CombTr_Loss: 1.37, CombTr_Acc: 0.42, CVHum_Loss: 1.84, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4894, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.87, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4895, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4896, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4897, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4898, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4899, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4900, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4901, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4902, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4903, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4904, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4905, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 1.5, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4906, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4907, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 2.23, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4908, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4909, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4910, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.95, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4911, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 2.23, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4912, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4913, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4914, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4915, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 4916, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 1.94, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 4917, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.33, CVHum_Acc: 0.12 \n",
      "Epoch: 14, Step: 4918, CombTr_Loss: 1.17, CombTr_Acc: 0.6, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4919, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4920, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4921, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4922, CombTr_Loss: 1.08, CombTr_Acc: 0.66, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4923, CombTr_Loss: 1.15, CombTr_Acc: 0.62, CVHum_Loss: 2.19, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4924, CombTr_Loss: 1.57, CombTr_Acc: 0.38, CVHum_Loss: 1.49, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4925, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4926, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4927, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4928, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4929, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4930, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 2.14, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4931, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.06, CVHum_Acc: 0.16 \n",
      "Epoch: 14, Step: 4932, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4933, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 2.08, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4934, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4935, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4936, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4937, CombTr_Loss: 1.13, CombTr_Acc: 0.66, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4938, CombTr_Loss: 1.51, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4939, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4940, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4941, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4942, CombTr_Loss: 1.46, CombTr_Acc: 0.48, CVHum_Loss: 2.62, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4943, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.53, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4944, CombTr_Loss: 1.29, CombTr_Acc: 0.6, CVHum_Loss: 1.51, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4945, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4946, CombTr_Loss: 1.1, CombTr_Acc: 0.7, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4947, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.74, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4948, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4949, CombTr_Loss: 1.45, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4950, CombTr_Loss: 1.05, CombTr_Acc: 0.66, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4951, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4952, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4953, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4954, CombTr_Loss: 1.53, CombTr_Acc: 0.42, CVHum_Loss: 1.52, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 4955, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4956, CombTr_Loss: 1.27, CombTr_Acc: 0.64, CVHum_Loss: 2.25, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 4957, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4958, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4959, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4960, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4961, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4962, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4963, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4964, CombTr_Loss: 1.43, CombTr_Acc: 0.38, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4965, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4966, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4967, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4968, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4969, CombTr_Loss: 1.3, CombTr_Acc: 0.58, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4970, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4971, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4972, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.01, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4973, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 4974, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4975, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4976, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4977, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4978, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4979, CombTr_Loss: 1.48, CombTr_Acc: 0.42, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4980, CombTr_Loss: 1.13, CombTr_Acc: 0.66, CVHum_Loss: 2.1, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4981, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 4982, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 4983, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4984, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.53, CVHum_Acc: 0.52 \n",
      "Epoch: 14, Step: 4985, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4986, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 2.33, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 4987, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 4988, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4989, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 4990, CombTr_Loss: 1.03, CombTr_Acc: 0.56, CVHum_Loss: 1.43, CVHum_Acc: 0.54 \n",
      "Epoch: 14, Step: 4991, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 4992, CombTr_Loss: 1.3, CombTr_Acc: 0.52, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 4993, CombTr_Loss: 1.08, CombTr_Acc: 0.68, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4994, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4995, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 4996, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 4997, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 4998, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 4999, CombTr_Loss: 1.52, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5000, CombTr_Loss: 1.32, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5001, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5002, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5003, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 2.1, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5004, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5005, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5006, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5007, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5008, CombTr_Loss: 0.91, CombTr_Acc: 0.7, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5009, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5010, CombTr_Loss: 1.35, CombTr_Acc: 0.44, CVHum_Loss: 2.0, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5011, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 2.49, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5012, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5013, CombTr_Loss: 1.62, CombTr_Acc: 0.32, CVHum_Loss: 1.37, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5014, CombTr_Loss: 1.13, CombTr_Acc: 0.5, CVHum_Loss: 1.97, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5015, CombTr_Loss: 1.4, CombTr_Acc: 0.38, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5016, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5017, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5018, CombTr_Loss: 1.26, CombTr_Acc: 0.62, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5019, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5020, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5021, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5022, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5023, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5024, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5025, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 1.95, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5026, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.99, CVHum_Acc: 0.16 \n",
      "Epoch: 14, Step: 5027, CombTr_Loss: 1.42, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5028, CombTr_Loss: 1.08, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5029, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 5030, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5031, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5032, CombTr_Loss: 1.42, CombTr_Acc: 0.48, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5033, CombTr_Loss: 1.27, CombTr_Acc: 0.42, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 5034, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5035, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5036, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5037, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5038, CombTr_Loss: 1.41, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5039, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5040, CombTr_Loss: 1.05, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5041, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.68, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5042, CombTr_Loss: 1.52, CombTr_Acc: 0.32, CVHum_Loss: 2.01, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5043, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.52, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5044, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.99, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5045, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5046, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5047, CombTr_Loss: 1.33, CombTr_Acc: 0.42, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5048, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5049, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 1.99, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5050, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5051, CombTr_Loss: 1.0, CombTr_Acc: 0.6, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5052, CombTr_Loss: 1.48, CombTr_Acc: 0.38, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5053, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.57, CVHum_Acc: 0.52 \n",
      "Epoch: 14, Step: 5054, CombTr_Loss: 1.4, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5055, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 2.11, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5056, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5057, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.74, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5058, CombTr_Loss: 1.43, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 5059, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5060, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5061, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.37, CVHum_Acc: 0.18 \n",
      "Epoch: 14, Step: 5062, CombTr_Loss: 1.52, CombTr_Acc: 0.5, CVHum_Loss: 1.5, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5063, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5064, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.51, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5065, CombTr_Loss: 1.17, CombTr_Acc: 0.6, CVHum_Loss: 1.43, CVHum_Acc: 0.64 \n",
      "Epoch: 14, Step: 5066, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5067, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5068, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 2.07, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5069, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5070, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5071, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 2.14, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 5072, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5073, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5074, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5075, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5076, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5077, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5078, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.9, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5079, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5080, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 2.33, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 5081, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5082, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.51, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 5083, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5084, CombTr_Loss: 1.38, CombTr_Acc: 0.52, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5085, CombTr_Loss: 1.34, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5086, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.56, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5087, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5088, CombTr_Loss: 1.04, CombTr_Acc: 0.7, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5089, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5090, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5091, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5092, CombTr_Loss: 1.36, CombTr_Acc: 0.54, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 5093, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.63, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5094, CombTr_Loss: 1.39, CombTr_Acc: 0.48, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5095, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5096, CombTr_Loss: 1.36, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5097, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 5098, CombTr_Loss: 1.16, CombTr_Acc: 0.5, CVHum_Loss: 1.53, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5099, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 5100, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 2.02, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 5101, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5102, CombTr_Loss: 1.35, CombTr_Acc: 0.52, CVHum_Loss: 2.15, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5103, CombTr_Loss: 1.24, CombTr_Acc: 0.4, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5104, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 1.43, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 5105, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5106, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5107, CombTr_Loss: 1.21, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5108, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5109, CombTr_Loss: 1.39, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5110, CombTr_Loss: 1.4, CombTr_Acc: 0.42, CVHum_Loss: 1.68, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 5111, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5112, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.42, CVHum_Acc: 0.5 \n",
      "Epoch: 14, Step: 5113, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 2.0, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5114, CombTr_Loss: 1.45, CombTr_Acc: 0.5, CVHum_Loss: 2.02, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5115, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5116, CombTr_Loss: 1.05, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5117, CombTr_Loss: 1.16, CombTr_Acc: 0.5, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5118, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.17, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5119, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5120, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.94, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5121, CombTr_Loss: 1.28, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5122, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.59, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5123, CombTr_Loss: 1.47, CombTr_Acc: 0.3, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5124, CombTr_Loss: 1.28, CombTr_Acc: 0.58, CVHum_Loss: 2.44, CVHum_Acc: 0.16 \n",
      "Epoch: 14, Step: 5125, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5126, CombTr_Loss: 1.43, CombTr_Acc: 0.5, CVHum_Loss: 1.48, CVHum_Acc: 0.44 \n",
      "Epoch: 14, Step: 5127, CombTr_Loss: 0.85, CombTr_Acc: 0.72, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5128, CombTr_Loss: 1.06, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5129, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5130, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 2.25, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5131, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.58, CVHum_Acc: 0.5 \n",
      "Epoch: 14, Step: 5132, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5133, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5134, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5135, CombTr_Loss: 1.12, CombTr_Acc: 0.64, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5136, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5137, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 2.21, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5138, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5139, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5140, CombTr_Loss: 1.5, CombTr_Acc: 0.42, CVHum_Loss: 2.13, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5141, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 14, Step: 5142, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5143, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 1.71, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 5144, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5145, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5146, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5147, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.98, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5148, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5149, CombTr_Loss: 1.36, CombTr_Acc: 0.38, CVHum_Loss: 2.34, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 5150, CombTr_Loss: 1.19, CombTr_Acc: 0.6, CVHum_Loss: 2.14, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5151, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5152, CombTr_Loss: 1.31, CombTr_Acc: 0.44, CVHum_Loss: 2.1, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5153, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5154, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 2.01, CVHum_Acc: 0.2 \n",
      "Epoch: 14, Step: 5155, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 14, Step: 5156, CombTr_Loss: 1.24, CombTr_Acc: 0.6, CVHum_Loss: 1.87, CVHum_Acc: 0.22 \n",
      "Epoch: 14, Step: 5157, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5158, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.65, CVHum_Acc: 0.48 \n",
      "Epoch: 14, Step: 5159, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 2.59, CVHum_Acc: 0.16 \n",
      "Epoch: 14, Step: 5160, CombTr_Loss: 1.55, CombTr_Acc: 0.54, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5161, CombTr_Loss: 1.55, CombTr_Acc: 0.4, CVHum_Loss: 1.74, CVHum_Acc: 0.46 \n",
      "Epoch: 14, Step: 5162, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 14, Step: 5163, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5164, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 14, Step: 5165, CombTr_Loss: 1.46, CombTr_Acc: 0.5, CVHum_Loss: 2.08, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5166, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5167, CombTr_Loss: 1.24, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 14, Step: 5168, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5169, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.09, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5170, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 14, Step: 5171, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 2.16, CVHum_Acc: 0.3 \n",
      "Epoch: 14, Step: 5172, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 2.25, CVHum_Acc: 0.28 \n",
      "Epoch: 14, Step: 5173, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.42 \n",
      "Epoch: 14, Step: 5174, CombTr_Loss: 1.03, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.32 \n",
      "Epoch: 14, Step: 5175, CombTr_Loss: 1.17, CombTr_Acc: 0.58, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Avg_CombTrain_Loss: 1.24, Avg_CombTrain_Acc: 0.53, Avg_CVHum_Loss: 1.84, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 14\n",
      "Epoch: 15, Step: 5176, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.74, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5177, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.34, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5178, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5179, CombTr_Loss: 1.07, CombTr_Acc: 0.66, CVHum_Loss: 2.1, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5180, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5181, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5182, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 1.99, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5183, CombTr_Loss: 1.0, CombTr_Acc: 0.56, CVHum_Loss: 2.15, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5184, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5185, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5186, CombTr_Loss: 1.17, CombTr_Acc: 0.6, CVHum_Loss: 1.94, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5187, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 2.15, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5188, CombTr_Loss: 1.22, CombTr_Acc: 0.46, CVHum_Loss: 1.56, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5189, CombTr_Loss: 1.1, CombTr_Acc: 0.68, CVHum_Loss: 1.95, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5190, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5191, CombTr_Loss: 1.23, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5192, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5193, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 2.26, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5194, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5195, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5196, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5197, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5198, CombTr_Loss: 1.45, CombTr_Acc: 0.4, CVHum_Loss: 2.06, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5199, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 2.65, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5200, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.89, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5201, CombTr_Loss: 1.51, CombTr_Acc: 0.4, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5202, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 2.29, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5203, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5204, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5205, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5206, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.12, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5207, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5208, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5209, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 2.35, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5210, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5211, CombTr_Loss: 1.46, CombTr_Acc: 0.34, CVHum_Loss: 1.69, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5212, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 1.93, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5213, CombTr_Loss: 1.07, CombTr_Acc: 0.68, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5214, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 2.02, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5215, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5216, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 2.03, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5217, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5218, CombTr_Loss: 1.37, CombTr_Acc: 0.44, CVHum_Loss: 2.43, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5219, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5220, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.54, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5221, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.5, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5222, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.72, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5223, CombTr_Loss: 1.1, CombTr_Acc: 0.56, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5224, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5225, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.03, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5226, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5227, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5228, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 2.33, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5229, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 2.24, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5230, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5231, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5232, CombTr_Loss: 1.13, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5233, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.03, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5234, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 2.08, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5235, CombTr_Loss: 0.92, CombTr_Acc: 0.78, CVHum_Loss: 2.08, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5236, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5237, CombTr_Loss: 1.37, CombTr_Acc: 0.46, CVHum_Loss: 1.97, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5238, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5239, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 2.16, CVHum_Acc: 0.18 \n",
      "Epoch: 15, Step: 5240, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5241, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5242, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5243, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 2.05, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5244, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5245, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5246, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5247, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5248, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.87, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5249, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.13, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5250, CombTr_Loss: 0.87, CombTr_Acc: 0.7, CVHum_Loss: 1.54, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5251, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 2.29, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5252, CombTr_Loss: 1.44, CombTr_Acc: 0.52, CVHum_Loss: 2.5, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5253, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5254, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 2.16, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5255, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5256, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 2.34, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5257, CombTr_Loss: 1.11, CombTr_Acc: 0.64, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5258, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5259, CombTr_Loss: 1.32, CombTr_Acc: 0.44, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5260, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5261, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.99, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5262, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5263, CombTr_Loss: 1.19, CombTr_Acc: 0.62, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5264, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5265, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5266, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5267, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5268, CombTr_Loss: 1.12, CombTr_Acc: 0.5, CVHum_Loss: 2.29, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5269, CombTr_Loss: 1.63, CombTr_Acc: 0.4, CVHum_Loss: 1.61, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5270, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5271, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 2.15, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5272, CombTr_Loss: 1.18, CombTr_Acc: 0.62, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5273, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.13, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5274, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5275, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.12, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5276, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5277, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5278, CombTr_Loss: 1.32, CombTr_Acc: 0.56, CVHum_Loss: 2.42, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5279, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5280, CombTr_Loss: 1.24, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5281, CombTr_Loss: 1.24, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5282, CombTr_Loss: 1.22, CombTr_Acc: 0.58, CVHum_Loss: 1.53, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5283, CombTr_Loss: 1.39, CombTr_Acc: 0.5, CVHum_Loss: 1.67, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5284, CombTr_Loss: 1.21, CombTr_Acc: 0.46, CVHum_Loss: 1.9, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5285, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5286, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5287, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.66, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5288, CombTr_Loss: 1.34, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5289, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.56, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5290, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5291, CombTr_Loss: 0.96, CombTr_Acc: 0.7, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5292, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5293, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5294, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5295, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5296, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5297, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5298, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5299, CombTr_Loss: 1.47, CombTr_Acc: 0.46, CVHum_Loss: 1.63, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5300, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.82, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5301, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5302, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5303, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5304, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5305, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5306, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5307, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5308, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5309, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5310, CombTr_Loss: 1.23, CombTr_Acc: 0.42, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5311, CombTr_Loss: 1.07, CombTr_Acc: 0.5, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5312, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5313, CombTr_Loss: 1.11, CombTr_Acc: 0.68, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5314, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5315, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.09, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5316, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5317, CombTr_Loss: 1.08, CombTr_Acc: 0.52, CVHum_Loss: 2.37, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5318, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5319, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5320, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5321, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 2.01, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5322, CombTr_Loss: 0.92, CombTr_Acc: 0.62, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5323, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5324, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 2.12, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5325, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5326, CombTr_Loss: 1.3, CombTr_Acc: 0.42, CVHum_Loss: 1.92, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5327, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 2.04, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5328, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5329, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5330, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5331, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 2.45, CVHum_Acc: 0.18 \n",
      "Epoch: 15, Step: 5332, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5333, CombTr_Loss: 1.11, CombTr_Acc: 0.64, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5334, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.82, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5335, CombTr_Loss: 0.97, CombTr_Acc: 0.74, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5336, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5337, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 2.14, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5338, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5339, CombTr_Loss: 1.19, CombTr_Acc: 0.5, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5340, CombTr_Loss: 1.39, CombTr_Acc: 0.36, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5341, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 1.4, CVHum_Acc: 0.54 \n",
      "Epoch: 15, Step: 5342, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5343, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5344, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5345, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5346, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5347, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5348, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5349, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5350, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5351, CombTr_Loss: 1.49, CombTr_Acc: 0.42, CVHum_Loss: 1.62, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5352, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5353, CombTr_Loss: 0.98, CombTr_Acc: 0.68, CVHum_Loss: 1.63, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5354, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5355, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5356, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5357, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5358, CombTr_Loss: 1.5, CombTr_Acc: 0.34, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5359, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5360, CombTr_Loss: 1.38, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5361, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 1.72, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5362, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.8, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5363, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5364, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5365, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 1.6, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5366, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5367, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.91, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5368, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.57, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5369, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5370, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5371, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.03, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5372, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5373, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5374, CombTr_Loss: 1.07, CombTr_Acc: 0.5, CVHum_Loss: 1.57, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5375, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5376, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5377, CombTr_Loss: 1.35, CombTr_Acc: 0.54, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5378, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 2.07, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5379, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5380, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5381, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5382, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5383, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5384, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 2.06, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5385, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.79, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5386, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5387, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 2.22, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5388, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.58, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5389, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 2.04, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5390, CombTr_Loss: 1.28, CombTr_Acc: 0.58, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5391, CombTr_Loss: 1.46, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5392, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5393, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5394, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5395, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5396, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5397, CombTr_Loss: 1.54, CombTr_Acc: 0.4, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5398, CombTr_Loss: 1.17, CombTr_Acc: 0.58, CVHum_Loss: 1.46, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5399, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5400, CombTr_Loss: 1.47, CombTr_Acc: 0.42, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5401, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5402, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5403, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5404, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5405, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5406, CombTr_Loss: 0.98, CombTr_Acc: 0.68, CVHum_Loss: 2.46, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5407, CombTr_Loss: 1.41, CombTr_Acc: 0.44, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5408, CombTr_Loss: 1.52, CombTr_Acc: 0.42, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5409, CombTr_Loss: 1.32, CombTr_Acc: 0.4, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5410, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 1.49, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5411, CombTr_Loss: 1.06, CombTr_Acc: 0.66, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5412, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.74, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5413, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.03, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5414, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.2 \n",
      "Epoch: 15, Step: 5415, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5416, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5417, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.95, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5418, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5419, CombTr_Loss: 0.89, CombTr_Acc: 0.74, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5420, CombTr_Loss: 1.28, CombTr_Acc: 0.42, CVHum_Loss: 1.36, CVHum_Acc: 0.46 \n",
      "Epoch: 15, Step: 5421, CombTr_Loss: 1.18, CombTr_Acc: 0.62, CVHum_Loss: 1.75, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5422, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5423, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5424, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5425, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 2.56, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5426, CombTr_Loss: 1.22, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5427, CombTr_Loss: 1.25, CombTr_Acc: 0.44, CVHum_Loss: 1.55, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5428, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 2.08, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5429, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5430, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5431, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5432, CombTr_Loss: 1.12, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5433, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5434, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5435, CombTr_Loss: 1.24, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5436, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.07, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5437, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5438, CombTr_Loss: 0.96, CombTr_Acc: 0.7, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5439, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 2.12, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5440, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 2.01, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5441, CombTr_Loss: 1.16, CombTr_Acc: 0.48, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5442, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5443, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.52, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5444, CombTr_Loss: 0.97, CombTr_Acc: 0.74, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5445, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.14 \n",
      "Epoch: 15, Step: 5446, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5447, CombTr_Loss: 1.35, CombTr_Acc: 0.46, CVHum_Loss: 2.18, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5448, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5449, CombTr_Loss: 1.38, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5450, CombTr_Loss: 0.99, CombTr_Acc: 0.56, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5451, CombTr_Loss: 1.06, CombTr_Acc: 0.66, CVHum_Loss: 1.72, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5452, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5453, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5454, CombTr_Loss: 1.19, CombTr_Acc: 0.46, CVHum_Loss: 1.82, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5455, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5456, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 2.14, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5457, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.65, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5458, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 2.04, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5459, CombTr_Loss: 1.43, CombTr_Acc: 0.4, CVHum_Loss: 2.11, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5460, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.57, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5461, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5462, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 2.32, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5463, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 2.14, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5464, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 1.68, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5465, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5466, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5467, CombTr_Loss: 1.29, CombTr_Acc: 0.42, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5468, CombTr_Loss: 1.23, CombTr_Acc: 0.4, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5469, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 2.45, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5470, CombTr_Loss: 1.19, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5471, CombTr_Loss: 1.24, CombTr_Acc: 0.6, CVHum_Loss: 1.46, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5472, CombTr_Loss: 0.81, CombTr_Acc: 0.76, CVHum_Loss: 1.91, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5473, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5474, CombTr_Loss: 1.24, CombTr_Acc: 0.44, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5475, CombTr_Loss: 1.58, CombTr_Acc: 0.42, CVHum_Loss: 2.35, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5476, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5477, CombTr_Loss: 1.1, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5478, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5479, CombTr_Loss: 1.19, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5480, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5481, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5482, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 2.3, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5483, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5484, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 15, Step: 5485, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5486, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5487, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5488, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 1.66, CVHum_Acc: 0.44 \n",
      "Epoch: 15, Step: 5489, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5490, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5491, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5492, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5493, CombTr_Loss: 1.21, CombTr_Acc: 0.58, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5494, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 2.37, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5495, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5496, CombTr_Loss: 1.1, CombTr_Acc: 0.56, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5497, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 2.14, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5498, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5499, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 15, Step: 5500, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5501, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5502, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5503, CombTr_Loss: 1.42, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5504, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.73, CVHum_Acc: 0.18 \n",
      "Epoch: 15, Step: 5505, CombTr_Loss: 1.33, CombTr_Acc: 0.6, CVHum_Loss: 2.18, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5506, CombTr_Loss: 1.38, CombTr_Acc: 0.5, CVHum_Loss: 1.73, CVHum_Acc: 0.5 \n",
      "Epoch: 15, Step: 5507, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 1.78, CVHum_Acc: 0.42 \n",
      "Epoch: 15, Step: 5508, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5509, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5510, CombTr_Loss: 1.32, CombTr_Acc: 0.46, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 15, Step: 5511, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 2.18, CVHum_Acc: 0.32 \n",
      "Epoch: 15, Step: 5512, CombTr_Loss: 1.19, CombTr_Acc: 0.44, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5513, CombTr_Loss: 1.17, CombTr_Acc: 0.62, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5514, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 2.03, CVHum_Acc: 0.22 \n",
      "Epoch: 15, Step: 5515, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 2.09, CVHum_Acc: 0.24 \n",
      "Epoch: 15, Step: 5516, CombTr_Loss: 1.4, CombTr_Acc: 0.44, CVHum_Loss: 2.11, CVHum_Acc: 0.3 \n",
      "Epoch: 15, Step: 5517, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 2.31, CVHum_Acc: 0.36 \n",
      "Epoch: 15, Step: 5518, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 15, Step: 5519, CombTr_Loss: 1.04, CombTr_Acc: 0.52, CVHum_Loss: 2.01, CVHum_Acc: 0.4 \n",
      "Epoch: 15, Step: 5520, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Avg_CombTrain_Loss: 1.19, Avg_CombTrain_Acc: 0.54, Avg_CVHum_Loss: 1.89, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 15\n",
      "Epoch: 16, Step: 5521, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.01, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5522, CombTr_Loss: 1.05, CombTr_Acc: 0.62, CVHum_Loss: 2.85, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5523, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 1.98, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5524, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 2.09, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5525, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5526, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 1.83, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5527, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 2.21, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5528, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 2.25, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5529, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5530, CombTr_Loss: 1.08, CombTr_Acc: 0.64, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5531, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5532, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5533, CombTr_Loss: 1.3, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5534, CombTr_Loss: 0.98, CombTr_Acc: 0.72, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5535, CombTr_Loss: 1.29, CombTr_Acc: 0.58, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5536, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5537, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5538, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 2.49, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5539, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5540, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5541, CombTr_Loss: 1.02, CombTr_Acc: 0.7, CVHum_Loss: 2.04, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5542, CombTr_Loss: 1.23, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5543, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 2.07, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5544, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 2.64, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5545, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.52 \n",
      "Epoch: 16, Step: 5546, CombTr_Loss: 1.45, CombTr_Acc: 0.42, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5547, CombTr_Loss: 1.01, CombTr_Acc: 0.54, CVHum_Loss: 2.47, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5548, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.79, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5549, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.91, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5550, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5551, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 2.47, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5552, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5553, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5554, CombTr_Loss: 1.08, CombTr_Acc: 0.66, CVHum_Loss: 2.43, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5555, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5556, CombTr_Loss: 1.34, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5557, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.93, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5558, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5559, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.07, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5560, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5561, CombTr_Loss: 1.3, CombTr_Acc: 0.44, CVHum_Loss: 1.96, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5562, CombTr_Loss: 1.35, CombTr_Acc: 0.38, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5563, CombTr_Loss: 1.39, CombTr_Acc: 0.4, CVHum_Loss: 2.69, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5564, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5565, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.42, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5566, CombTr_Loss: 0.94, CombTr_Acc: 0.66, CVHum_Loss: 2.41, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5567, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5568, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.65, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5569, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5570, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.03, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5571, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 2.14, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5572, CombTr_Loss: 0.88, CombTr_Acc: 0.76, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5573, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.52, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5574, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 2.11, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5575, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5576, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5577, CombTr_Loss: 1.16, CombTr_Acc: 0.5, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5578, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 2.04, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5579, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 1.96, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5580, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5581, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 1.61, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5582, CombTr_Loss: 1.49, CombTr_Acc: 0.38, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5583, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5584, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 2.09, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5585, CombTr_Loss: 1.12, CombTr_Acc: 0.5, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5586, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5587, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.49, CVHum_Acc: 0.5 \n",
      "Epoch: 16, Step: 5588, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5589, CombTr_Loss: 1.2, CombTr_Acc: 0.46, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5590, CombTr_Loss: 1.04, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5591, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 2.14, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5592, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5593, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5594, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 2.28, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5595, CombTr_Loss: 0.86, CombTr_Acc: 0.66, CVHum_Loss: 1.54, CVHum_Acc: 0.54 \n",
      "Epoch: 16, Step: 5596, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 2.37, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5597, CombTr_Loss: 1.37, CombTr_Acc: 0.58, CVHum_Loss: 2.6, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5598, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 1.87, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5599, CombTr_Loss: 0.91, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5600, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 2.25, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5601, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 2.39, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5602, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 1.73, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5603, CombTr_Loss: 0.93, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5604, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5605, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5606, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5607, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.41, CVHum_Acc: 0.18 \n",
      "Epoch: 16, Step: 5608, CombTr_Loss: 1.33, CombTr_Acc: 0.48, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5609, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5610, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5611, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5612, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 1.89, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5613, CombTr_Loss: 1.12, CombTr_Acc: 0.66, CVHum_Loss: 2.37, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5614, CombTr_Loss: 1.44, CombTr_Acc: 0.48, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5615, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.54, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5616, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.34, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5617, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5618, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5619, CombTr_Loss: 1.05, CombTr_Acc: 0.66, CVHum_Loss: 2.06, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5620, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 2.11, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5621, CombTr_Loss: 0.91, CombTr_Acc: 0.62, CVHum_Loss: 2.08, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5622, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5623, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 2.55, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5624, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 2.08, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5625, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5626, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 1.89, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5627, CombTr_Loss: 0.99, CombTr_Acc: 0.68, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5628, CombTr_Loss: 1.47, CombTr_Acc: 0.44, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5629, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5630, CombTr_Loss: 1.24, CombTr_Acc: 0.46, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5631, CombTr_Loss: 1.0, CombTr_Acc: 0.68, CVHum_Loss: 2.08, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5632, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.63, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5633, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 1.53, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5634, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 1.43, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5635, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5636, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5637, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 1.87, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5638, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5639, CombTr_Loss: 1.27, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5640, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5641, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5642, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.22, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5643, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.3, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5644, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 1.57, CVHum_Acc: 0.48 \n",
      "Epoch: 16, Step: 5645, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.75, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5646, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 2.16, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5647, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 2.17, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5648, CombTr_Loss: 1.39, CombTr_Acc: 0.46, CVHum_Loss: 1.94, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5649, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 2.27, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5650, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.58, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5651, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5652, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5653, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5654, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 1.87, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5655, CombTr_Loss: 1.25, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5656, CombTr_Loss: 0.92, CombTr_Acc: 0.72, CVHum_Loss: 1.52, CVHum_Acc: 0.48 \n",
      "Epoch: 16, Step: 5657, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5658, CombTr_Loss: 0.96, CombTr_Acc: 0.72, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5659, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5660, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5661, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5662, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5663, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5664, CombTr_Loss: 1.07, CombTr_Acc: 0.64, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5665, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5666, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.13, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5667, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5668, CombTr_Loss: 1.17, CombTr_Acc: 0.48, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5669, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 2.05, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5670, CombTr_Loss: 1.12, CombTr_Acc: 0.7, CVHum_Loss: 2.21, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5671, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5672, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 2.22, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5673, CombTr_Loss: 1.34, CombTr_Acc: 0.48, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5674, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.7, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5675, CombTr_Loss: 1.09, CombTr_Acc: 0.5, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5676, CombTr_Loss: 1.12, CombTr_Acc: 0.62, CVHum_Loss: 2.51, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5677, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5678, CombTr_Loss: 1.19, CombTr_Acc: 0.6, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5679, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5680, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 1.56, CVHum_Acc: 0.5 \n",
      "Epoch: 16, Step: 5681, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5682, CombTr_Loss: 1.21, CombTr_Acc: 0.48, CVHum_Loss: 2.2, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5683, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5684, CombTr_Loss: 1.16, CombTr_Acc: 0.62, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5685, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5686, CombTr_Loss: 1.44, CombTr_Acc: 0.5, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5687, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5688, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5689, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.92, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5690, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5691, CombTr_Loss: 1.0, CombTr_Acc: 0.66, CVHum_Loss: 1.77, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5692, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.21, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5693, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5694, CombTr_Loss: 1.42, CombTr_Acc: 0.52, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5695, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.91, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5696, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5697, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.86, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5698, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5699, CombTr_Loss: 1.3, CombTr_Acc: 0.44, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5700, CombTr_Loss: 1.35, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5701, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.47, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5702, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5703, CombTr_Loss: 1.32, CombTr_Acc: 0.48, CVHum_Loss: 1.54, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5704, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5705, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5706, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.83, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5707, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5708, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5709, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5710, CombTr_Loss: 1.06, CombTr_Acc: 0.7, CVHum_Loss: 1.74, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5711, CombTr_Loss: 1.17, CombTr_Acc: 0.64, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5712, CombTr_Loss: 1.55, CombTr_Acc: 0.42, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5713, CombTr_Loss: 1.13, CombTr_Acc: 0.62, CVHum_Loss: 1.44, CVHum_Acc: 0.62 \n",
      "Epoch: 16, Step: 5714, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 1.57, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5715, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.14, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5716, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5717, CombTr_Loss: 1.27, CombTr_Acc: 0.54, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5718, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5719, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5720, CombTr_Loss: 1.04, CombTr_Acc: 0.68, CVHum_Loss: 1.73, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5721, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5722, CombTr_Loss: 1.26, CombTr_Acc: 0.46, CVHum_Loss: 2.09, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5723, CombTr_Loss: 1.01, CombTr_Acc: 0.54, CVHum_Loss: 2.09, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5724, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5725, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5726, CombTr_Loss: 1.12, CombTr_Acc: 0.66, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5727, CombTr_Loss: 0.98, CombTr_Acc: 0.58, CVHum_Loss: 1.59, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5728, CombTr_Loss: 1.28, CombTr_Acc: 0.48, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5729, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 2.15, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5730, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5731, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5732, CombTr_Loss: 1.26, CombTr_Acc: 0.44, CVHum_Loss: 2.25, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5733, CombTr_Loss: 1.26, CombTr_Acc: 0.6, CVHum_Loss: 1.49, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5734, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5735, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 2.36, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5736, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5737, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5738, CombTr_Loss: 1.08, CombTr_Acc: 0.52, CVHum_Loss: 2.06, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5739, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 2.04, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5740, CombTr_Loss: 1.07, CombTr_Acc: 0.52, CVHum_Loss: 1.57, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5741, CombTr_Loss: 0.9, CombTr_Acc: 0.58, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5742, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 1.7, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5743, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.52, CVHum_Acc: 0.48 \n",
      "Epoch: 16, Step: 5744, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5745, CombTr_Loss: 1.4, CombTr_Acc: 0.46, CVHum_Loss: 2.2, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5746, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5747, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5748, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5749, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5750, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.85, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5751, CombTr_Loss: 0.86, CombTr_Acc: 0.66, CVHum_Loss: 2.54, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5752, CombTr_Loss: 1.44, CombTr_Acc: 0.46, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5753, CombTr_Loss: 1.41, CombTr_Acc: 0.42, CVHum_Loss: 1.82, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5754, CombTr_Loss: 1.29, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5755, CombTr_Loss: 1.13, CombTr_Acc: 0.5, CVHum_Loss: 1.48, CVHum_Acc: 0.52 \n",
      "Epoch: 16, Step: 5756, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.95, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5757, CombTr_Loss: 1.34, CombTr_Acc: 0.52, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5758, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 2.29, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5759, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5760, CombTr_Loss: 1.37, CombTr_Acc: 0.38, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5761, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.27, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5762, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5763, CombTr_Loss: 1.04, CombTr_Acc: 0.54, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5764, CombTr_Loss: 0.94, CombTr_Acc: 0.72, CVHum_Loss: 1.89, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5765, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5766, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5767, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5768, CombTr_Loss: 1.22, CombTr_Acc: 0.44, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5769, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5770, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 2.55, CVHum_Acc: 0.16 \n",
      "Epoch: 16, Step: 5771, CombTr_Loss: 1.19, CombTr_Acc: 0.54, CVHum_Loss: 1.87, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5772, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5773, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.33, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5774, CombTr_Loss: 1.36, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5775, CombTr_Loss: 1.44, CombTr_Acc: 0.54, CVHum_Loss: 2.02, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5776, CombTr_Loss: 1.33, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5777, CombTr_Loss: 0.91, CombTr_Acc: 0.72, CVHum_Loss: 1.88, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5778, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.89, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5779, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 1.64, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5780, CombTr_Loss: 1.4, CombTr_Acc: 0.54, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5781, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 2.18, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5782, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5783, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 1.57, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5784, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 1.97, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5785, CombTr_Loss: 0.99, CombTr_Acc: 0.68, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5786, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5787, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5788, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5789, CombTr_Loss: 1.01, CombTr_Acc: 0.68, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5790, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5791, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5792, CombTr_Loss: 1.25, CombTr_Acc: 0.46, CVHum_Loss: 2.15, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5793, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5794, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5795, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.69, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5796, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5797, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.5, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5798, CombTr_Loss: 1.08, CombTr_Acc: 0.66, CVHum_Loss: 2.33, CVHum_Acc: 0.18 \n",
      "Epoch: 16, Step: 5799, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.46 \n",
      "Epoch: 16, Step: 5800, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5801, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.57, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5802, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5803, CombTr_Loss: 1.24, CombTr_Acc: 0.68, CVHum_Loss: 2.35, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5804, CombTr_Loss: 1.4, CombTr_Acc: 0.48, CVHum_Loss: 2.03, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5805, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5806, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 16, Step: 5807, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5808, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 2.11, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5809, CombTr_Loss: 1.11, CombTr_Acc: 0.64, CVHum_Loss: 1.6, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5810, CombTr_Loss: 1.45, CombTr_Acc: 0.56, CVHum_Loss: 2.1, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5811, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.66, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5812, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.59, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5813, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5814, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 2.61, CVHum_Acc: 0.14 \n",
      "Epoch: 16, Step: 5815, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5816, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5817, CombTr_Loss: 0.88, CombTr_Acc: 0.64, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5818, CombTr_Loss: 0.82, CombTr_Acc: 0.7, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5819, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.01, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5820, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 2.61, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5821, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5822, CombTr_Loss: 1.02, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5823, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5824, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.68, CVHum_Acc: 0.48 \n",
      "Epoch: 16, Step: 5825, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5826, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5827, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 2.2, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5828, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5829, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5830, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 2.24, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5831, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 1.98, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5832, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.87, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5833, CombTr_Loss: 0.92, CombTr_Acc: 0.7, CVHum_Loss: 1.74, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5834, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5835, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5836, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5837, CombTr_Loss: 1.1, CombTr_Acc: 0.52, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5838, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5839, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 2.69, CVHum_Acc: 0.22 \n",
      "Epoch: 16, Step: 5840, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5841, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.45, CVHum_Acc: 0.48 \n",
      "Epoch: 16, Step: 5842, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 2.21, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5843, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 16, Step: 5844, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5845, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 16, Step: 5846, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5847, CombTr_Loss: 1.37, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5848, CombTr_Loss: 1.39, CombTr_Acc: 0.52, CVHum_Loss: 1.68, CVHum_Acc: 0.44 \n",
      "Epoch: 16, Step: 5849, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.53, CVHum_Acc: 0.2 \n",
      "Epoch: 16, Step: 5850, CombTr_Loss: 1.3, CombTr_Acc: 0.56, CVHum_Loss: 2.28, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5851, CombTr_Loss: 1.36, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5852, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 16, Step: 5853, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.12, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5854, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.95, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5855, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5856, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 2.15, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5857, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 16, Step: 5858, CombTr_Loss: 0.97, CombTr_Acc: 0.6, CVHum_Loss: 2.2, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5859, CombTr_Loss: 1.04, CombTr_Acc: 0.66, CVHum_Loss: 2.13, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5860, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 16, Step: 5861, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 16, Step: 5862, CombTr_Loss: 1.25, CombTr_Acc: 0.44, CVHum_Loss: 2.36, CVHum_Acc: 0.28 \n",
      "Epoch: 16, Step: 5863, CombTr_Loss: 1.23, CombTr_Acc: 0.46, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 16, Step: 5864, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 2.02, CVHum_Acc: 0.38 \n",
      "Epoch: 16, Step: 5865, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Avg_CombTrain_Loss: 1.15, Avg_CombTrain_Acc: 0.56, Avg_CVHum_Loss: 1.94, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 16\n",
      "Epoch: 17, Step: 5866, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5867, CombTr_Loss: 1.07, CombTr_Acc: 0.52, CVHum_Loss: 2.67, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5868, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5869, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5870, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 2.13, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5871, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5872, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.43, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5873, CombTr_Loss: 0.93, CombTr_Acc: 0.56, CVHum_Loss: 2.35, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5874, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5875, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.0, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5876, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 2.14, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5877, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 2.11, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5878, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.61, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5879, CombTr_Loss: 0.98, CombTr_Acc: 0.74, CVHum_Loss: 2.0, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5880, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5881, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 1.74, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 5882, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 1.8, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 5883, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.59, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5884, CombTr_Loss: 1.09, CombTr_Acc: 0.52, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5885, CombTr_Loss: 0.98, CombTr_Acc: 0.7, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 5886, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5887, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5888, CombTr_Loss: 1.43, CombTr_Acc: 0.44, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5889, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.64, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5890, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5891, CombTr_Loss: 1.39, CombTr_Acc: 0.44, CVHum_Loss: 1.74, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5892, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.3, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5893, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.73, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5894, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5895, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.0, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5896, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 2.34, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5897, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5898, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.78, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5899, CombTr_Loss: 1.1, CombTr_Acc: 0.64, CVHum_Loss: 2.43, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5900, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5901, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5902, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.03, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 5903, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.87, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 5904, CombTr_Loss: 1.24, CombTr_Acc: 0.4, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5905, CombTr_Loss: 1.26, CombTr_Acc: 0.48, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5906, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 2.0, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5907, CombTr_Loss: 1.35, CombTr_Acc: 0.56, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5908, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 2.7, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5909, CombTr_Loss: 1.24, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 5910, CombTr_Loss: 0.96, CombTr_Acc: 0.68, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 5911, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 2.64, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5912, CombTr_Loss: 1.3, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5913, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 1.78, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 5914, CombTr_Loss: 0.96, CombTr_Acc: 0.68, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5915, CombTr_Loss: 0.95, CombTr_Acc: 0.62, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5916, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 2.15, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5917, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 2.06, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5918, CombTr_Loss: 1.22, CombTr_Acc: 0.46, CVHum_Loss: 2.69, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5919, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.57, CVHum_Acc: 0.16 \n",
      "Epoch: 17, Step: 5920, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 1.58, CVHum_Acc: 0.48 \n",
      "Epoch: 17, Step: 5921, CombTr_Loss: 1.01, CombTr_Acc: 0.7, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5922, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5923, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 2.18, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5924, CombTr_Loss: 1.31, CombTr_Acc: 0.58, CVHum_Loss: 2.27, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5925, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.16, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5926, CombTr_Loss: 0.88, CombTr_Acc: 0.72, CVHum_Loss: 1.74, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 5927, CombTr_Loss: 1.14, CombTr_Acc: 0.48, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5928, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5929, CombTr_Loss: 1.14, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5930, CombTr_Loss: 1.07, CombTr_Acc: 0.64, CVHum_Loss: 2.08, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5931, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 2.16, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5932, CombTr_Loss: 0.99, CombTr_Acc: 0.7, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5933, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.94, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5934, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5935, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5936, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 2.27, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5937, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.99, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5938, CombTr_Loss: 1.06, CombTr_Acc: 0.66, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5939, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 2.38, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5940, CombTr_Loss: 0.9, CombTr_Acc: 0.62, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 17, Step: 5941, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 2.3, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5942, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 2.67, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5943, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5944, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 2.25, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5945, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 2.43, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5946, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 2.31, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5947, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.61, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5948, CombTr_Loss: 0.9, CombTr_Acc: 0.6, CVHum_Loss: 2.12, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5949, CombTr_Loss: 1.28, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5950, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 1.8, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 5951, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.07, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5952, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.55, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5953, CombTr_Loss: 1.04, CombTr_Acc: 0.7, CVHum_Loss: 1.72, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 5954, CombTr_Loss: 1.2, CombTr_Acc: 0.48, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5955, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5956, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5957, CombTr_Loss: 0.94, CombTr_Acc: 0.66, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5958, CombTr_Loss: 1.1, CombTr_Acc: 0.5, CVHum_Loss: 2.46, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 5959, CombTr_Loss: 1.46, CombTr_Acc: 0.4, CVHum_Loss: 1.57, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5960, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5961, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 2.18, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5962, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.78, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5963, CombTr_Loss: 0.87, CombTr_Acc: 0.64, CVHum_Loss: 2.19, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5964, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5965, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 2.34, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5966, CombTr_Loss: 0.82, CombTr_Acc: 0.66, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5967, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5968, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.7, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5969, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5970, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 1.74, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5971, CombTr_Loss: 1.11, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5972, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 5973, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5974, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 2.14, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5975, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 5976, CombTr_Loss: 0.94, CombTr_Acc: 0.58, CVHum_Loss: 2.17, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 5977, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 2.87, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 5978, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 1.65, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5979, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.73, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 5980, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 2.18, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5981, CombTr_Loss: 0.88, CombTr_Acc: 0.68, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5982, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5983, CombTr_Loss: 0.98, CombTr_Acc: 0.7, CVHum_Loss: 2.3, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 5984, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 2.12, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5985, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5986, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5987, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.32, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5988, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 2.54, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 5989, CombTr_Loss: 1.22, CombTr_Acc: 0.48, CVHum_Loss: 1.89, CVHum_Acc: 0.48 \n",
      "Epoch: 17, Step: 5990, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.68, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 5991, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.34, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5992, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 2.27, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5993, CombTr_Loss: 0.94, CombTr_Acc: 0.66, CVHum_Loss: 2.21, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 5994, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.42, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 5995, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 1.55, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 5996, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 1.75, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5997, CombTr_Loss: 1.12, CombTr_Acc: 0.48, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 5998, CombTr_Loss: 1.04, CombTr_Acc: 0.54, CVHum_Loss: 2.13, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 5999, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6000, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6001, CombTr_Loss: 0.9, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6002, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6003, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.98, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6004, CombTr_Loss: 1.03, CombTr_Acc: 0.7, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6005, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 2.18, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6006, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 2.11, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6007, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.41, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6008, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 2.26, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6009, CombTr_Loss: 1.16, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6010, CombTr_Loss: 1.31, CombTr_Acc: 0.48, CVHum_Loss: 2.22, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6011, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.27, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6012, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6013, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6014, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6015, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 2.34, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6016, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6017, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6018, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 2.06, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6019, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.86, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6020, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6021, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 2.54, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6022, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6023, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 2.0, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6024, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6025, CombTr_Loss: 0.95, CombTr_Acc: 0.68, CVHum_Loss: 1.66, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6026, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6027, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.38, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6028, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 1.5, CVHum_Acc: 0.5 \n",
      "Epoch: 17, Step: 6029, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6030, CombTr_Loss: 1.11, CombTr_Acc: 0.64, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6031, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 1.52, CVHum_Acc: 0.52 \n",
      "Epoch: 17, Step: 6032, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6033, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6034, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.96, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6035, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6036, CombTr_Loss: 0.91, CombTr_Acc: 0.62, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6037, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 2.28, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6038, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.22, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6039, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 1.73, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6040, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6041, CombTr_Loss: 1.41, CombTr_Acc: 0.5, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6042, CombTr_Loss: 1.08, CombTr_Acc: 0.5, CVHum_Loss: 1.93, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6043, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6044, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6045, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.48 \n",
      "Epoch: 17, Step: 6046, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 2.57, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6047, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6048, CombTr_Loss: 1.24, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6049, CombTr_Loss: 0.86, CombTr_Acc: 0.72, CVHum_Loss: 2.17, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6050, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6051, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 1.95, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6052, CombTr_Loss: 1.14, CombTr_Acc: 0.48, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6053, CombTr_Loss: 0.93, CombTr_Acc: 0.6, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6054, CombTr_Loss: 1.12, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6055, CombTr_Loss: 0.93, CombTr_Acc: 0.66, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6056, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.22, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6057, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 2.29, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6058, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.53, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6059, CombTr_Loss: 0.91, CombTr_Acc: 0.7, CVHum_Loss: 1.61, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6060, CombTr_Loss: 0.95, CombTr_Acc: 0.6, CVHum_Loss: 2.33, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6061, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.09, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6062, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 2.11, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6063, CombTr_Loss: 0.93, CombTr_Acc: 0.7, CVHum_Loss: 2.2, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6064, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.5, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6065, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6066, CombTr_Loss: 1.15, CombTr_Acc: 0.62, CVHum_Loss: 1.99, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6067, CombTr_Loss: 1.31, CombTr_Acc: 0.4, CVHum_Loss: 2.18, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6068, CombTr_Loss: 0.97, CombTr_Acc: 0.6, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6069, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6070, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 6071, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6072, CombTr_Loss: 0.92, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6073, CombTr_Loss: 1.23, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6074, CombTr_Loss: 1.17, CombTr_Acc: 0.46, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6075, CombTr_Loss: 1.12, CombTr_Acc: 0.64, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6076, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.97, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6077, CombTr_Loss: 1.19, CombTr_Acc: 0.52, CVHum_Loss: 2.52, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6078, CombTr_Loss: 1.05, CombTr_Acc: 0.62, CVHum_Loss: 1.72, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6079, CombTr_Loss: 1.13, CombTr_Acc: 0.5, CVHum_Loss: 2.15, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6080, CombTr_Loss: 1.23, CombTr_Acc: 0.5, CVHum_Loss: 2.33, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6081, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 1.75, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6082, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 2.23, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6083, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 2.38, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6084, CombTr_Loss: 0.83, CombTr_Acc: 0.68, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6085, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 1.51, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6086, CombTr_Loss: 0.83, CombTr_Acc: 0.72, CVHum_Loss: 2.11, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6087, CombTr_Loss: 1.35, CombTr_Acc: 0.5, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6088, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.64, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6089, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6090, CombTr_Loss: 1.3, CombTr_Acc: 0.48, CVHum_Loss: 2.35, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6091, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6092, CombTr_Loss: 0.89, CombTr_Acc: 0.68, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6093, CombTr_Loss: 1.26, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6094, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6095, CombTr_Loss: 1.29, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6096, CombTr_Loss: 0.82, CombTr_Acc: 0.74, CVHum_Loss: 2.76, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6097, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 1.58, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6098, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6099, CombTr_Loss: 1.18, CombTr_Acc: 0.5, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6100, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.47, CVHum_Acc: 0.5 \n",
      "Epoch: 17, Step: 6101, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6102, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6103, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 2.36, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6104, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6105, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6106, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 2.17, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 6107, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 1.85, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6108, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6109, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6110, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6111, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.89, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6112, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.93, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6113, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6114, CombTr_Loss: 0.98, CombTr_Acc: 0.68, CVHum_Loss: 2.2, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6115, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.5, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6116, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6117, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.58, CVHum_Acc: 0.52 \n",
      "Epoch: 17, Step: 6118, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 2.34, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6119, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6120, CombTr_Loss: 1.27, CombTr_Acc: 0.52, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6121, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.66, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6122, CombTr_Loss: 0.87, CombTr_Acc: 0.62, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6123, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6124, CombTr_Loss: 1.12, CombTr_Acc: 0.64, CVHum_Loss: 1.69, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6125, CombTr_Loss: 1.24, CombTr_Acc: 0.5, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6126, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 2.31, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6127, CombTr_Loss: 1.14, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6128, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 1.57, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6129, CombTr_Loss: 1.32, CombTr_Acc: 0.5, CVHum_Loss: 2.15, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6130, CombTr_Loss: 0.98, CombTr_Acc: 0.72, CVHum_Loss: 2.1, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6131, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6132, CombTr_Loss: 1.1, CombTr_Acc: 0.5, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6133, CombTr_Loss: 0.88, CombTr_Acc: 0.7, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6134, CombTr_Loss: 0.9, CombTr_Acc: 0.72, CVHum_Loss: 1.77, CVHum_Acc: 0.44 \n",
      "Epoch: 17, Step: 6135, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.14, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6136, CombTr_Loss: 1.07, CombTr_Acc: 0.46, CVHum_Loss: 2.22, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6137, CombTr_Loss: 1.23, CombTr_Acc: 0.52, CVHum_Loss: 2.19, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6138, CombTr_Loss: 1.18, CombTr_Acc: 0.48, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6139, CombTr_Loss: 1.25, CombTr_Acc: 0.54, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6140, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.6, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6141, CombTr_Loss: 1.05, CombTr_Acc: 0.7, CVHum_Loss: 1.8, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6142, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6143, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 2.15, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6144, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6145, CombTr_Loss: 1.31, CombTr_Acc: 0.54, CVHum_Loss: 1.98, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6146, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.43, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6147, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 1.59, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6148, CombTr_Loss: 1.27, CombTr_Acc: 0.56, CVHum_Loss: 2.32, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6149, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 2.41, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6150, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 1.66, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6151, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 2.39, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 6152, CombTr_Loss: 1.1, CombTr_Acc: 0.52, CVHum_Loss: 2.38, CVHum_Acc: 0.24 \n",
      "Epoch: 17, Step: 6153, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6154, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6155, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.86, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6156, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6157, CombTr_Loss: 1.19, CombTr_Acc: 0.48, CVHum_Loss: 1.71, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6158, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.98, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6159, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 2.75, CVHum_Acc: 0.2 \n",
      "Epoch: 17, Step: 6160, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.17, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6161, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.28 \n",
      "Epoch: 17, Step: 6162, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.12, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6163, CombTr_Loss: 0.82, CombTr_Acc: 0.62, CVHum_Loss: 1.88, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6164, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6165, CombTr_Loss: 1.45, CombTr_Acc: 0.48, CVHum_Loss: 2.89, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6166, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 1.79, CVHum_Acc: 0.5 \n",
      "Epoch: 17, Step: 6167, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6168, CombTr_Loss: 1.36, CombTr_Acc: 0.48, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6169, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.62, CVHum_Acc: 0.5 \n",
      "Epoch: 17, Step: 6170, CombTr_Loss: 1.09, CombTr_Acc: 0.66, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6171, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6172, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 2.42, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6173, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6174, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6175, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6176, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.03, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6177, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6178, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.74, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6179, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6180, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6181, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6182, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 2.14, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6183, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6184, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 2.66, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6185, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.18, CVHum_Acc: 0.42 \n",
      "Epoch: 17, Step: 6186, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 1.52, CVHum_Acc: 0.38 \n",
      "Epoch: 17, Step: 6187, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.26, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6188, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.79, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6189, CombTr_Loss: 1.0, CombTr_Acc: 0.7, CVHum_Loss: 2.21, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6190, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6191, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6192, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6193, CombTr_Loss: 1.36, CombTr_Acc: 0.42, CVHum_Loss: 1.92, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6194, CombTr_Loss: 0.85, CombTr_Acc: 0.74, CVHum_Loss: 2.54, CVHum_Acc: 0.26 \n",
      "Epoch: 17, Step: 6195, CombTr_Loss: 1.3, CombTr_Acc: 0.62, CVHum_Loss: 2.43, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6196, CombTr_Loss: 1.3, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6197, CombTr_Loss: 0.96, CombTr_Acc: 0.7, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6198, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6199, CombTr_Loss: 1.04, CombTr_Acc: 0.54, CVHum_Loss: 2.04, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6200, CombTr_Loss: 1.2, CombTr_Acc: 0.46, CVHum_Loss: 2.08, CVHum_Acc: 0.32 \n",
      "Epoch: 17, Step: 6201, CombTr_Loss: 1.03, CombTr_Acc: 0.54, CVHum_Loss: 2.18, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6202, CombTr_Loss: 1.12, CombTr_Acc: 0.44, CVHum_Loss: 1.72, CVHum_Acc: 0.46 \n",
      "Epoch: 17, Step: 6203, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6204, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6205, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 1.92, CVHum_Acc: 0.22 \n",
      "Epoch: 17, Step: 6206, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 2.12, CVHum_Acc: 0.3 \n",
      "Epoch: 17, Step: 6207, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 2.42, CVHum_Acc: 0.34 \n",
      "Epoch: 17, Step: 6208, CombTr_Loss: 1.11, CombTr_Acc: 0.5, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 17, Step: 6209, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.96, CVHum_Acc: 0.36 \n",
      "Epoch: 17, Step: 6210, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.87, CVHum_Acc: 0.32 \n",
      "Avg_CombTrain_Loss: 1.1, Avg_CombTrain_Acc: 0.58, Avg_CVHum_Loss: 2.01, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 17\n",
      "Epoch: 18, Step: 6211, CombTr_Loss: 0.99, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6212, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 2.72, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6213, CombTr_Loss: 1.05, CombTr_Acc: 0.48, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6214, CombTr_Loss: 1.02, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6215, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 2.22, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6216, CombTr_Loss: 1.05, CombTr_Acc: 0.62, CVHum_Loss: 2.04, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6217, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.43, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6218, CombTr_Loss: 0.97, CombTr_Acc: 0.68, CVHum_Loss: 2.4, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6219, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6220, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 2.19, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6221, CombTr_Loss: 0.83, CombTr_Acc: 0.74, CVHum_Loss: 2.21, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6222, CombTr_Loss: 0.87, CombTr_Acc: 0.7, CVHum_Loss: 2.24, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6223, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.61, CVHum_Acc: 0.5 \n",
      "Epoch: 18, Step: 6224, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6225, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.93, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6226, CombTr_Loss: 1.03, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6227, CombTr_Loss: 0.87, CombTr_Acc: 0.66, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6228, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.74, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6229, CombTr_Loss: 1.0, CombTr_Acc: 0.6, CVHum_Loss: 2.03, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6230, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6231, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 2.36, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6232, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.11, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6233, CombTr_Loss: 1.27, CombTr_Acc: 0.46, CVHum_Loss: 2.51, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6234, CombTr_Loss: 1.09, CombTr_Acc: 0.5, CVHum_Loss: 3.12, CVHum_Acc: 0.2 \n",
      "Epoch: 18, Step: 6235, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.09, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6236, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6237, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.87, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6238, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.85, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6239, CombTr_Loss: 1.23, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6240, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 2.26, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6241, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 2.5, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6242, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.11, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6243, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6244, CombTr_Loss: 1.06, CombTr_Acc: 0.68, CVHum_Loss: 2.46, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6245, CombTr_Loss: 1.18, CombTr_Acc: 0.64, CVHum_Loss: 2.09, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6246, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6247, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.21, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6248, CombTr_Loss: 0.93, CombTr_Acc: 0.66, CVHum_Loss: 1.89, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6249, CombTr_Loss: 1.0, CombTr_Acc: 0.54, CVHum_Loss: 2.0, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6250, CombTr_Loss: 1.09, CombTr_Acc: 0.52, CVHum_Loss: 2.11, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6251, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 2.13, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6252, CombTr_Loss: 1.42, CombTr_Acc: 0.42, CVHum_Loss: 2.32, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6253, CombTr_Loss: 1.43, CombTr_Acc: 0.48, CVHum_Loss: 2.76, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6254, CombTr_Loss: 1.17, CombTr_Acc: 0.5, CVHum_Loss: 2.05, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6255, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 1.53, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6256, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.77, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6257, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 1.88, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6258, CombTr_Loss: 1.27, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6259, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.77, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6260, CombTr_Loss: 0.92, CombTr_Acc: 0.6, CVHum_Loss: 2.19, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6261, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6262, CombTr_Loss: 0.85, CombTr_Acc: 0.72, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6263, CombTr_Loss: 1.21, CombTr_Acc: 0.58, CVHum_Loss: 2.54, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6264, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 2.49, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6265, CombTr_Loss: 0.95, CombTr_Acc: 0.58, CVHum_Loss: 1.81, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6266, CombTr_Loss: 1.15, CombTr_Acc: 0.62, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6267, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.97, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6268, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 2.25, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6269, CombTr_Loss: 1.23, CombTr_Acc: 0.58, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6270, CombTr_Loss: 1.05, CombTr_Acc: 0.66, CVHum_Loss: 2.17, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6271, CombTr_Loss: 0.76, CombTr_Acc: 0.74, CVHum_Loss: 1.8, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6272, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 2.2, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6273, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.91, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6274, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 1.98, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6275, CombTr_Loss: 1.02, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6276, CombTr_Loss: 0.86, CombTr_Acc: 0.62, CVHum_Loss: 2.11, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6277, CombTr_Loss: 0.97, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6278, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.82, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6279, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6280, CombTr_Loss: 0.94, CombTr_Acc: 0.7, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6281, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 2.28, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6282, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6283, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.03, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6284, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 2.37, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6285, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6286, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 2.63, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6287, CombTr_Loss: 1.33, CombTr_Acc: 0.52, CVHum_Loss: 2.6, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6288, CombTr_Loss: 1.0, CombTr_Acc: 0.56, CVHum_Loss: 1.86, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6289, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.25, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6290, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 2.37, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6291, CombTr_Loss: 1.07, CombTr_Acc: 0.52, CVHum_Loss: 2.34, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6292, CombTr_Loss: 0.97, CombTr_Acc: 0.58, CVHum_Loss: 1.49, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6293, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 2.01, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6294, CombTr_Loss: 1.07, CombTr_Acc: 0.66, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6295, CombTr_Loss: 1.32, CombTr_Acc: 0.44, CVHum_Loss: 1.91, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6296, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 2.06, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6297, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 2.32, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6298, CombTr_Loss: 1.2, CombTr_Acc: 0.56, CVHum_Loss: 1.73, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6299, CombTr_Loss: 1.03, CombTr_Acc: 0.52, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6300, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 2.29, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6301, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6302, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 2.03, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6303, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.68, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6304, CombTr_Loss: 1.27, CombTr_Acc: 0.44, CVHum_Loss: 1.6, CVHum_Acc: 0.5 \n",
      "Epoch: 18, Step: 6305, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.74, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6306, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 2.42, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6307, CombTr_Loss: 1.13, CombTr_Acc: 0.46, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6308, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.32, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6309, CombTr_Loss: 1.0, CombTr_Acc: 0.68, CVHum_Loss: 2.1, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6310, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 2.22, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6311, CombTr_Loss: 0.81, CombTr_Acc: 0.64, CVHum_Loss: 2.14, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6312, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.85, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6313, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.66, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6314, CombTr_Loss: 0.97, CombTr_Acc: 0.72, CVHum_Loss: 2.39, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6315, CombTr_Loss: 1.15, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6316, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 2.0, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6317, CombTr_Loss: 1.1, CombTr_Acc: 0.64, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6318, CombTr_Loss: 1.24, CombTr_Acc: 0.54, CVHum_Loss: 1.83, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6319, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6320, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6321, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.12, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6322, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 3.19, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6323, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 1.68, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6324, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.6, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6325, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6326, CombTr_Loss: 0.9, CombTr_Acc: 0.72, CVHum_Loss: 2.0, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6327, CombTr_Loss: 0.9, CombTr_Acc: 0.64, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6328, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.41, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6329, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 2.16, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6330, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 2.15, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6331, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 1.82, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6332, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6333, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 2.58, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6334, CombTr_Loss: 1.38, CombTr_Acc: 0.42, CVHum_Loss: 2.07, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6335, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6336, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.44, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6337, CombTr_Loss: 1.01, CombTr_Acc: 0.66, CVHum_Loss: 2.52, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6338, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 2.12, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6339, CombTr_Loss: 0.96, CombTr_Acc: 0.56, CVHum_Loss: 2.56, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6340, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 1.56, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6341, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.8, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6342, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 2.12, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6343, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 2.34, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6344, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 2.12, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6345, CombTr_Loss: 1.17, CombTr_Acc: 0.48, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6346, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6347, CombTr_Loss: 0.9, CombTr_Acc: 0.6, CVHum_Loss: 1.83, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6348, CombTr_Loss: 0.98, CombTr_Acc: 0.68, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6349, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.36, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6350, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6351, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.09, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6352, CombTr_Loss: 0.91, CombTr_Acc: 0.68, CVHum_Loss: 2.6, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6353, CombTr_Loss: 1.12, CombTr_Acc: 0.52, CVHum_Loss: 2.41, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6354, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.88, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6355, CombTr_Loss: 1.13, CombTr_Acc: 0.62, CVHum_Loss: 2.16, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6356, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.24, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6357, CombTr_Loss: 1.02, CombTr_Acc: 0.58, CVHum_Loss: 2.1, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6358, CombTr_Loss: 1.04, CombTr_Acc: 0.7, CVHum_Loss: 2.06, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6359, CombTr_Loss: 1.16, CombTr_Acc: 0.62, CVHum_Loss: 2.35, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6360, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.55, CVHum_Acc: 0.2 \n",
      "Epoch: 18, Step: 6361, CombTr_Loss: 1.23, CombTr_Acc: 0.44, CVHum_Loss: 1.79, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6362, CombTr_Loss: 1.27, CombTr_Acc: 0.44, CVHum_Loss: 2.35, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6363, CombTr_Loss: 1.16, CombTr_Acc: 0.58, CVHum_Loss: 1.77, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6364, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.83, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6365, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.83, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6366, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 2.56, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6367, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6368, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.92, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6369, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.21, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6370, CombTr_Loss: 0.9, CombTr_Acc: 0.62, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6371, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6372, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.5, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6373, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 1.6, CVHum_Acc: 0.5 \n",
      "Epoch: 18, Step: 6374, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.65, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6375, CombTr_Loss: 1.02, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6376, CombTr_Loss: 1.3, CombTr_Acc: 0.46, CVHum_Loss: 1.47, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6377, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6378, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6379, CombTr_Loss: 1.2, CombTr_Acc: 0.64, CVHum_Loss: 2.0, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6380, CombTr_Loss: 1.21, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6381, CombTr_Loss: 0.93, CombTr_Acc: 0.64, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6382, CombTr_Loss: 1.14, CombTr_Acc: 0.52, CVHum_Loss: 2.43, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6383, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.27, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6384, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6385, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.81, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6386, CombTr_Loss: 1.25, CombTr_Acc: 0.56, CVHum_Loss: 1.61, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6387, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6388, CombTr_Loss: 0.77, CombTr_Acc: 0.72, CVHum_Loss: 1.8, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6389, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.85, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6390, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 1.98, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6391, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 2.45, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6392, CombTr_Loss: 1.13, CombTr_Acc: 0.52, CVHum_Loss: 1.81, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6393, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 1.66, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6394, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 2.21, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6395, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 1.94, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6396, CombTr_Loss: 0.94, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6397, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 1.88, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6398, CombTr_Loss: 0.95, CombTr_Acc: 0.7, CVHum_Loss: 2.01, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6399, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.91, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6400, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 1.51, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6401, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6402, CombTr_Loss: 1.23, CombTr_Acc: 0.42, CVHum_Loss: 2.26, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6403, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6404, CombTr_Loss: 0.99, CombTr_Acc: 0.72, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6405, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.23, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6406, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 2.07, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6407, CombTr_Loss: 1.41, CombTr_Acc: 0.4, CVHum_Loss: 2.09, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6408, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.02, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6409, CombTr_Loss: 1.01, CombTr_Acc: 0.66, CVHum_Loss: 1.7, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6410, CombTr_Loss: 1.19, CombTr_Acc: 0.46, CVHum_Loss: 1.79, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6411, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 1.78, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6412, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.04, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6413, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.08, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6414, CombTr_Loss: 1.13, CombTr_Acc: 0.62, CVHum_Loss: 2.14, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6415, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6416, CombTr_Loss: 1.09, CombTr_Acc: 0.68, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6417, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6418, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6419, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 2.13, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6420, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6421, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 2.19, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6422, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.51, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6423, CombTr_Loss: 1.14, CombTr_Acc: 0.62, CVHum_Loss: 1.68, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6424, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.21, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6425, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.62, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6426, CombTr_Loss: 1.31, CombTr_Acc: 0.42, CVHum_Loss: 1.81, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6427, CombTr_Loss: 1.03, CombTr_Acc: 0.56, CVHum_Loss: 2.2, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6428, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 2.62, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6429, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 1.99, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6430, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.55, CVHum_Acc: 0.54 \n",
      "Epoch: 18, Step: 6431, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.01, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6432, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6433, CombTr_Loss: 0.97, CombTr_Acc: 0.6, CVHum_Loss: 1.6, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6434, CombTr_Loss: 1.06, CombTr_Acc: 0.66, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6435, CombTr_Loss: 1.44, CombTr_Acc: 0.4, CVHum_Loss: 2.45, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6436, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6437, CombTr_Loss: 0.77, CombTr_Acc: 0.72, CVHum_Loss: 1.91, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6438, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6439, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6440, CombTr_Loss: 1.26, CombTr_Acc: 0.5, CVHum_Loss: 1.9, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6441, CombTr_Loss: 0.92, CombTr_Acc: 0.72, CVHum_Loss: 2.62, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6442, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6443, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6444, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.67, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6445, CombTr_Loss: 1.11, CombTr_Acc: 0.68, CVHum_Loss: 1.6, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6446, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6447, CombTr_Loss: 1.32, CombTr_Acc: 0.56, CVHum_Loss: 1.93, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6448, CombTr_Loss: 1.09, CombTr_Acc: 0.48, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6449, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 2.34, CVHum_Acc: 0.18 \n",
      "Epoch: 18, Step: 6450, CombTr_Loss: 1.33, CombTr_Acc: 0.54, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6451, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 2.32, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6452, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6453, CombTr_Loss: 1.03, CombTr_Acc: 0.5, CVHum_Loss: 2.0, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6454, CombTr_Loss: 0.85, CombTr_Acc: 0.72, CVHum_Loss: 1.81, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6455, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 1.75, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6456, CombTr_Loss: 1.13, CombTr_Acc: 0.48, CVHum_Loss: 1.98, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6457, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 1.83, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6458, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6459, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.2, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6460, CombTr_Loss: 0.94, CombTr_Acc: 0.66, CVHum_Loss: 2.71, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6461, CombTr_Loss: 1.31, CombTr_Acc: 0.5, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6462, CombTr_Loss: 1.23, CombTr_Acc: 0.46, CVHum_Loss: 1.73, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6463, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.41, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6464, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 1.68, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6465, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6466, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.83, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6467, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 1.89, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6468, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6469, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 1.9, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6470, CombTr_Loss: 1.34, CombTr_Acc: 0.5, CVHum_Loss: 2.09, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6471, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 2.22, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6472, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6473, CombTr_Loss: 0.87, CombTr_Acc: 0.72, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6474, CombTr_Loss: 1.4, CombTr_Acc: 0.5, CVHum_Loss: 2.14, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6475, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 2.25, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6476, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 2.12, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6477, CombTr_Loss: 0.87, CombTr_Acc: 0.72, CVHum_Loss: 2.09, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6478, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.7, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6479, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6480, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.2, CVHum_Acc: 0.2 \n",
      "Epoch: 18, Step: 6481, CombTr_Loss: 1.0, CombTr_Acc: 0.56, CVHum_Loss: 2.25, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6482, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 2.28, CVHum_Acc: 0.2 \n",
      "Epoch: 18, Step: 6483, CombTr_Loss: 1.15, CombTr_Acc: 0.5, CVHum_Loss: 2.14, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6484, CombTr_Loss: 1.33, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6485, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 1.9, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6486, CombTr_Loss: 0.94, CombTr_Acc: 0.72, CVHum_Loss: 1.96, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6487, CombTr_Loss: 0.97, CombTr_Acc: 0.68, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6488, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6489, CombTr_Loss: 1.07, CombTr_Acc: 0.5, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6490, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.1, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6491, CombTr_Loss: 1.25, CombTr_Acc: 0.58, CVHum_Loss: 2.57, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6492, CombTr_Loss: 1.18, CombTr_Acc: 0.6, CVHum_Loss: 1.78, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6493, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 2.13, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6494, CombTr_Loss: 1.23, CombTr_Acc: 0.46, CVHum_Loss: 2.37, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6495, CombTr_Loss: 1.09, CombTr_Acc: 0.64, CVHum_Loss: 1.71, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6496, CombTr_Loss: 0.99, CombTr_Acc: 0.66, CVHum_Loss: 2.33, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6497, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.56, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6498, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6499, CombTr_Loss: 1.0, CombTr_Acc: 0.66, CVHum_Loss: 1.6, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6500, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6501, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.77, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6502, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.73, CVHum_Acc: 0.42 \n",
      "Epoch: 18, Step: 6503, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.9, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6504, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 2.66, CVHum_Acc: 0.22 \n",
      "Epoch: 18, Step: 6505, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 1.92, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6506, CombTr_Loss: 1.25, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6507, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.02, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6508, CombTr_Loss: 0.69, CombTr_Acc: 0.74, CVHum_Loss: 1.69, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6509, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 1.96, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6510, CombTr_Loss: 1.28, CombTr_Acc: 0.54, CVHum_Loss: 3.08, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6511, CombTr_Loss: 1.09, CombTr_Acc: 0.64, CVHum_Loss: 1.65, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6512, CombTr_Loss: 0.93, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6513, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 1.61, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6514, CombTr_Loss: 0.97, CombTr_Acc: 0.56, CVHum_Loss: 1.74, CVHum_Acc: 0.44 \n",
      "Epoch: 18, Step: 6515, CombTr_Loss: 1.1, CombTr_Acc: 0.66, CVHum_Loss: 2.02, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6516, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 1.83, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6517, CombTr_Loss: 1.11, CombTr_Acc: 0.5, CVHum_Loss: 2.35, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6518, CombTr_Loss: 1.18, CombTr_Acc: 0.54, CVHum_Loss: 2.16, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6519, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.66, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6520, CombTr_Loss: 1.1, CombTr_Acc: 0.64, CVHum_Loss: 2.44, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6521, CombTr_Loss: 0.94, CombTr_Acc: 0.6, CVHum_Loss: 2.04, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6522, CombTr_Loss: 1.16, CombTr_Acc: 0.64, CVHum_Loss: 1.9, CVHum_Acc: 0.48 \n",
      "Epoch: 18, Step: 6523, CombTr_Loss: 0.98, CombTr_Acc: 0.68, CVHum_Loss: 1.7, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6524, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6525, CombTr_Loss: 0.88, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6526, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6527, CombTr_Loss: 1.18, CombTr_Acc: 0.56, CVHum_Loss: 2.11, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6528, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6529, CombTr_Loss: 1.23, CombTr_Acc: 0.6, CVHum_Loss: 2.73, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6530, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.14, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6531, CombTr_Loss: 0.83, CombTr_Acc: 0.68, CVHum_Loss: 1.52, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6532, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.23, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6533, CombTr_Loss: 1.01, CombTr_Acc: 0.54, CVHum_Loss: 1.86, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6534, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 2.19, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6535, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 2.03, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6536, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.07, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6537, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6538, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6539, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 2.39, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6540, CombTr_Loss: 1.29, CombTr_Acc: 0.44, CVHum_Loss: 2.31, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6541, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.94, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6542, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 1.71, CVHum_Acc: 0.38 \n",
      "Epoch: 18, Step: 6543, CombTr_Loss: 1.01, CombTr_Acc: 0.56, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6544, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 1.98, CVHum_Acc: 0.32 \n",
      "Epoch: 18, Step: 6545, CombTr_Loss: 1.23, CombTr_Acc: 0.44, CVHum_Loss: 2.11, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6546, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.36, CVHum_Acc: 0.3 \n",
      "Epoch: 18, Step: 6547, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 1.81, CVHum_Acc: 0.46 \n",
      "Epoch: 18, Step: 6548, CombTr_Loss: 0.9, CombTr_Acc: 0.62, CVHum_Loss: 2.16, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6549, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.24 \n",
      "Epoch: 18, Step: 6550, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 1.99, CVHum_Acc: 0.26 \n",
      "Epoch: 18, Step: 6551, CombTr_Loss: 1.17, CombTr_Acc: 0.58, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 18, Step: 6552, CombTr_Loss: 1.29, CombTr_Acc: 0.56, CVHum_Loss: 2.33, CVHum_Acc: 0.36 \n",
      "Epoch: 18, Step: 6553, CombTr_Loss: 1.09, CombTr_Acc: 0.5, CVHum_Loss: 1.88, CVHum_Acc: 0.4 \n",
      "Epoch: 18, Step: 6554, CombTr_Loss: 0.82, CombTr_Acc: 0.7, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 18, Step: 6555, CombTr_Loss: 1.08, CombTr_Acc: 0.56, CVHum_Loss: 1.88, CVHum_Acc: 0.26 \n",
      "Avg_CombTrain_Loss: 1.07, Avg_CombTrain_Acc: 0.59, Avg_CVHum_Loss: 2.04, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 18\n",
      "Epoch: 19, Step: 6556, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 1.99, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6557, CombTr_Loss: 1.04, CombTr_Acc: 0.58, CVHum_Loss: 2.81, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6558, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 1.93, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6559, CombTr_Loss: 0.83, CombTr_Acc: 0.7, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6560, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.16, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6561, CombTr_Loss: 0.97, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6562, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.46, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6563, CombTr_Loss: 0.8, CombTr_Acc: 0.68, CVHum_Loss: 2.39, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6564, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6565, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.36, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6566, CombTr_Loss: 0.87, CombTr_Acc: 0.72, CVHum_Loss: 2.5, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6567, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 2.37, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6568, CombTr_Loss: 1.24, CombTr_Acc: 0.42, CVHum_Loss: 1.79, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6569, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6570, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 1.85, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6571, CombTr_Loss: 1.07, CombTr_Acc: 0.58, CVHum_Loss: 1.95, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6572, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6573, CombTr_Loss: 1.22, CombTr_Acc: 0.54, CVHum_Loss: 2.59, CVHum_Acc: 0.18 \n",
      "Epoch: 19, Step: 6574, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6575, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 1.96, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6576, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.3, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6577, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.2, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6578, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 2.32, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6579, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 2.97, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6580, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.86, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6581, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6582, CombTr_Loss: 0.94, CombTr_Acc: 0.6, CVHum_Loss: 2.56, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6583, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.94, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6584, CombTr_Loss: 1.3, CombTr_Acc: 0.56, CVHum_Loss: 1.98, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6585, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 2.1, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6586, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.7, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6587, CombTr_Loss: 1.22, CombTr_Acc: 0.52, CVHum_Loss: 2.15, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6588, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6589, CombTr_Loss: 0.97, CombTr_Acc: 0.58, CVHum_Loss: 2.61, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6590, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6591, CombTr_Loss: 1.16, CombTr_Acc: 0.44, CVHum_Loss: 1.8, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6592, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.34, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6593, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6594, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.17, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6595, CombTr_Loss: 1.05, CombTr_Acc: 0.68, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6596, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 2.24, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6597, CombTr_Loss: 1.33, CombTr_Acc: 0.46, CVHum_Loss: 2.27, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6598, CombTr_Loss: 1.28, CombTr_Acc: 0.5, CVHum_Loss: 2.93, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6599, CombTr_Loss: 1.11, CombTr_Acc: 0.5, CVHum_Loss: 2.17, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6600, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.59, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6601, CombTr_Loss: 0.89, CombTr_Acc: 0.78, CVHum_Loss: 2.4, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6602, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6603, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6604, CombTr_Loss: 1.08, CombTr_Acc: 0.68, CVHum_Loss: 1.74, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6605, CombTr_Loss: 0.86, CombTr_Acc: 0.62, CVHum_Loss: 2.28, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6606, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6607, CombTr_Loss: 0.83, CombTr_Acc: 0.76, CVHum_Loss: 1.87, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6608, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.57, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6609, CombTr_Loss: 1.17, CombTr_Acc: 0.52, CVHum_Loss: 2.5, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6610, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 1.74, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6611, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 1.77, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6612, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6613, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 2.49, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6614, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 2.09, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6615, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 2.25, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6616, CombTr_Loss: 0.84, CombTr_Acc: 0.72, CVHum_Loss: 1.86, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6617, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 2.36, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6618, CombTr_Loss: 0.96, CombTr_Acc: 0.72, CVHum_Loss: 2.09, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6619, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6620, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 2.15, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6621, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.49, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6622, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 1.78, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6623, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6624, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6625, CombTr_Loss: 0.88, CombTr_Acc: 0.68, CVHum_Loss: 2.16, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6626, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.38, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6627, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.27, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6628, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.16, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6629, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 2.58, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6630, CombTr_Loss: 0.61, CombTr_Acc: 0.82, CVHum_Loss: 1.64, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6631, CombTr_Loss: 1.13, CombTr_Acc: 0.64, CVHum_Loss: 2.29, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6632, CombTr_Loss: 1.22, CombTr_Acc: 0.6, CVHum_Loss: 2.72, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6633, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.9, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6634, CombTr_Loss: 0.94, CombTr_Acc: 0.6, CVHum_Loss: 2.57, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6635, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 2.37, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6636, CombTr_Loss: 0.91, CombTr_Acc: 0.6, CVHum_Loss: 2.26, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6637, CombTr_Loss: 0.79, CombTr_Acc: 0.68, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6638, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6639, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6640, CombTr_Loss: 1.17, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6641, CombTr_Loss: 1.05, CombTr_Acc: 0.62, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6642, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 2.44, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6643, CombTr_Loss: 1.13, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6644, CombTr_Loss: 0.95, CombTr_Acc: 0.64, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6645, CombTr_Loss: 0.87, CombTr_Acc: 0.7, CVHum_Loss: 2.22, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6646, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 1.83, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6647, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.07, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6648, CombTr_Loss: 1.2, CombTr_Acc: 0.6, CVHum_Loss: 2.77, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6649, CombTr_Loss: 1.23, CombTr_Acc: 0.48, CVHum_Loss: 1.67, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6650, CombTr_Loss: 0.99, CombTr_Acc: 0.74, CVHum_Loss: 1.59, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6651, CombTr_Loss: 1.03, CombTr_Acc: 0.66, CVHum_Loss: 2.3, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6652, CombTr_Loss: 1.03, CombTr_Acc: 0.56, CVHum_Loss: 1.65, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6653, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6654, CombTr_Loss: 0.84, CombTr_Acc: 0.68, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6655, CombTr_Loss: 0.95, CombTr_Acc: 0.7, CVHum_Loss: 2.29, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6656, CombTr_Loss: 0.89, CombTr_Acc: 0.62, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6657, CombTr_Loss: 0.93, CombTr_Acc: 0.62, CVHum_Loss: 1.88, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6658, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 2.71, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6659, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.42, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6660, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6661, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.0, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6662, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.8, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6663, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 1.92, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6664, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.06, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6665, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.89, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6666, CombTr_Loss: 0.81, CombTr_Acc: 0.72, CVHum_Loss: 2.11, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6667, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 3.09, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6668, CombTr_Loss: 1.21, CombTr_Acc: 0.44, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6669, CombTr_Loss: 0.99, CombTr_Acc: 0.66, CVHum_Loss: 1.58, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6670, CombTr_Loss: 0.84, CombTr_Acc: 0.7, CVHum_Loss: 1.96, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6671, CombTr_Loss: 0.78, CombTr_Acc: 0.78, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6672, CombTr_Loss: 0.85, CombTr_Acc: 0.64, CVHum_Loss: 1.82, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6673, CombTr_Loss: 0.87, CombTr_Acc: 0.64, CVHum_Loss: 2.34, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6674, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.47, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6675, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.41, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6676, CombTr_Loss: 0.91, CombTr_Acc: 0.58, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6677, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 2.33, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6678, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 2.43, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6679, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 1.96, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6680, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 1.69, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6681, CombTr_Loss: 0.96, CombTr_Acc: 0.68, CVHum_Loss: 2.53, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6682, CombTr_Loss: 0.9, CombTr_Acc: 0.62, CVHum_Loss: 2.5, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6683, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6684, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.6, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6685, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 1.7, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6686, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.01, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6687, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 2.21, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6688, CombTr_Loss: 0.95, CombTr_Acc: 0.68, CVHum_Loss: 2.45, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6689, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6690, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.04, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6691, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 2.22, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6692, CombTr_Loss: 0.93, CombTr_Acc: 0.62, CVHum_Loss: 1.76, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6693, CombTr_Loss: 0.91, CombTr_Acc: 0.68, CVHum_Loss: 2.07, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6694, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.28, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6695, CombTr_Loss: 0.85, CombTr_Acc: 0.68, CVHum_Loss: 2.27, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6696, CombTr_Loss: 0.88, CombTr_Acc: 0.7, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6697, CombTr_Loss: 0.83, CombTr_Acc: 0.74, CVHum_Loss: 2.29, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6698, CombTr_Loss: 1.1, CombTr_Acc: 0.46, CVHum_Loss: 2.6, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6699, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 2.09, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6700, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.25, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6701, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.15, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6702, CombTr_Loss: 0.93, CombTr_Acc: 0.6, CVHum_Loss: 2.05, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6703, CombTr_Loss: 0.99, CombTr_Acc: 0.64, CVHum_Loss: 2.3, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6704, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 2.16, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6705, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 2.42, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6706, CombTr_Loss: 1.14, CombTr_Acc: 0.5, CVHum_Loss: 1.8, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6707, CombTr_Loss: 1.14, CombTr_Acc: 0.54, CVHum_Loss: 2.5, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6708, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6709, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6710, CombTr_Loss: 0.89, CombTr_Acc: 0.64, CVHum_Loss: 1.82, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6711, CombTr_Loss: 0.84, CombTr_Acc: 0.74, CVHum_Loss: 2.56, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6712, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.87, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6713, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6714, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 2.12, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6715, CombTr_Loss: 0.9, CombTr_Acc: 0.68, CVHum_Loss: 1.7, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6716, CombTr_Loss: 0.86, CombTr_Acc: 0.74, CVHum_Loss: 1.94, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6717, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 2.35, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6718, CombTr_Loss: 0.91, CombTr_Acc: 0.62, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6719, CombTr_Loss: 0.95, CombTr_Acc: 0.72, CVHum_Loss: 1.85, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6720, CombTr_Loss: 0.95, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6721, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 1.57, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6722, CombTr_Loss: 1.11, CombTr_Acc: 0.48, CVHum_Loss: 2.13, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6723, CombTr_Loss: 0.97, CombTr_Acc: 0.58, CVHum_Loss: 1.75, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6724, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.07, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6725, CombTr_Loss: 1.12, CombTr_Acc: 0.62, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6726, CombTr_Loss: 0.8, CombTr_Acc: 0.66, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6727, CombTr_Loss: 1.09, CombTr_Acc: 0.6, CVHum_Loss: 2.58, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6728, CombTr_Loss: 1.06, CombTr_Acc: 0.62, CVHum_Loss: 2.52, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6729, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6730, CombTr_Loss: 1.07, CombTr_Acc: 0.64, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6731, CombTr_Loss: 1.22, CombTr_Acc: 0.56, CVHum_Loss: 1.7, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6732, CombTr_Loss: 0.87, CombTr_Acc: 0.58, CVHum_Loss: 1.99, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6733, CombTr_Loss: 0.8, CombTr_Acc: 0.72, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6734, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.95, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6735, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.33, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6736, CombTr_Loss: 0.95, CombTr_Acc: 0.64, CVHum_Loss: 2.68, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6737, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.92, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6738, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6739, CombTr_Loss: 0.75, CombTr_Acc: 0.78, CVHum_Loss: 2.14, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6740, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 1.98, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6741, CombTr_Loss: 0.81, CombTr_Acc: 0.74, CVHum_Loss: 1.87, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6742, CombTr_Loss: 0.93, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6743, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 2.05, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6744, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 1.95, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6745, CombTr_Loss: 1.02, CombTr_Acc: 0.54, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6746, CombTr_Loss: 0.88, CombTr_Acc: 0.64, CVHum_Loss: 2.21, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6747, CombTr_Loss: 1.23, CombTr_Acc: 0.46, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6748, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 1.61, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6749, CombTr_Loss: 0.89, CombTr_Acc: 0.78, CVHum_Loss: 1.59, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6750, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6751, CombTr_Loss: 1.06, CombTr_Acc: 0.74, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6752, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.08, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6753, CombTr_Loss: 0.91, CombTr_Acc: 0.62, CVHum_Loss: 2.07, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6754, CombTr_Loss: 0.84, CombTr_Acc: 0.66, CVHum_Loss: 1.71, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6755, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 1.7, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6756, CombTr_Loss: 0.96, CombTr_Acc: 0.66, CVHum_Loss: 1.91, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6757, CombTr_Loss: 1.17, CombTr_Acc: 0.56, CVHum_Loss: 2.02, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6758, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 2.05, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6759, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.26, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6760, CombTr_Loss: 0.97, CombTr_Acc: 0.6, CVHum_Loss: 1.62, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6761, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 1.95, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6762, CombTr_Loss: 0.84, CombTr_Acc: 0.66, CVHum_Loss: 1.68, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6763, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.07, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6764, CombTr_Loss: 0.98, CombTr_Acc: 0.58, CVHum_Loss: 2.23, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6765, CombTr_Loss: 1.01, CombTr_Acc: 0.58, CVHum_Loss: 1.97, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6766, CombTr_Loss: 1.07, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6767, CombTr_Loss: 1.27, CombTr_Acc: 0.46, CVHum_Loss: 2.53, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6768, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6769, CombTr_Loss: 1.0, CombTr_Acc: 0.54, CVHum_Loss: 2.39, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6770, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.5, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6771, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6772, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 2.42, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6773, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 2.63, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6774, CombTr_Loss: 0.87, CombTr_Acc: 0.66, CVHum_Loss: 2.37, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6775, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 1.44, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6776, CombTr_Loss: 0.85, CombTr_Acc: 0.6, CVHum_Loss: 2.15, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6777, CombTr_Loss: 1.36, CombTr_Acc: 0.5, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6778, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.72, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6779, CombTr_Loss: 1.05, CombTr_Acc: 0.64, CVHum_Loss: 2.03, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6780, CombTr_Loss: 1.29, CombTr_Acc: 0.6, CVHum_Loss: 2.28, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6781, CombTr_Loss: 0.94, CombTr_Acc: 0.6, CVHum_Loss: 1.83, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6782, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 1.88, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6783, CombTr_Loss: 1.04, CombTr_Acc: 0.66, CVHum_Loss: 1.84, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6784, CombTr_Loss: 1.04, CombTr_Acc: 0.66, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6785, CombTr_Loss: 1.18, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6786, CombTr_Loss: 0.73, CombTr_Acc: 0.76, CVHum_Loss: 2.74, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6787, CombTr_Loss: 1.31, CombTr_Acc: 0.46, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6788, CombTr_Loss: 1.14, CombTr_Acc: 0.5, CVHum_Loss: 1.85, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6789, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6790, CombTr_Loss: 1.07, CombTr_Acc: 0.52, CVHum_Loss: 1.49, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6791, CombTr_Loss: 0.95, CombTr_Acc: 0.6, CVHum_Loss: 1.99, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6792, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.72, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6793, CombTr_Loss: 0.84, CombTr_Acc: 0.7, CVHum_Loss: 2.37, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6794, CombTr_Loss: 1.14, CombTr_Acc: 0.48, CVHum_Loss: 2.05, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6795, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 1.58, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6796, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.4, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6797, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.19, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6798, CombTr_Loss: 0.95, CombTr_Acc: 0.58, CVHum_Loss: 2.12, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6799, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 1.9, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6800, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 1.58, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6801, CombTr_Loss: 1.09, CombTr_Acc: 0.62, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6802, CombTr_Loss: 1.01, CombTr_Acc: 0.56, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6803, CombTr_Loss: 0.93, CombTr_Acc: 0.64, CVHum_Loss: 2.22, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6804, CombTr_Loss: 0.89, CombTr_Acc: 0.68, CVHum_Loss: 2.36, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6805, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 2.8, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6806, CombTr_Loss: 1.1, CombTr_Acc: 0.64, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6807, CombTr_Loss: 1.11, CombTr_Acc: 0.5, CVHum_Loss: 1.64, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6808, CombTr_Loss: 0.82, CombTr_Acc: 0.7, CVHum_Loss: 2.39, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6809, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.89, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6810, CombTr_Loss: 1.17, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6811, CombTr_Loss: 1.03, CombTr_Acc: 0.6, CVHum_Loss: 1.82, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6812, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6813, CombTr_Loss: 0.87, CombTr_Acc: 0.74, CVHum_Loss: 2.13, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6814, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6815, CombTr_Loss: 1.19, CombTr_Acc: 0.56, CVHum_Loss: 2.04, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6816, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.36, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6817, CombTr_Loss: 1.09, CombTr_Acc: 0.7, CVHum_Loss: 1.93, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6818, CombTr_Loss: 0.83, CombTr_Acc: 0.68, CVHum_Loss: 1.59, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6819, CombTr_Loss: 1.29, CombTr_Acc: 0.52, CVHum_Loss: 2.47, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6820, CombTr_Loss: 0.75, CombTr_Acc: 0.72, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6821, CombTr_Loss: 0.9, CombTr_Acc: 0.62, CVHum_Loss: 2.33, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6822, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 2.27, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6823, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6824, CombTr_Loss: 0.85, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6825, CombTr_Loss: 0.91, CombTr_Acc: 0.6, CVHum_Loss: 2.27, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6826, CombTr_Loss: 0.86, CombTr_Acc: 0.64, CVHum_Loss: 2.18, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6827, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.15, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6828, CombTr_Loss: 1.1, CombTr_Acc: 0.5, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6829, CombTr_Loss: 1.28, CombTr_Acc: 0.56, CVHum_Loss: 1.72, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6830, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 1.78, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6831, CombTr_Loss: 0.95, CombTr_Acc: 0.58, CVHum_Loss: 1.88, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6832, CombTr_Loss: 0.9, CombTr_Acc: 0.64, CVHum_Loss: 1.91, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6833, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 2.34, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6834, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6835, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 2.15, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6836, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 2.82, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6837, CombTr_Loss: 1.09, CombTr_Acc: 0.58, CVHum_Loss: 1.7, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6838, CombTr_Loss: 1.06, CombTr_Acc: 0.64, CVHum_Loss: 2.2, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6839, CombTr_Loss: 1.18, CombTr_Acc: 0.52, CVHum_Loss: 2.25, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6840, CombTr_Loss: 0.82, CombTr_Acc: 0.74, CVHum_Loss: 1.9, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6841, CombTr_Loss: 0.91, CombTr_Acc: 0.64, CVHum_Loss: 2.24, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6842, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 2.42, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6843, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6844, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 1.76, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6845, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 1.91, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6846, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 1.74, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6847, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 1.81, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6848, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6849, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.78, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6850, CombTr_Loss: 1.13, CombTr_Acc: 0.62, CVHum_Loss: 1.97, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6851, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 1.75, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6852, CombTr_Loss: 0.86, CombTr_Acc: 0.72, CVHum_Loss: 2.05, CVHum_Acc: 0.26 \n",
      "Epoch: 19, Step: 6853, CombTr_Loss: 0.81, CombTr_Acc: 0.68, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6854, CombTr_Loss: 1.07, CombTr_Acc: 0.5, CVHum_Loss: 1.79, CVHum_Acc: 0.44 \n",
      "Epoch: 19, Step: 6855, CombTr_Loss: 1.29, CombTr_Acc: 0.5, CVHum_Loss: 2.79, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6856, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 1.78, CVHum_Acc: 0.5 \n",
      "Epoch: 19, Step: 6857, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6858, CombTr_Loss: 1.22, CombTr_Acc: 0.62, CVHum_Loss: 1.51, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6859, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6860, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.9, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6861, CombTr_Loss: 0.96, CombTr_Acc: 0.7, CVHum_Loss: 1.78, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6862, CombTr_Loss: 1.13, CombTr_Acc: 0.56, CVHum_Loss: 2.46, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6863, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.03, CVHum_Acc: 0.2 \n",
      "Epoch: 19, Step: 6864, CombTr_Loss: 1.2, CombTr_Acc: 0.42, CVHum_Loss: 1.63, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6865, CombTr_Loss: 1.26, CombTr_Acc: 0.52, CVHum_Loss: 2.24, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6866, CombTr_Loss: 0.87, CombTr_Acc: 0.72, CVHum_Loss: 2.28, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6867, CombTr_Loss: 1.0, CombTr_Acc: 0.66, CVHum_Loss: 1.91, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6868, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 1.8, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6869, CombTr_Loss: 1.13, CombTr_Acc: 0.6, CVHum_Loss: 1.81, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6870, CombTr_Loss: 0.98, CombTr_Acc: 0.64, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6871, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 1.97, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6872, CombTr_Loss: 1.04, CombTr_Acc: 0.68, CVHum_Loss: 2.04, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6873, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.09, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6874, CombTr_Loss: 1.19, CombTr_Acc: 0.62, CVHum_Loss: 2.75, CVHum_Acc: 0.24 \n",
      "Epoch: 19, Step: 6875, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 1.89, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6876, CombTr_Loss: 1.02, CombTr_Acc: 0.58, CVHum_Loss: 1.62, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6877, CombTr_Loss: 1.15, CombTr_Acc: 0.48, CVHum_Loss: 2.41, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6878, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.77, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6879, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.24, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6880, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 1.93, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6881, CombTr_Loss: 0.92, CombTr_Acc: 0.58, CVHum_Loss: 2.27, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6882, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 2.15, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6883, CombTr_Loss: 1.31, CombTr_Acc: 0.56, CVHum_Loss: 1.84, CVHum_Acc: 0.4 \n",
      "Epoch: 19, Step: 6884, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 2.74, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6885, CombTr_Loss: 1.34, CombTr_Acc: 0.46, CVHum_Loss: 2.49, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6886, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.2, CVHum_Acc: 0.42 \n",
      "Epoch: 19, Step: 6887, CombTr_Loss: 0.77, CombTr_Acc: 0.74, CVHum_Loss: 1.93, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6888, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.44, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6889, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 2.2, CVHum_Acc: 0.34 \n",
      "Epoch: 19, Step: 6890, CombTr_Loss: 1.11, CombTr_Acc: 0.54, CVHum_Loss: 2.19, CVHum_Acc: 0.32 \n",
      "Epoch: 19, Step: 6891, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.43, CVHum_Acc: 0.36 \n",
      "Epoch: 19, Step: 6892, CombTr_Loss: 0.88, CombTr_Acc: 0.62, CVHum_Loss: 1.85, CVHum_Acc: 0.48 \n",
      "Epoch: 19, Step: 6893, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 2.21, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6894, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 2.35, CVHum_Acc: 0.22 \n",
      "Epoch: 19, Step: 6895, CombTr_Loss: 1.08, CombTr_Acc: 0.6, CVHum_Loss: 2.2, CVHum_Acc: 0.18 \n",
      "Epoch: 19, Step: 6896, CombTr_Loss: 0.93, CombTr_Acc: 0.64, CVHum_Loss: 2.42, CVHum_Acc: 0.28 \n",
      "Epoch: 19, Step: 6897, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.69, CVHum_Acc: 0.3 \n",
      "Epoch: 19, Step: 6898, CombTr_Loss: 1.07, CombTr_Acc: 0.48, CVHum_Loss: 1.93, CVHum_Acc: 0.46 \n",
      "Epoch: 19, Step: 6899, CombTr_Loss: 0.8, CombTr_Acc: 0.72, CVHum_Loss: 2.04, CVHum_Acc: 0.38 \n",
      "Epoch: 19, Step: 6900, CombTr_Loss: 1.11, CombTr_Acc: 0.52, CVHum_Loss: 1.88, CVHum_Acc: 0.32 \n",
      "Avg_CombTrain_Loss: 1.02, Avg_CombTrain_Acc: 0.61, Avg_CVHum_Loss: 2.08, Avg_CVHum_Acc: 0.34 \n",
      "Model and weights saved at epoch 19\n",
      "Epoch: 20, Step: 6901, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.14, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6902, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.7, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 6903, CombTr_Loss: 0.79, CombTr_Acc: 0.62, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6904, CombTr_Loss: 0.75, CombTr_Acc: 0.7, CVHum_Loss: 2.26, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 6905, CombTr_Loss: 0.92, CombTr_Acc: 0.54, CVHum_Loss: 2.26, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6906, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6907, CombTr_Loss: 1.0, CombTr_Acc: 0.56, CVHum_Loss: 2.39, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6908, CombTr_Loss: 0.81, CombTr_Acc: 0.68, CVHum_Loss: 2.56, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6909, CombTr_Loss: 0.89, CombTr_Acc: 0.64, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6910, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 2.38, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 6911, CombTr_Loss: 0.63, CombTr_Acc: 0.76, CVHum_Loss: 2.54, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6912, CombTr_Loss: 0.91, CombTr_Acc: 0.66, CVHum_Loss: 2.25, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6913, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 1.65, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 6914, CombTr_Loss: 1.02, CombTr_Acc: 0.66, CVHum_Loss: 2.02, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6915, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 2.05, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 6916, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.02, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6917, CombTr_Loss: 0.83, CombTr_Acc: 0.56, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 6918, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.63, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6919, CombTr_Loss: 0.87, CombTr_Acc: 0.64, CVHum_Loss: 2.09, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6920, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 1.99, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6921, CombTr_Loss: 0.92, CombTr_Acc: 0.68, CVHum_Loss: 2.17, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 6922, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.92, CVHum_Acc: 0.48 \n",
      "Epoch: 20, Step: 6923, CombTr_Loss: 1.15, CombTr_Acc: 0.52, CVHum_Loss: 2.44, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 6924, CombTr_Loss: 1.09, CombTr_Acc: 0.48, CVHum_Loss: 3.17, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 6925, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.05, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 6926, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 1.9, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6927, CombTr_Loss: 0.92, CombTr_Acc: 0.66, CVHum_Loss: 2.48, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6928, CombTr_Loss: 0.95, CombTr_Acc: 0.62, CVHum_Loss: 1.94, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6929, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.87, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6930, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.33, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6931, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 2.55, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6932, CombTr_Loss: 0.86, CombTr_Acc: 0.68, CVHum_Loss: 2.17, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6933, CombTr_Loss: 1.27, CombTr_Acc: 0.5, CVHum_Loss: 2.03, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6934, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 2.65, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6935, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 2.17, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6936, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6937, CombTr_Loss: 0.81, CombTr_Acc: 0.62, CVHum_Loss: 2.45, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 6938, CombTr_Loss: 0.97, CombTr_Acc: 0.7, CVHum_Loss: 2.27, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6939, CombTr_Loss: 0.99, CombTr_Acc: 0.54, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6940, CombTr_Loss: 1.15, CombTr_Acc: 0.54, CVHum_Loss: 2.29, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 6941, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.18, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6942, CombTr_Loss: 1.29, CombTr_Acc: 0.44, CVHum_Loss: 2.27, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6943, CombTr_Loss: 1.21, CombTr_Acc: 0.52, CVHum_Loss: 3.14, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 6944, CombTr_Loss: 1.1, CombTr_Acc: 0.58, CVHum_Loss: 2.14, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6945, CombTr_Loss: 0.91, CombTr_Acc: 0.68, CVHum_Loss: 1.65, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6946, CombTr_Loss: 0.88, CombTr_Acc: 0.7, CVHum_Loss: 2.47, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 6947, CombTr_Loss: 1.21, CombTr_Acc: 0.5, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6948, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 1.79, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 6949, CombTr_Loss: 1.04, CombTr_Acc: 0.68, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6950, CombTr_Loss: 0.73, CombTr_Acc: 0.68, CVHum_Loss: 2.07, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6951, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.13, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6952, CombTr_Loss: 0.82, CombTr_Acc: 0.74, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6953, CombTr_Loss: 1.01, CombTr_Acc: 0.62, CVHum_Loss: 2.47, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6954, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.55, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6955, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 6956, CombTr_Loss: 0.81, CombTr_Acc: 0.76, CVHum_Loss: 1.62, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 6957, CombTr_Loss: 0.87, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6958, CombTr_Loss: 0.97, CombTr_Acc: 0.6, CVHum_Loss: 2.21, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6959, CombTr_Loss: 0.96, CombTr_Acc: 0.68, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 6960, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 2.32, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6961, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.01, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6962, CombTr_Loss: 1.21, CombTr_Acc: 0.56, CVHum_Loss: 2.4, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6963, CombTr_Loss: 1.2, CombTr_Acc: 0.5, CVHum_Loss: 2.24, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 6964, CombTr_Loss: 0.98, CombTr_Acc: 0.66, CVHum_Loss: 2.16, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 6965, CombTr_Loss: 0.95, CombTr_Acc: 0.7, CVHum_Loss: 2.44, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6966, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 2.48, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6967, CombTr_Loss: 0.89, CombTr_Acc: 0.58, CVHum_Loss: 1.69, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 6968, CombTr_Loss: 0.92, CombTr_Acc: 0.68, CVHum_Loss: 2.08, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6969, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 1.86, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6970, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 2.12, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6971, CombTr_Loss: 1.05, CombTr_Acc: 0.58, CVHum_Loss: 2.35, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6972, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.93, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6973, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 2.06, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 6974, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.42, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6975, CombTr_Loss: 0.8, CombTr_Acc: 0.66, CVHum_Loss: 1.61, CVHum_Acc: 0.5 \n",
      "Epoch: 20, Step: 6976, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.46, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6977, CombTr_Loss: 1.32, CombTr_Acc: 0.52, CVHum_Loss: 2.23, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 6978, CombTr_Loss: 0.93, CombTr_Acc: 0.58, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6979, CombTr_Loss: 0.75, CombTr_Acc: 0.72, CVHum_Loss: 2.42, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6980, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.04, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6981, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 2.54, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 6982, CombTr_Loss: 0.86, CombTr_Acc: 0.68, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 6983, CombTr_Loss: 0.88, CombTr_Acc: 0.62, CVHum_Loss: 2.19, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6984, CombTr_Loss: 0.98, CombTr_Acc: 0.54, CVHum_Loss: 1.91, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6985, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 2.07, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 6986, CombTr_Loss: 1.07, CombTr_Acc: 0.54, CVHum_Loss: 1.77, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6987, CombTr_Loss: 0.76, CombTr_Acc: 0.66, CVHum_Loss: 2.61, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 6988, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.78, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 6989, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6990, CombTr_Loss: 0.83, CombTr_Acc: 0.76, CVHum_Loss: 2.38, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 6991, CombTr_Loss: 0.94, CombTr_Acc: 0.6, CVHum_Loss: 1.93, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 6992, CombTr_Loss: 0.87, CombTr_Acc: 0.72, CVHum_Loss: 2.17, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 6993, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.87, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 6994, CombTr_Loss: 1.31, CombTr_Acc: 0.52, CVHum_Loss: 1.64, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 6995, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 1.72, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 6996, CombTr_Loss: 0.85, CombTr_Acc: 0.68, CVHum_Loss: 2.34, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 6997, CombTr_Loss: 0.95, CombTr_Acc: 0.6, CVHum_Loss: 1.63, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 6998, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.37, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 6999, CombTr_Loss: 0.72, CombTr_Acc: 0.74, CVHum_Loss: 2.45, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7000, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 2.35, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7001, CombTr_Loss: 0.82, CombTr_Acc: 0.68, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7002, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.18, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7003, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 2.92, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7004, CombTr_Loss: 1.11, CombTr_Acc: 0.58, CVHum_Loss: 2.42, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7005, CombTr_Loss: 0.95, CombTr_Acc: 0.7, CVHum_Loss: 1.87, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7006, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 2.19, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7007, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 1.76, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7008, CombTr_Loss: 1.12, CombTr_Acc: 0.64, CVHum_Loss: 1.94, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7009, CombTr_Loss: 1.06, CombTr_Acc: 0.58, CVHum_Loss: 2.23, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7010, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.05, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7011, CombTr_Loss: 0.86, CombTr_Acc: 0.7, CVHum_Loss: 2.31, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7012, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 3.35, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7013, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 1.85, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7014, CombTr_Loss: 1.04, CombTr_Acc: 0.56, CVHum_Loss: 1.69, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7015, CombTr_Loss: 0.85, CombTr_Acc: 0.72, CVHum_Loss: 2.38, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7016, CombTr_Loss: 0.78, CombTr_Acc: 0.82, CVHum_Loss: 1.98, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7017, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7018, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.58, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7019, CombTr_Loss: 1.22, CombTr_Acc: 0.5, CVHum_Loss: 2.36, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7020, CombTr_Loss: 0.87, CombTr_Acc: 0.74, CVHum_Loss: 2.32, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7021, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 1.86, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7022, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.57, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7023, CombTr_Loss: 1.08, CombTr_Acc: 0.64, CVHum_Loss: 2.76, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7024, CombTr_Loss: 1.2, CombTr_Acc: 0.52, CVHum_Loss: 2.12, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7025, CombTr_Loss: 1.1, CombTr_Acc: 0.56, CVHum_Loss: 1.74, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7026, CombTr_Loss: 1.12, CombTr_Acc: 0.6, CVHum_Loss: 2.91, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7027, CombTr_Loss: 1.14, CombTr_Acc: 0.48, CVHum_Loss: 2.57, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7028, CombTr_Loss: 0.91, CombTr_Acc: 0.6, CVHum_Loss: 2.33, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7029, CombTr_Loss: 0.89, CombTr_Acc: 0.64, CVHum_Loss: 2.54, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7030, CombTr_Loss: 0.94, CombTr_Acc: 0.58, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7031, CombTr_Loss: 0.88, CombTr_Acc: 0.76, CVHum_Loss: 2.08, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7032, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 2.25, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7033, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.33, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7034, CombTr_Loss: 1.1, CombTr_Acc: 0.52, CVHum_Loss: 2.53, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7035, CombTr_Loss: 1.0, CombTr_Acc: 0.6, CVHum_Loss: 2.0, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7036, CombTr_Loss: 0.86, CombTr_Acc: 0.68, CVHum_Loss: 2.16, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7037, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 2.0, CVHum_Acc: 0.48 \n",
      "Epoch: 20, Step: 7038, CombTr_Loss: 0.9, CombTr_Acc: 0.74, CVHum_Loss: 2.11, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7039, CombTr_Loss: 1.01, CombTr_Acc: 0.7, CVHum_Loss: 2.46, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7040, CombTr_Loss: 0.85, CombTr_Acc: 0.66, CVHum_Loss: 2.22, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7041, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.21, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7042, CombTr_Loss: 0.86, CombTr_Acc: 0.66, CVHum_Loss: 2.53, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7043, CombTr_Loss: 0.92, CombTr_Acc: 0.68, CVHum_Loss: 2.77, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7044, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7045, CombTr_Loss: 1.04, CombTr_Acc: 0.6, CVHum_Loss: 2.41, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7046, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.34, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7047, CombTr_Loss: 0.83, CombTr_Acc: 0.68, CVHum_Loss: 2.4, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7048, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.21, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7049, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.29, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7050, CombTr_Loss: 0.94, CombTr_Acc: 0.68, CVHum_Loss: 2.68, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7051, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.93, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7052, CombTr_Loss: 0.98, CombTr_Acc: 0.58, CVHum_Loss: 2.44, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7053, CombTr_Loss: 1.07, CombTr_Acc: 0.6, CVHum_Loss: 2.13, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7054, CombTr_Loss: 1.01, CombTr_Acc: 0.6, CVHum_Loss: 1.83, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7055, CombTr_Loss: 0.92, CombTr_Acc: 0.6, CVHum_Loss: 1.88, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7056, CombTr_Loss: 0.89, CombTr_Acc: 0.74, CVHum_Loss: 2.85, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7057, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.16, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7058, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 2.07, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7059, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 2.35, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7060, CombTr_Loss: 0.89, CombTr_Acc: 0.68, CVHum_Loss: 1.65, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7061, CombTr_Loss: 0.74, CombTr_Acc: 0.74, CVHum_Loss: 2.44, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7062, CombTr_Loss: 0.99, CombTr_Acc: 0.68, CVHum_Loss: 2.45, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7063, CombTr_Loss: 0.97, CombTr_Acc: 0.62, CVHum_Loss: 2.05, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7064, CombTr_Loss: 1.01, CombTr_Acc: 0.64, CVHum_Loss: 1.87, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7065, CombTr_Loss: 1.1, CombTr_Acc: 0.52, CVHum_Loss: 2.2, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7066, CombTr_Loss: 1.05, CombTr_Acc: 0.52, CVHum_Loss: 1.43, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7067, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.25, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7068, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 1.96, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7069, CombTr_Loss: 1.02, CombTr_Acc: 0.66, CVHum_Loss: 2.12, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7070, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 2.08, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7071, CombTr_Loss: 0.9, CombTr_Acc: 0.64, CVHum_Loss: 1.67, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7072, CombTr_Loss: 0.94, CombTr_Acc: 0.64, CVHum_Loss: 2.37, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7073, CombTr_Loss: 1.02, CombTr_Acc: 0.56, CVHum_Loss: 2.62, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7074, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.16, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7075, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 1.87, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7076, CombTr_Loss: 1.29, CombTr_Acc: 0.54, CVHum_Loss: 1.78, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7077, CombTr_Loss: 0.82, CombTr_Acc: 0.72, CVHum_Loss: 2.03, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7078, CombTr_Loss: 0.91, CombTr_Acc: 0.72, CVHum_Loss: 1.75, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7079, CombTr_Loss: 1.01, CombTr_Acc: 0.66, CVHum_Loss: 2.15, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7080, CombTr_Loss: 1.1, CombTr_Acc: 0.6, CVHum_Loss: 2.21, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7081, CombTr_Loss: 0.96, CombTr_Acc: 0.58, CVHum_Loss: 2.81, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7082, CombTr_Loss: 0.96, CombTr_Acc: 0.7, CVHum_Loss: 1.92, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7083, CombTr_Loss: 1.23, CombTr_Acc: 0.46, CVHum_Loss: 1.45, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7084, CombTr_Loss: 0.76, CombTr_Acc: 0.7, CVHum_Loss: 2.42, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7085, CombTr_Loss: 1.06, CombTr_Acc: 0.6, CVHum_Loss: 2.25, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7086, CombTr_Loss: 0.86, CombTr_Acc: 0.72, CVHum_Loss: 2.09, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7087, CombTr_Loss: 0.98, CombTr_Acc: 0.56, CVHum_Loss: 1.81, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7088, CombTr_Loss: 0.81, CombTr_Acc: 0.76, CVHum_Loss: 2.19, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7089, CombTr_Loss: 0.9, CombTr_Acc: 0.7, CVHum_Loss: 2.09, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7090, CombTr_Loss: 0.93, CombTr_Acc: 0.66, CVHum_Loss: 1.87, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7091, CombTr_Loss: 1.11, CombTr_Acc: 0.6, CVHum_Loss: 2.53, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7092, CombTr_Loss: 1.16, CombTr_Acc: 0.56, CVHum_Loss: 2.51, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7093, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 1.55, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7094, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 1.66, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7095, CombTr_Loss: 1.07, CombTr_Acc: 0.62, CVHum_Loss: 2.43, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7096, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.01, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7097, CombTr_Loss: 1.2, CombTr_Acc: 0.54, CVHum_Loss: 2.38, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7098, CombTr_Loss: 0.92, CombTr_Acc: 0.68, CVHum_Loss: 2.25, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7099, CombTr_Loss: 0.92, CombTr_Acc: 0.7, CVHum_Loss: 1.87, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7100, CombTr_Loss: 1.05, CombTr_Acc: 0.6, CVHum_Loss: 2.03, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7101, CombTr_Loss: 1.09, CombTr_Acc: 0.54, CVHum_Loss: 2.2, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7102, CombTr_Loss: 1.25, CombTr_Acc: 0.52, CVHum_Loss: 1.93, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7103, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 2.24, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7104, CombTr_Loss: 1.03, CombTr_Acc: 0.62, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7105, CombTr_Loss: 1.11, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7106, CombTr_Loss: 1.31, CombTr_Acc: 0.64, CVHum_Loss: 1.99, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7107, CombTr_Loss: 0.78, CombTr_Acc: 0.72, CVHum_Loss: 1.75, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7108, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 2.04, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7109, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.06, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7110, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 1.99, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7111, CombTr_Loss: 0.95, CombTr_Acc: 0.66, CVHum_Loss: 2.11, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7112, CombTr_Loss: 1.09, CombTr_Acc: 0.56, CVHum_Loss: 2.52, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7113, CombTr_Loss: 1.02, CombTr_Acc: 0.68, CVHum_Loss: 1.89, CVHum_Acc: 0.52 \n",
      "Epoch: 20, Step: 7114, CombTr_Loss: 1.08, CombTr_Acc: 0.48, CVHum_Loss: 2.34, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7115, CombTr_Loss: 1.05, CombTr_Acc: 0.56, CVHum_Loss: 2.58, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7116, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 1.85, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7117, CombTr_Loss: 1.3, CombTr_Acc: 0.54, CVHum_Loss: 2.33, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7118, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 2.34, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7119, CombTr_Loss: 0.83, CombTr_Acc: 0.7, CVHum_Loss: 2.01, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7120, CombTr_Loss: 0.89, CombTr_Acc: 0.68, CVHum_Loss: 1.52, CVHum_Acc: 0.5 \n",
      "Epoch: 20, Step: 7121, CombTr_Loss: 0.78, CombTr_Acc: 0.66, CVHum_Loss: 1.97, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7122, CombTr_Loss: 1.34, CombTr_Acc: 0.44, CVHum_Loss: 1.71, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7123, CombTr_Loss: 1.03, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7124, CombTr_Loss: 0.95, CombTr_Acc: 0.7, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7125, CombTr_Loss: 1.23, CombTr_Acc: 0.56, CVHum_Loss: 2.43, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7126, CombTr_Loss: 0.89, CombTr_Acc: 0.7, CVHum_Loss: 1.83, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7127, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7128, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 2.0, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7129, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 1.79, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7130, CombTr_Loss: 1.25, CombTr_Acc: 0.48, CVHum_Loss: 2.26, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7131, CombTr_Loss: 0.75, CombTr_Acc: 0.78, CVHum_Loss: 2.84, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7132, CombTr_Loss: 1.37, CombTr_Acc: 0.48, CVHum_Loss: 1.8, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7133, CombTr_Loss: 1.24, CombTr_Acc: 0.52, CVHum_Loss: 1.79, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7134, CombTr_Loss: 1.04, CombTr_Acc: 0.54, CVHum_Loss: 1.79, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7135, CombTr_Loss: 1.02, CombTr_Acc: 0.6, CVHum_Loss: 1.4, CVHum_Acc: 0.5 \n",
      "Epoch: 20, Step: 7136, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 2.03, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7137, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7138, CombTr_Loss: 0.83, CombTr_Acc: 0.7, CVHum_Loss: 2.46, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7139, CombTr_Loss: 1.08, CombTr_Acc: 0.62, CVHum_Loss: 2.04, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 7140, CombTr_Loss: 1.1, CombTr_Acc: 0.54, CVHum_Loss: 1.63, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7141, CombTr_Loss: 0.88, CombTr_Acc: 0.66, CVHum_Loss: 2.33, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7142, CombTr_Loss: 1.0, CombTr_Acc: 0.64, CVHum_Loss: 2.26, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7143, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.42, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7144, CombTr_Loss: 0.85, CombTr_Acc: 0.66, CVHum_Loss: 2.11, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7145, CombTr_Loss: 1.14, CombTr_Acc: 0.6, CVHum_Loss: 1.67, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7146, CombTr_Loss: 1.23, CombTr_Acc: 0.54, CVHum_Loss: 1.95, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7147, CombTr_Loss: 0.92, CombTr_Acc: 0.64, CVHum_Loss: 1.88, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7148, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 2.18, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7149, CombTr_Loss: 0.79, CombTr_Acc: 0.72, CVHum_Loss: 2.3, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7150, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 3.03, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7151, CombTr_Loss: 1.01, CombTr_Acc: 0.66, CVHum_Loss: 2.53, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7152, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 1.67, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7153, CombTr_Loss: 0.89, CombTr_Acc: 0.66, CVHum_Loss: 2.53, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7154, CombTr_Loss: 1.15, CombTr_Acc: 0.6, CVHum_Loss: 1.72, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7155, CombTr_Loss: 1.12, CombTr_Acc: 0.56, CVHum_Loss: 2.26, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7156, CombTr_Loss: 0.97, CombTr_Acc: 0.54, CVHum_Loss: 1.84, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7157, CombTr_Loss: 0.87, CombTr_Acc: 0.68, CVHum_Loss: 2.14, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7158, CombTr_Loss: 1.01, CombTr_Acc: 0.72, CVHum_Loss: 2.05, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7159, CombTr_Loss: 0.98, CombTr_Acc: 0.58, CVHum_Loss: 1.78, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7160, CombTr_Loss: 1.12, CombTr_Acc: 0.58, CVHum_Loss: 2.25, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7161, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 2.19, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7162, CombTr_Loss: 1.28, CombTr_Acc: 0.46, CVHum_Loss: 1.89, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7163, CombTr_Loss: 0.77, CombTr_Acc: 0.72, CVHum_Loss: 1.59, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7164, CombTr_Loss: 1.21, CombTr_Acc: 0.54, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7165, CombTr_Loss: 1.11, CombTr_Acc: 0.62, CVHum_Loss: 2.01, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7166, CombTr_Loss: 0.94, CombTr_Acc: 0.66, CVHum_Loss: 2.1, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7167, CombTr_Loss: 0.87, CombTr_Acc: 0.7, CVHum_Loss: 2.29, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7168, CombTr_Loss: 0.95, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7169, CombTr_Loss: 0.68, CombTr_Acc: 0.82, CVHum_Loss: 1.91, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7170, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.24, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7171, CombTr_Loss: 0.86, CombTr_Acc: 0.62, CVHum_Loss: 2.29, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7172, CombTr_Loss: 1.06, CombTr_Acc: 0.54, CVHum_Loss: 2.32, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7173, CombTr_Loss: 1.16, CombTr_Acc: 0.6, CVHum_Loss: 2.03, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 7174, CombTr_Loss: 1.17, CombTr_Acc: 0.64, CVHum_Loss: 2.11, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7175, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 2.06, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7176, CombTr_Loss: 0.8, CombTr_Acc: 0.76, CVHum_Loss: 2.07, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7177, CombTr_Loss: 0.99, CombTr_Acc: 0.66, CVHum_Loss: 1.88, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7178, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 2.18, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7179, CombTr_Loss: 0.99, CombTr_Acc: 0.58, CVHum_Loss: 2.06, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7180, CombTr_Loss: 0.97, CombTr_Acc: 0.64, CVHum_Loss: 2.03, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7181, CombTr_Loss: 0.95, CombTr_Acc: 0.62, CVHum_Loss: 2.65, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7182, CombTr_Loss: 1.28, CombTr_Acc: 0.6, CVHum_Loss: 1.94, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7183, CombTr_Loss: 0.91, CombTr_Acc: 0.68, CVHum_Loss: 2.33, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7184, CombTr_Loss: 0.96, CombTr_Acc: 0.6, CVHum_Loss: 2.77, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7185, CombTr_Loss: 0.89, CombTr_Acc: 0.62, CVHum_Loss: 2.1, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7186, CombTr_Loss: 0.71, CombTr_Acc: 0.78, CVHum_Loss: 2.62, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 7187, CombTr_Loss: 1.07, CombTr_Acc: 0.52, CVHum_Loss: 2.71, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7188, CombTr_Loss: 0.91, CombTr_Acc: 0.6, CVHum_Loss: 2.59, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7189, CombTr_Loss: 1.09, CombTr_Acc: 0.66, CVHum_Loss: 1.77, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7190, CombTr_Loss: 0.93, CombTr_Acc: 0.68, CVHum_Loss: 2.0, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7191, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.91, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7192, CombTr_Loss: 1.02, CombTr_Acc: 0.64, CVHum_Loss: 1.89, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7193, CombTr_Loss: 0.94, CombTr_Acc: 0.62, CVHum_Loss: 2.24, CVHum_Acc: 0.28 \n",
      "Epoch: 20, Step: 7194, CombTr_Loss: 0.81, CombTr_Acc: 0.72, CVHum_Loss: 3.03, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7195, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.21, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7196, CombTr_Loss: 0.99, CombTr_Acc: 0.66, CVHum_Loss: 1.92, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7197, CombTr_Loss: 0.81, CombTr_Acc: 0.64, CVHum_Loss: 2.01, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7198, CombTr_Loss: 0.75, CombTr_Acc: 0.68, CVHum_Loss: 1.92, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7199, CombTr_Loss: 0.99, CombTr_Acc: 0.6, CVHum_Loss: 2.02, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7200, CombTr_Loss: 1.26, CombTr_Acc: 0.56, CVHum_Loss: 2.9, CVHum_Acc: 0.16 \n",
      "Epoch: 20, Step: 7201, CombTr_Loss: 1.0, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.5 \n",
      "Epoch: 20, Step: 7202, CombTr_Loss: 0.86, CombTr_Acc: 0.68, CVHum_Loss: 1.99, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7203, CombTr_Loss: 1.2, CombTr_Acc: 0.58, CVHum_Loss: 1.64, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7204, CombTr_Loss: 0.93, CombTr_Acc: 0.66, CVHum_Loss: 1.68, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7205, CombTr_Loss: 0.95, CombTr_Acc: 0.6, CVHum_Loss: 2.02, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7206, CombTr_Loss: 0.91, CombTr_Acc: 0.68, CVHum_Loss: 1.78, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7207, CombTr_Loss: 0.98, CombTr_Acc: 0.6, CVHum_Loss: 2.44, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7208, CombTr_Loss: 1.02, CombTr_Acc: 0.62, CVHum_Loss: 1.96, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7209, CombTr_Loss: 0.95, CombTr_Acc: 0.64, CVHum_Loss: 1.86, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7210, CombTr_Loss: 1.16, CombTr_Acc: 0.54, CVHum_Loss: 2.5, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7211, CombTr_Loss: 0.86, CombTr_Acc: 0.78, CVHum_Loss: 2.4, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7212, CombTr_Loss: 1.08, CombTr_Acc: 0.58, CVHum_Loss: 1.93, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7213, CombTr_Loss: 0.75, CombTr_Acc: 0.76, CVHum_Loss: 1.82, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7214, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 1.94, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7215, CombTr_Loss: 0.88, CombTr_Acc: 0.72, CVHum_Loss: 1.91, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7216, CombTr_Loss: 1.07, CombTr_Acc: 0.56, CVHum_Loss: 1.96, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7217, CombTr_Loss: 1.05, CombTr_Acc: 0.54, CVHum_Loss: 2.22, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7218, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 2.23, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7219, CombTr_Loss: 1.1, CombTr_Acc: 0.62, CVHum_Loss: 2.77, CVHum_Acc: 0.22 \n",
      "Epoch: 20, Step: 7220, CombTr_Loss: 0.96, CombTr_Acc: 0.62, CVHum_Loss: 1.93, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7221, CombTr_Loss: 0.83, CombTr_Acc: 0.7, CVHum_Loss: 1.62, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7222, CombTr_Loss: 1.08, CombTr_Acc: 0.54, CVHum_Loss: 2.41, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7223, CombTr_Loss: 0.95, CombTr_Acc: 0.62, CVHum_Loss: 1.76, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7224, CombTr_Loss: 0.98, CombTr_Acc: 0.62, CVHum_Loss: 2.17, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7225, CombTr_Loss: 1.19, CombTr_Acc: 0.58, CVHum_Loss: 1.84, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7226, CombTr_Loss: 1.0, CombTr_Acc: 0.62, CVHum_Loss: 2.11, CVHum_Acc: 0.3 \n",
      "Epoch: 20, Step: 7227, CombTr_Loss: 0.9, CombTr_Acc: 0.64, CVHum_Loss: 2.17, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7228, CombTr_Loss: 1.15, CombTr_Acc: 0.58, CVHum_Loss: 1.82, CVHum_Acc: 0.46 \n",
      "Epoch: 20, Step: 7229, CombTr_Loss: 1.04, CombTr_Acc: 0.62, CVHum_Loss: 2.36, CVHum_Acc: 0.26 \n",
      "Epoch: 20, Step: 7230, CombTr_Loss: 1.14, CombTr_Acc: 0.64, CVHum_Loss: 2.55, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7231, CombTr_Loss: 1.06, CombTr_Acc: 0.56, CVHum_Loss: 2.16, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7232, CombTr_Loss: 0.88, CombTr_Acc: 0.64, CVHum_Loss: 1.75, CVHum_Acc: 0.42 \n",
      "Epoch: 20, Step: 7233, CombTr_Loss: 1.13, CombTr_Acc: 0.54, CVHum_Loss: 2.39, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7234, CombTr_Loss: 0.85, CombTr_Acc: 0.7, CVHum_Loss: 2.13, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7235, CombTr_Loss: 1.14, CombTr_Acc: 0.56, CVHum_Loss: 2.37, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7236, CombTr_Loss: 1.03, CombTr_Acc: 0.58, CVHum_Loss: 2.27, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7237, CombTr_Loss: 1.15, CombTr_Acc: 0.56, CVHum_Loss: 1.79, CVHum_Acc: 0.44 \n",
      "Epoch: 20, Step: 7238, CombTr_Loss: 0.96, CombTr_Acc: 0.64, CVHum_Loss: 1.94, CVHum_Acc: 0.34 \n",
      "Epoch: 20, Step: 7239, CombTr_Loss: 0.87, CombTr_Acc: 0.66, CVHum_Loss: 2.29, CVHum_Acc: 0.24 \n",
      "Epoch: 20, Step: 7240, CombTr_Loss: 1.02, CombTr_Acc: 0.54, CVHum_Loss: 2.07, CVHum_Acc: 0.2 \n",
      "Epoch: 20, Step: 7241, CombTr_Loss: 0.9, CombTr_Acc: 0.66, CVHum_Loss: 2.33, CVHum_Acc: 0.36 \n",
      "Epoch: 20, Step: 7242, CombTr_Loss: 1.04, CombTr_Acc: 0.64, CVHum_Loss: 2.55, CVHum_Acc: 0.32 \n",
      "Epoch: 20, Step: 7243, CombTr_Loss: 0.99, CombTr_Acc: 0.62, CVHum_Loss: 2.22, CVHum_Acc: 0.4 \n",
      "Epoch: 20, Step: 7244, CombTr_Loss: 0.72, CombTr_Acc: 0.76, CVHum_Loss: 2.36, CVHum_Acc: 0.38 \n",
      "Epoch: 20, Step: 7245, CombTr_Loss: 0.93, CombTr_Acc: 0.72, CVHum_Loss: 2.09, CVHum_Acc: 0.3 \n",
      "Avg_CombTrain_Loss: 0.99, Avg_CombTrain_Acc: 0.62, Avg_CVHum_Loss: 2.15, Avg_CVHum_Acc: 0.35 \n",
      "Model and weights saved at epoch 20\n"
     ]
    }
   ],
   "source": [
    "epoch_number, CombTrain_loss, CombTrain_acc, CVHuman_loss, CVHuman_acc = [], [], [], [], []\n",
    "for epoch in range(epochs):\n",
    "    avg_epoch_CombTr_loss, avg_epoch_CombTr_acc, avg_epoch_CVHum_loss, avg_epoch_CVHum_acc = 0, 0, 0, 0\n",
    "    epoch_number.append(epoch + 1)\n",
    "    \n",
    "    for i in range(combTrain_bottleneck_files):\n",
    "        step += 1\n",
    "        #loading batch of train bottleneck features for training MLP.\n",
    "        X_CombTrain_load = np.load(os.path.join(SAVEDIR_COMB_TRAIN, \"bottleneck_{}.npy\".format(i+1)))\n",
    "        X_CombTrain = X_CombTrain_load.reshape(X_CombTrain_load.shape[0], X_CombTrain_load.shape[1]*X_CombTrain_load.shape[2]*X_CombTrain_load.shape[3])\n",
    "        Y_CombTrain = np.load(os.path.join(SAVEDIR_COMB_TRAIN_LABELS, \"bottleneck_labels_{}.npy\".format(i+1)))\n",
    "        \n",
    "        #loading batch of Human CV bottleneck features for cross-validation.\n",
    "        X_CVHuman_load = np.load(os.path.join(SAVEDIR_CV_HUMANS, \"bottleneck_{}.npy\".format((i % CVHuman_bottleneck_files) + 1)))\n",
    "        X_CVHuman = X_CVHuman_load.reshape(X_CVHuman_load.shape[0], X_CVHuman_load.shape[1]*X_CVHuman_load.shape[2]*X_CVHuman_load.shape[3])\n",
    "        Y_CVHuman = np.load(os.path.join(SAVEDIR_CV_HUMANS_LABELS, \"bottleneck_labels_{}.npy\".format((i % CVHuman_bottleneck_files) + 1)))\n",
    "        \n",
    "        CombTrain_Loss, CombTrain_Accuracy = model.train_on_batch(X_CombTrain, Y_CombTrain) #train the model on batch\n",
    "        CVHuman_Loss, CVHuman_Accuracy = model.test_on_batch(X_CVHuman, Y_CVHuman) #cross validate the model on CV Human batch\n",
    "\n",
    "        print(\"Epoch: {}, Step: {}, CombTr_Loss: {}, CombTr_Acc: {}, CVHum_Loss: {}, CVHum_Acc: {} \".format(epoch+1, step, np.round(float(CombTrain_Loss), 2), np.round(float(CombTrain_Accuracy), 2), np.round(float(CVHuman_Loss), 2), np.round(float(CVHuman_Accuracy), 2)))\n",
    "        \n",
    "        avg_epoch_CombTr_loss += CombTrain_Loss / combTrain_bottleneck_files\n",
    "        avg_epoch_CombTr_acc += CombTrain_Accuracy / combTrain_bottleneck_files\n",
    "        avg_epoch_CVHum_loss += CVHuman_Loss / combTrain_bottleneck_files\n",
    "        avg_epoch_CVHum_acc += CVHuman_Accuracy / combTrain_bottleneck_files\n",
    "       \n",
    "    print(\"Avg_CombTrain_Loss: {}, Avg_CombTrain_Acc: {}, Avg_CVHum_Loss: {}, Avg_CVHum_Acc: {} \".format(np.round(float(avg_epoch_CombTr_loss), 2), np.round(float(avg_epoch_CombTr_acc), 2), np.round(float(avg_epoch_CVHum_loss), 2), np.round(float(avg_epoch_CVHum_acc), 2)))\n",
    "\n",
    "    CombTrain_loss.append(avg_epoch_CombTr_loss)\n",
    "    CombTrain_acc.append(avg_epoch_CombTr_acc)\n",
    "    CVHuman_loss.append(avg_epoch_CVHum_loss)\n",
    "    CVHuman_acc.append(avg_epoch_CVHum_acc)\n",
    "    \n",
    "    model.save(os.path.join(SAVER, \"model.h5\"))  #saving the model on each epoc\n",
    "    model.save_weights(os.path.join(SAVER, \"model_weights.h5\")) #saving the weights of model on each epoch\n",
    "    print(\"Model and weights saved at epoch {}\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_frame = pd.DataFrame(columns = [\"Epoch\", \"Comb_Train_Loss\", \"Comb_Train_Accuracy\", \"CVHuman_Loss\", \"CVHuman_Accuracy\" ])\n",
    "log_frame[\"Epoch\"] = epoch_number\n",
    "log_frame[\"Comb_Train_Loss\"] = CombTrain_loss\n",
    "log_frame[\"Comb_Train_Accuracy\"] = CombTrain_acc\n",
    "log_frame[\"CVHuman_Loss\"] = CVHuman_loss\n",
    "log_frame[\"CVHuman_Accuracy\"] = CVHuman_acc\n",
    "log_frame.to_csv(\"../Data/Logs/Log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Comb_Train_Loss</th>\n",
       "      <th>Comb_Train_Accuracy</th>\n",
       "      <th>CVHuman_Loss</th>\n",
       "      <th>CVHuman_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.801509</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>1.886042</td>\n",
       "      <td>0.236638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.685807</td>\n",
       "      <td>0.331014</td>\n",
       "      <td>1.770282</td>\n",
       "      <td>0.294725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.646218</td>\n",
       "      <td>0.346725</td>\n",
       "      <td>1.750570</td>\n",
       "      <td>0.310783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.606674</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>1.770343</td>\n",
       "      <td>0.312580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.578341</td>\n",
       "      <td>0.375884</td>\n",
       "      <td>1.750646</td>\n",
       "      <td>0.313043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.546278</td>\n",
       "      <td>0.394087</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>0.326493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.510768</td>\n",
       "      <td>0.406609</td>\n",
       "      <td>1.721530</td>\n",
       "      <td>0.328174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.481824</td>\n",
       "      <td>0.419768</td>\n",
       "      <td>1.720514</td>\n",
       "      <td>0.335420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.446982</td>\n",
       "      <td>0.432348</td>\n",
       "      <td>1.722421</td>\n",
       "      <td>0.337043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1.411069</td>\n",
       "      <td>0.449159</td>\n",
       "      <td>1.758579</td>\n",
       "      <td>0.331768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1.369267</td>\n",
       "      <td>0.466725</td>\n",
       "      <td>1.762829</td>\n",
       "      <td>0.334493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1.327479</td>\n",
       "      <td>0.487536</td>\n",
       "      <td>1.788232</td>\n",
       "      <td>0.334435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1.281424</td>\n",
       "      <td>0.505217</td>\n",
       "      <td>1.831890</td>\n",
       "      <td>0.332464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1.243173</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>1.844154</td>\n",
       "      <td>0.340928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1.194403</td>\n",
       "      <td>0.539710</td>\n",
       "      <td>1.889985</td>\n",
       "      <td>0.340522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1.149478</td>\n",
       "      <td>0.559942</td>\n",
       "      <td>1.941626</td>\n",
       "      <td>0.342377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1.098640</td>\n",
       "      <td>0.576870</td>\n",
       "      <td>2.006090</td>\n",
       "      <td>0.335304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1.068697</td>\n",
       "      <td>0.591710</td>\n",
       "      <td>2.040883</td>\n",
       "      <td>0.342551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1.020510</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>2.082765</td>\n",
       "      <td>0.344116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.992053</td>\n",
       "      <td>0.622609</td>\n",
       "      <td>2.147613</td>\n",
       "      <td>0.345391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  Comb_Train_Loss  Comb_Train_Accuracy  CVHuman_Loss  \\\n",
       "0       1         1.801509             0.277217      1.886042   \n",
       "1       2         1.685807             0.331014      1.770282   \n",
       "2       3         1.646218             0.346725      1.750570   \n",
       "3       4         1.606674             0.364000      1.770343   \n",
       "4       5         1.578341             0.375884      1.750646   \n",
       "5       6         1.546278             0.394087      1.704748   \n",
       "6       7         1.510768             0.406609      1.721530   \n",
       "7       8         1.481824             0.419768      1.720514   \n",
       "8       9         1.446982             0.432348      1.722421   \n",
       "9      10         1.411069             0.449159      1.758579   \n",
       "10     11         1.369267             0.466725      1.762829   \n",
       "11     12         1.327479             0.487536      1.788232   \n",
       "12     13         1.281424             0.505217      1.831890   \n",
       "13     14         1.243173             0.525391      1.844154   \n",
       "14     15         1.194403             0.539710      1.889985   \n",
       "15     16         1.149478             0.559942      1.941626   \n",
       "16     17         1.098640             0.576870      2.006090   \n",
       "17     18         1.068697             0.591710      2.040883   \n",
       "18     19         1.020510             0.608986      2.082765   \n",
       "19     20         0.992053             0.622609      2.147613   \n",
       "\n",
       "    CVHuman_Accuracy  \n",
       "0           0.236638  \n",
       "1           0.294725  \n",
       "2           0.310783  \n",
       "3           0.312580  \n",
       "4           0.313043  \n",
       "5           0.326493  \n",
       "6           0.328174  \n",
       "7           0.335420  \n",
       "8           0.337043  \n",
       "9           0.331768  \n",
       "10          0.334493  \n",
       "11          0.334435  \n",
       "12          0.332464  \n",
       "13          0.340928  \n",
       "14          0.340522  \n",
       "15          0.342377  \n",
       "16          0.335304  \n",
       "17          0.342551  \n",
       "18          0.344116  \n",
       "19          0.345391  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(\"../Data/Logs/Log.csv\")\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(epoch, train_loss, CVHuman_loss, title):\n",
    "    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n",
    "    axes.plot(epoch, train_loss, color = 'red', label = \"Train\")\n",
    "    axes.plot(epoch, CVHuman_loss, color = 'blue', label = \"CV_Human\")\n",
    "    axes.set_title(title, fontsize = 25)\n",
    "    axes.set_xlabel(\"Epochs\", fontsize = 20)\n",
    "    axes.set_ylabel(\"Loss\", fontsize = 20)\n",
    "    axes.grid()\n",
    "    axes.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting(list(log[\"Epoch\"]), list(log[\"Comb_Train_Loss\"]), list(log[\"CVHuman_Loss\"]), \"EPOCH VS LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(epoch, train_acc, CVHuman_acc, title):\n",
    "    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n",
    "    axes.plot(epoch, train_acc, color = 'red', label = \"Train_Accuracy\")\n",
    "    axes.plot(epoch, CVHuman_acc, color = 'blue', label = \"CV_Human_Accuracy\")\n",
    "    axes.set_title(title, fontsize = 25)\n",
    "    axes.set_xlabel(\"Epochs\", fontsize = 20)\n",
    "    axes.set_ylabel(\"Accuracy\", fontsize = 20)\n",
    "    axes.grid()\n",
    "    axes.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting(list(log[\"Epoch\"]), list(log[\"Comb_Train_Accuracy\"]), list(log[\"CVHuman_Accuracy\"]), \"EPOCH VS ACCURACY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Real World with Still Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for testing the model on real world images we have to follow all of the same steps which we have done on our training, CV\n",
    "# and test images. Like here we have to first pre-preocess our images then create its VGG-16 bottleneck features then pass those \n",
    "# bottleneck features through our own MLP model for prediction.\n",
    "# Steps are as follows:\n",
    "# 1. Read the image, convert it to grayscale and save it.\n",
    "# 2. Read that grayscale saved image, the detect face in it using HAAR cascade.\n",
    "# 3. Crop the image to the detected face and resize it to 350*350 and save the image.\n",
    "# 4. Read that processed cropped-resized image, then reshape it and normalize it.\n",
    "# 5. Then feed that image to VGG-16 and create bottleneck features of that image and then reshape it.\n",
    "# 6. Then use our own model for final prediction of expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_DICT = {1:\"ANGRY\", 2:\"DISGUST\", 3:\"FEAR\", 4:\"HAPPY\", 5:\"NEUTRAL\", 6:\"SAD\", 7:\"SURPRISE\",8:\"PAIN\"}\n",
    "model_VGG = VGG16(weights='imagenet', include_top=False)\n",
    "model_top = load_model(\"../Data/Model_Save/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(path):\n",
    "    #converting image to gray scale and save it\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(path, gray)\n",
    "    \n",
    "    #detect face in image, crop it then resize it then save it\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_clip = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(path, cv2.resize(face_clip, (48, 48)))\n",
    "    \n",
    "    #read the processed image then make prediction and display the result\n",
    "    read_image = cv2.imread(path)\n",
    "    read_image = read_image.reshape(1, read_image.shape[0], read_image.shape[1], read_image.shape[2])\n",
    "    read_image_final = read_image/25.0  #normalizing the image\n",
    "    VGG_Pred = model_VGG.predict(read_image_final)  #creating bottleneck features of image using VGG-16.\n",
    "    VGG_Pred = VGG_Pred.reshape(1, VGG_Pred.shape[1]*VGG_Pred.shape[2]*VGG_Pred.shape[3])\n",
    "    top_pred = model_top.predict(VGG_Pred)  #making prediction from our own model.\n",
    "    emotion_label = top_pred[0].argmax() + 1\n",
    "    print(\"Predicted Expression Probabilities\")\n",
    "    print(\"ANGRY: {}\\nDISGUST: {}\\nFEAR: {}\\nHAPPY: {}\\nNEUTRAL: {}\\nSAD: {}\\nSURPRISE: {}\\nPAIN: {}\\n\\n\".format(top_pred[0][0], top_pred[0][1], top_pred[0][2], top_pred[0][3], top_pred[0][4], top_pred[0][5], top_pred[0][6], top_pred[0][7]))\n",
    "    print(\"Dominant Probability = \"+str(EMOTION_DICT[emotion_label])+\": \"+str(max(top_pred[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x216BC673608>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"../Data/Test/test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Expression Probabilities\n",
      "ANGRY: 0.5011460185050964\n",
      "DISGUST: 7.556018885074085e-25\n",
      "FEAR: 0.40846365690231323\n",
      "HAPPY: 5.160607184639954e-13\n",
      "NEUTRAL: 0.09038113057613373\n",
      "SAD: 9.14750125957653e-06\n",
      "SURPRISE: 2.6224636342234025e-23\n",
      "PAIN: 0.0\n",
      "\n",
      "\n",
      "Dominant Probability = ANGRY: 0.501146\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"../Data/Test/test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHX0lEQVR4nAXBSW9dZxkA4Pf9pjPdc8+dbMfxkDh2GicESgKUkra0FREItaroihVLYBOJDf8BNogVqoSQ2CCxqlAlKFRCQAmTghLTpE6cOnYmx0Pu7HvP8M08D76x/M2vNgQzhCiilPIapdRV5SqrJ4b5iodhComspqTa/ctDVbKZJHAOLTiHFpE6AEq8sd57yow3mlAmA/AsDtnETS0hTeEKix6dQ4eEgLCA2qEhQMA4CFNGLCrtwjgWSYN5NsJSmgo4eABPwHn01mjjDKGUOReHStrQC4hD4PX61DDPJoUH6hAdMQi2CsGb3DIXoUXNUkcqE2LWDBxmrawYsPZy6L1DI9BSh4hQ0UAXYsI5Gu/jWq+aIqtkK5IkrDX8c7ZypV6PEZij4L1mhJc2RIsyb6YCXST9yKQWj7uUAm/WRYOdvUAUUEs8oActEMLSRU6FPcfQAy/VOPRlfXD3iKNOBJ5gTQDiCTXCWElhwq3zIxJWMUxiNyJ61A9tPtk4VrXV+VaDY5MJZqzwOlBcWectmVCVh+mwBbYYPlkcX6+3RuVBN11aXzAWw/wEq1nnVSQMGwO66KhVHjenYeNJM+qzwSHvPQ33akOzMvP5tD7pM2brzHmP5skR6GnYjHpcbCdBt26TWntnc/s5k/bBPDDIuxt2+VLk4kHJDHhbHGz227Qq+izr7q6lUVuvNm3/jjePc8m7+a4mX7HkPlylcZ4z5xB9Y71f2fFgoO4Ok3u1JbV0scjSWt/n/ti9uFPES7XGt4Jh4ETwiE258swoRmU5Jg+GvnNhTTcWVefAdOLDXaNOp18840lxPjqZWlElFTuSzIWN7T/2ytfO/GabLIu7i53Wmc6kbNDO32Rw+gux5BPfmY0OcQ5m5xps5zVqaG3tnfHRiebletImw+lrVPjoZC+eyXTG86QeAJkhfUhARKdW2GZ/iRpYXBg+HH92PtOFPDOvTllieWhwYWYApIhRhVaNo0YQQmeV3X60aAkB2zhvTz2s54MyUJIEVmMS+Ytvbx1OTLPWqCcizNoJMcEMO7z7uiHeWx9OSCcZZJ6Ki7FkRDAblFcvj59OHTbTgCftdgigmsxuKEQLwuqMR3Z2KJdnmRHKHo+DxLWzIupOdUAAWByDI0wwsTNKPDpNQyNCjwGdoS6gpCSC5TGmrjbNnQQSOg/gPQkIGx0S6TlHYJDQeGaWM47Ce2RTHmqTWVN5AG9jVN4W0hGaP2UUnAYfpCwKjRCIokKekEqKShatSJalAaiG3YmUljCmtq9aYJRQ5zE0TivCaOC0CLzzDfrB7gvNkZ5SXiFKYUnO0N3JgXgPiEgp8aqslYQbBIqlTuDse/9Zz0jqtTVIiPaaQPbwUBjPKSJ6bbSJ7v3LeucBmWHp4NI3Drb2Dg8ng1GupLa2S9D1bnJpS2edR+91fvt3U1oEgHHIfRGEL+JwT+U9WUjttHZbJHWzG4paI5UyzlSDex88PIfgQEpaEdqpPbOBPCa2VEp6raefEBW0b3yaSG+NkbLo7d7Y+lxHBzqMQFT7MNw6OOnkCOJSU1Ql7m+zvNbd/fAy9w6cM0Vv90F2peaUZ5pV5Weg759fv/VJ0YsSoGic+HRCnD0kH+0T7Z2uiuPu48OXzzVENe4XqIdscwNPvfT9K26QV8JohHKTkPqEdHofxFSBUaYc7M1+fcbTJCqe79wuu11OjWu93bTKWsF0vPuZYOOkVHM33ppTlY/65XD81gIH41NGvNVdfyR6j+P09OOYUEfQ/ddSttYbBMHwwx9IoXLQ3fh8fai8kJYFnc37UkZYljXFCdKABc9uUWDRyJP63J2/v1oILO2onh2OhlPBYTBwzyaU1xdbd26ZyDRF4Pit4wDIQ2f9VHZ/sk8Bkjp4/6dr11t6jjF4lLfWTl849+dhmwtOAgeT28Q6lpuqOU7V3k9/bljYXr3V3bu7e/Udubcg7g3app9d/+ebHT2OA6C1jQMGjjDJFR3049+/VwcWXxBHb7T1j689W108d2lllU3+fb0VxAvSAwT6pmOUsrydF8LnpvXLs1dlunRq52vf/u3evY3vVK+SGwayoD0Oau3HvYbAg50IJGUGeZkHxnL6s7V5k60/0N+7+ajdv1O8325HXz4p2cKl58HCExRwU3IpHGHHJtLaupw9/QUgXV44nvthVrUufenltfWVRYbsYmSyuhBB99PYUkCiPdQiKjytGn/9Vcw7Z6l56V0ygJX5lcWW1qMz32UyZJ0ovjPljAIjxtUYBZ3GUXLi/Y9EPQuMePdKvr283MC6GU1Wnx3WFU0aR5sZUgwFC23RavWFbbgmo39YPttWDLNrxT8uz0wiOXg0/8pd05FVvfax4ugjbvCE8/zM8X46Z2udg9VTb3Yq4Uwx+fWTFy6aajp/vndUzI+31scfWe1JpD3zKuD7ruMDLFNJ6f9eSQsbmPRHHzMaLs33e7vFnNtPYMsix5ATRqyjgkCFJehjRqPywTSKZFjIN9JsTj549KSr7MFBZ/yMe9qqiVbr/74GUoAgodwfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x216A220BF48>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"../Data/Test/test2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Expression Probabilities\n",
      "ANGRY: 0.004074513912200928\n",
      "DISGUST: 4.4642271108084886e-13\n",
      "FEAR: 0.13249272108078003\n",
      "HAPPY: 1.6985536888114439e-07\n",
      "NEUTRAL: 0.8611282110214233\n",
      "SAD: 0.0023043607361614704\n",
      "SURPRISE: 6.198796684286911e-12\n",
      "PAIN: 2.267895246768723e-16\n",
      "\n",
      "\n",
      "Dominant Probability = NEUTRAL: 0.8611282\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"../Data/Test/test2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x216A2156A08>"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"../Data/Test/pain.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Expression Probabilities\n",
      "ANGRY: 0.0006658844649791718\n",
      "DISGUST: 8.82831676686513e-14\n",
      "FEAR: 0.9810816645622253\n",
      "HAPPY: 0.0001393859420204535\n",
      "NEUTRAL: 0.0027486588805913925\n",
      "SAD: 0.015364337712526321\n",
      "SURPRISE: 4.2434117200965127e-13\n",
      "PAIN: 1.7273054575178508e-23\n",
      "\n",
      "\n",
      "Dominant Probability = FEAR: 0.98108166\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"../Data/Test/pain.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x21685E7AAC8>"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"../Data/Test/pain2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Expression Probabilities\n",
      "ANGRY: 0.0002111065259668976\n",
      "DISGUST: 6.80634298921845e-11\n",
      "FEAR: 0.005659537389874458\n",
      "HAPPY: 3.408640054658463e-07\n",
      "NEUTRAL: 0.9920576214790344\n",
      "SAD: 0.002071431605145335\n",
      "SURPRISE: 1.1987858622442005e-11\n",
      "PAIN: 1.984844860675489e-17\n",
      "\n",
      "\n",
      "Dominant Probability = NEUTRAL: 0.9920576\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"../Data/Test/pain2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x216A216B7C8>"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"../Data/Test/pain3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Expression Probabilities\n",
      "ANGRY: 4.5682682636716265e-10\n",
      "DISGUST: 8.538245083604484e-29\n",
      "FEAR: 1.6262578128589666e-07\n",
      "HAPPY: 0.009992771781980991\n",
      "NEUTRAL: 0.9900070428848267\n",
      "SAD: 7.139872337802444e-08\n",
      "SURPRISE: 7.599765718403407e-18\n",
      "PAIN: 1.7665092421483596e-37\n",
      "\n",
      "\n",
      "Dominant Probability = NEUTRAL: 0.99000704\n"
     ]
    }
   ],
   "source": [
    "make_prediction(\"../Data/Test/pain3.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
